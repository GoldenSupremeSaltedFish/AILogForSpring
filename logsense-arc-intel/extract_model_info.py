#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æå–æ¨¡å‹ä¿¡æ¯è„šæœ¬ - ä¸åŠ è½½å®Œæ•´æ¨¡å‹ç±»
"""

import torch
import pickle
import sys
import os

def extract_model_info(model_path):
    """æå–æ¨¡å‹ä¿¡æ¯"""
    try:
        print(f"ğŸ” åˆ†ææ¨¡å‹æ–‡ä»¶: {model_path}")
        
        # å®šä¹‰å¿…è¦çš„ç±»
        class StructuredFeatureExtractor:
            def __init__(self, max_tfidf_features=1000):
                self.max_tfidf_features = max_tfidf_features
                self.label_encoders = {}
                self.tfidf_vectorizer = None
                self.scaler = None
                self.feature_names = []
        
        # è®¾ç½®åˆ°å…¨å±€å‘½åç©ºé—´
        import __main__
        __main__.StructuredFeatureExtractor = StructuredFeatureExtractor
        
        # å°è¯•ç›´æ¥è¯»å–æ–‡ä»¶å†…å®¹
        with open(model_path, 'rb') as f:
            # è·³è¿‡PyTorchçš„å¤´éƒ¨ä¿¡æ¯
            f.seek(0)
            
            # å°è¯•ä½¿ç”¨pickleåŠ è½½ï¼Œä½†ä¸æ‰§è¡Œä»£ç 
            try:
                # æ·»åŠ å®‰å…¨å…¨å±€å˜é‡
                import torch.serialization
                torch.serialization.add_safe_globals([
                    'sklearn.preprocessing._label.LabelEncoder',
                    'sklearn.preprocessing._data.StandardScaler',
                    'sklearn.feature_extraction.text.TfidfVectorizer'
                ])
                
                # ä½¿ç”¨weights_only=Falseæ¥åŠ è½½å®Œæ•´æ¨¡å‹
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
                print("âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡")
                
                if isinstance(checkpoint, dict):
                    print(f"ğŸ“Š Checkpoint keys: {list(checkpoint.keys())}")
                    
                    if 'model_state_dict' in checkpoint:
                        state_dict = checkpoint['model_state_dict']
                        print(f"ğŸ”§ æ¨¡å‹çŠ¶æ€å­—å…¸åŒ…å« {len(state_dict)} ä¸ªå‚æ•°:")
                        
                        # åˆ†æå…³é”®å‚æ•°
                        for key, tensor in state_dict.items():
                            print(f"  {key}: {tensor.shape}")
                            
                            # ç‰¹åˆ«å…³æ³¨åµŒå…¥å±‚å’ŒMLPå±‚
                            if 'embedding' in key and 'weight' in key:
                                print(f"    -> è¯æ±‡è¡¨å¤§å°: {tensor.shape[0]}")
                            elif 'mlp.0.weight' in key:
                                print(f"    -> ç»“æ„åŒ–ç‰¹å¾è¾“å…¥ç»´åº¦: {tensor.shape[1]}")
                            elif 'fusion_layer.0.weight' in key:
                                print(f"    -> èåˆå±‚è¾“å…¥ç»´åº¦: {tensor.shape[1]}")
                            elif 'fusion_layer.3.weight' in key:
                                print(f"    -> èåˆå±‚è¾“å‡ºç»´åº¦: {tensor.shape[0]}")
                        
                        # æå–å…³é”®ä¿¡æ¯
                        vocab_size = None
                        struct_input_dim = None
                        num_classes = None
                        
                        for key, tensor in state_dict.items():
                            if 'text_encoder.embedding.weight' in key:
                                vocab_size = tensor.shape[0]
                            elif 'struct_mlp.mlp.0.weight' in key:
                                struct_input_dim = tensor.shape[1]
                            elif 'fusion_layer.3.weight' in key:
                                num_classes = tensor.shape[0]
                        
                        print(f"\nğŸ“‹ æå–çš„å…³é”®ä¿¡æ¯:")
                        print(f"  è¯æ±‡è¡¨å¤§å°: {vocab_size}")
                        print(f"  ç»“æ„åŒ–ç‰¹å¾è¾“å…¥ç»´åº¦: {struct_input_dim}")
                        print(f"  ç±»åˆ«æ•°é‡: {num_classes}")
                        
                        # æå–è¯æ±‡è¡¨
                        vocab = checkpoint.get('vocab', {})
                        label_encoder = checkpoint.get('label_encoder', None)
                        
                        return {
                            'vocab_size': vocab_size,
                            'struct_input_dim': struct_input_dim,
                            'num_classes': num_classes,
                            'state_dict': state_dict,
                            'vocab': vocab,
                            'label_encoder': label_encoder
                        }
                    else:
                        print("âŒ æœªæ‰¾åˆ°model_state_dict")
                        return None
                else:
                    print(f"âŒ Checkpointä¸æ˜¯å­—å…¸æ ¼å¼: {type(checkpoint)}")
                    return None
                    
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥: {e}")
                return None
                
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    model_path = "results/models/feature_enhanced_model_20250809_103658.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    info = extract_model_info(model_path)
    
    if info:
        print(f"\nğŸ¯ æ¨¡å‹ä¿¡æ¯æå–å®Œæˆ")
        print(f"   è¯æ±‡è¡¨å¤§å°: {info['vocab_size']}")
        print(f"   ç»“æ„åŒ–ç‰¹å¾è¾“å…¥ç»´åº¦: {info['struct_input_dim']}")
        print(f"   ç±»åˆ«æ•°é‡: {info['num_classes']}")
    else:
        print("âŒ æ¨¡å‹ä¿¡æ¯æå–å¤±è´¥")

if __name__ == "__main__":
    main()
