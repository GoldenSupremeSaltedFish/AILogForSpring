#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„è®­ç»ƒè„šæœ¬ - åŒ…å«ç±»åˆ«æƒé‡å’Œæ›´å¼ºçš„æ­£åˆ™åŒ–
"""

import argparse
import torch
import torch.nn as nn
import logging
import os
from datetime import datetime
from typing import Dict, Any, List
import numpy as np
from collections import Counter
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, classification_report

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models import ModelFactory
from utils import create_persistence_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ImprovedDataset(torch.utils.data.Dataset):
    """æ”¹è¿›çš„æ•°æ®é›†"""
    
    def __init__(self, texts: list, labels: list, max_length: int = 128, vocab_size: int = 8000):
        self.texts = texts
        self.labels = labels
        self.max_length = max_length
        self.vocab_size = vocab_size
        self.vocab = self._build_vocab()
        logger.info(f"ğŸ“š è¯æ±‡è¡¨å¤§å°: {len(self.vocab)}")
    
    def _build_vocab(self):
        """æ„å»ºè¯æ±‡è¡¨"""
        word_counts = Counter()
        for text in self.texts:
            words = text.lower().split()
            word_counts.update(words)
        
        vocab = {'<PAD>': 0, '<UNK>': 1}
        for word, count in word_counts.most_common(self.vocab_size - 2):
            if count >= 2:  # è‡³å°‘å‡ºç°2æ¬¡
                vocab[word] = len(vocab)
        return vocab
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx]).lower()
        label = self.labels[idx]
        
        words = text.split()[:self.max_length]
        token_ids = []
        
        for word in words:
            if word in self.vocab:
                token_ids.append(self.vocab[word])
            else:
                token_ids.append(self.vocab['<UNK>'])
        
        if len(token_ids) < self.max_length:
            token_ids += [self.vocab['<PAD>']] * (self.max_length - len(token_ids))
        else:
            token_ids = token_ids[:self.max_length]
        
        return {
            'input_ids': torch.tensor(token_ids, dtype=torch.long),
            'labels': torch.tensor(label, dtype=torch.long)
        }


class ImprovedTrainer:
    """æ”¹è¿›çš„è®­ç»ƒå™¨"""
    
    def __init__(self, model_type: str = "textcnn"):
        self.model_type = model_type
        if torch.xpu.is_available():
            self.device = torch.device("xpu:0")
            logger.info("âœ… ä½¿ç”¨Intel XPU GPUåŠ é€Ÿ")
        else:
            self.device = torch.device("cpu")
            logger.warning("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒ")
        
        self.model = None
        self.label_encoder = None
        self.class_weights = None
        
        # åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨
        self.persistence = create_persistence_manager()
        
        # è®­ç»ƒå†å²è®°å½•
        self.training_history = {
            'train_loss': [], 'val_loss': [], 'train_acc': [], 
            'val_acc': [], 'val_f1': [], 'learning_rate': []
        }
        
        logger.info(f"ğŸ¯ åˆå§‹åŒ–æ”¹è¿›è®­ç»ƒå™¨ - æ¨¡å‹ç±»å‹: {model_type}")
        logger.info(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {self.device}")
    
    def load_data(self, data_path: str):
        """åŠ è½½æ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
        
        df = pd.read_csv(data_path)
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
        
        # æ•°æ®æ¸…æ´—
        df_cleaned = df.dropna(subset=['original_log', 'category'])
        df_cleaned = df_cleaned[df_cleaned['original_log'].str.strip() != '']
        
        # æ£€æŸ¥æ•°æ®å¹³è¡¡æ€§
        category_counts = df_cleaned['category'].value_counts()
        logger.info("ğŸ“Š æ•°æ®åˆ†å¸ƒæ£€æŸ¥:")
        for category, count in category_counts.items():
            logger.info(f"  {category}: {count} æ¡")
        
        # è¿‡æ»¤æ‰æ ·æœ¬å¤ªå°‘çš„ç±»åˆ«ï¼ˆå°‘äº10æ¡è®°å½•ï¼‰
        min_samples = 10
        valid_categories = category_counts[category_counts >= min_samples].index.tolist()
        df_balanced = df_cleaned[df_cleaned['category'].isin(valid_categories)]
        
        logger.info(f"ğŸ“Š å¹³è¡¡åæ•°æ®: {len(df_balanced)} æ¡è®°å½•")
        logger.info(f"ğŸ“Š æœ‰æ•ˆç±»åˆ«æ•°: {len(valid_categories)}")
        logger.info(f"ğŸ“Š æœ‰æ•ˆç±»åˆ«: {valid_categories}")
        
        texts = df_balanced['original_log'].fillna('').tolist()
        labels = df_balanced['category'].tolist()
        
        # åˆ†ææ•°æ®åˆ†å¸ƒ
        data_info = self._analyze_data_distribution(labels)
        self.persistence.save_data_info(data_info)
        self.persistence.copy_data_files(data_path)
        
        # æ ‡ç­¾ç¼–ç 
        unique_labels = sorted(list(set(labels)))
        label_to_id = {label: idx for idx, label in enumerate(unique_labels)}
        encoded_labels = [label_to_id[label] for label in labels]
        
        self.label_encoder = {idx: label for label, idx in label_to_id.items()}
        
        # è®¡ç®—ç±»åˆ«æƒé‡
        self.class_weights = self._calculate_class_weights(encoded_labels)
        
        logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ - ç±»åˆ«æ•°: {len(self.label_encoder)}")
        
        return texts, encoded_labels
    
    def _analyze_data_distribution(self, labels):
        """åˆ†ææ•°æ®åˆ†å¸ƒ"""
        label_counts = Counter(labels)
        total = len(labels)
        
        distribution = {}
        for label, count in label_counts.items():
            percentage = (count / total) * 100
            distribution[label] = {'count': count, 'percentage': percentage}
            logger.info(f"   {label}: {count} æ¡ ({percentage:.1f}%)")
        
        max_count = max(label_counts.values())
        min_count = min(label_counts.values())
        imbalance_ratio = max_count / min_count
        
        logger.info(f"ğŸ“ˆ æ•°æ®ä¸å¹³è¡¡æ¯”ä¾‹: {imbalance_ratio:.2f}:1")
        
        return {
            'total_samples': total,
            'label_distribution': distribution,
            'imbalance_ratio': imbalance_ratio,
            'num_classes': len(label_counts)
        }
    
    def _calculate_class_weights(self, labels: List[int]) -> torch.Tensor:
        """è®¡ç®—ç±»åˆ«æƒé‡"""
        label_counts = Counter(labels)
        total_samples = len(labels)
        num_classes = len(label_counts)
        
        weights = torch.ones(num_classes)
        for label, count in label_counts.items():
            # ä½¿ç”¨é€†é¢‘ç‡æƒé‡
            weight = total_samples / (num_classes * count)
            weights[label] = weight
        
        logger.info("ğŸ“Š ç±»åˆ«æƒé‡:")
        for i, weight in enumerate(weights):
            logger.info(f"  ç±»åˆ« {i} ({self.label_encoder[i]}): {weight:.3f}")
        
        return weights.to(self.device)
    
    def create_model(self, num_classes: int):
        """åˆ›å»ºæ¨¡å‹"""
        logger.info(f"ğŸ—ï¸ åˆ›å»ºæ¨¡å‹: {self.model_type}")
        
        model_config = {
            'vocab_size': 8000,
            'embed_dim': 128,
            'num_classes': num_classes,
            'filter_sizes': [3, 4, 5],
            'num_filters': 128,
            'dropout': 0.6  # å¢åŠ Dropout
        }
        
        self.model = ModelFactory.create_model(self.model_type, **model_config)
        self.model.to(self.device)
        
        param_count = self.model.count_parameters()
        logger.info(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ - å‚æ•°æ•°é‡: {param_count:,}")
        
        return model_config
    
    def train_epoch(self, train_loader, criterion, optimizer):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch in train_loader:
            input_ids = batch['input_ids'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            optimizer.zero_grad()
            outputs = self.model(input_ids)
            loss = criterion(outputs, labels)
            loss.backward()
            
            # æ›´å¼ºçš„æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)
            optimizer.step()
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        
        return total_loss / len(train_loader), 100 * correct / total
    
    def validate_epoch(self, val_loader, criterion):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        all_predictions = []
        all_labels = []
        
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = self.model(input_ids)
                loss = criterion(outputs, labels)
                
                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        f1 = f1_score(all_labels, all_predictions, average='weighted')
        
        return total_loss / len(val_loader), 100 * correct / total, f1, all_predictions, all_labels
    
    def train(self, data_path: str, epochs: int = 30, patience: int = 8, batch_size: int = 32):
        """è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹æ”¹è¿›è®­ç»ƒ")
        
        # åŠ è½½æ•°æ®
        texts, labels = self.load_data(data_path)
        
        # ä½¿ç”¨Stratified Split
        train_texts, val_texts, train_labels, val_labels = train_test_split(
            texts, labels, test_size=0.2, stratify=labels, random_state=42
        )
        
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            train_texts, train_labels, test_size=0.2, stratify=train_labels, random_state=42
        )
        
        logger.info(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
        logger.info(f"   è®­ç»ƒé›†: {len(train_texts)} æ¡")
        logger.info(f"   éªŒè¯é›†: {len(val_texts)} æ¡")
        logger.info(f"   æµ‹è¯•é›†: {len(test_texts)} æ¡")
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = ImprovedDataset(train_texts, train_labels)
        val_dataset = ImprovedDataset(val_texts, val_labels)
        test_dataset = ImprovedDataset(test_texts, test_labels)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        
        # åˆ›å»ºæ¨¡å‹
        num_classes = len(self.label_encoder)
        model_config = self.create_model(num_classes)
        
        # ä¿å­˜è®­ç»ƒé…ç½®
        training_config = {
            'model_type': self.model_type,
            'epochs': epochs,
            'patience': patience,
            'batch_size': batch_size,
            'learning_rate': 0.0005,  # é™ä½å­¦ä¹ ç‡
            'weight_decay': 0.05,     # å¢åŠ L2æ­£åˆ™åŒ–
            'model_config': model_config,
            'device': str(self.device),
            'data_path': data_path,
            'num_classes': num_classes,
            'use_class_weights': True
        }
        self.persistence.save_training_config(training_config)
        
        # è®­ç»ƒç»„ä»¶ - ä½¿ç”¨ç±»åˆ«æƒé‡
        criterion = nn.CrossEntropyLoss(weight=self.class_weights)
        optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.0005, weight_decay=0.05)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.3)
        
        best_acc = 0
        best_f1 = 0
        patience_counter = 0
        best_predictions = None
        best_labels = None
        
        for epoch in range(epochs):
            logger.info(f"ğŸ“ˆ Epoch {epoch+1}/{epochs}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)
            
            # éªŒè¯
            val_loss, val_acc, val_f1, val_predictions, val_labels = self.validate_epoch(val_loader, criterion)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_f1)
            current_lr = optimizer.param_groups[0]['lr']
            
            # è®°å½•å†å²
            self.training_history['train_loss'].append(train_loss)
            self.training_history['val_loss'].append(val_loss)
            self.training_history['train_acc'].append(train_acc)
            self.training_history['val_acc'].append(val_acc)
            self.training_history['val_f1'].append(val_f1)
            self.training_history['learning_rate'].append(current_lr)
            
            logger.info(f"  è®­ç»ƒ: æŸå¤±={train_loss:.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
            logger.info(f"  éªŒè¯: æŸå¤±={val_loss:.4f}, å‡†ç¡®ç‡={val_acc:.2f}%, F1={val_f1:.4f}")
            
            # æ—©åœæ£€æŸ¥
            if val_f1 > best_f1:
                best_f1 = val_f1
                best_acc = val_acc
                best_predictions = val_predictions
                best_labels = val_labels
                patience_counter = 0
                
                self.persistence.save_model(self.model, "best", model_config)
                logger.info(f" ä¿å­˜æœ€ä½³æ¨¡å‹ (F1: {val_f1:.4f}, å‡†ç¡®ç‡: {val_acc:.2f}%)")
            else:
                patience_counter += 1
                logger.info(f"â³ æ—©åœè®¡æ•°: {patience_counter}/{patience}")
            
            if patience_counter >= patience:
                logger.info(f" æ—©åœè§¦å‘ - {patience} è½®æœªæ”¹å–„")
                break
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.persistence.save_model(self.model, "final", model_config)
        
        # æµ‹è¯•é›†è¯„ä¼°
        test_loss, test_acc, test_f1, test_predictions, test_labels = self.validate_epoch(test_loader, criterion)
        logger.info(f" æµ‹è¯•é›†: æŸå¤±={test_loss:.4f}, å‡†ç¡®ç‡={test_acc:.2f}%, F1={test_f1:.4f}")
        
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        self._save_all_results(best_acc, best_f1, test_acc, test_f1, epoch + 1, 
                             best_predictions, best_labels)
        
        logger.info(f"âœ… æ”¹è¿›è®­ç»ƒå®Œæˆ - æœ€ä½³F1: {best_f1:.4f}, æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
        logger.info(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {self.persistence.session_dir}")
    
    def _save_all_results(self, best_acc, best_f1, test_acc, test_f1, final_epoch,
                         best_predictions, best_labels):
        """ä¿å­˜æ‰€æœ‰ç»“æœ"""
        # ä¿å­˜è®­ç»ƒå†å²
        self.persistence.save_training_history(self.training_history)
        
        # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
        metrics = {
            'best_val_acc': best_acc,
            'best_val_f1': best_f1,
            'test_acc': test_acc,
            'test_f1': test_f1,
            'final_epoch': final_epoch,
            'total_epochs': len(self.training_history['train_loss'])
        }
        self.persistence.save_training_metrics(metrics)
        
        # ä¿å­˜è®­ç»ƒå›¾è¡¨
        self.persistence.save_plots(self.training_history)
        
        # ä¿å­˜æ··æ·†çŸ©é˜µ
        actual_class_names = [self.label_encoder[i] for i in range(len(self.label_encoder))]
        logger.info(f"ğŸ“Š å®é™…ç±»åˆ«æ•°é‡: {len(actual_class_names)}")
        logger.info(f"ğŸ“Š å®é™…ç±»åˆ«: {actual_class_names}")
        
        self.persistence.save_confusion_matrix(best_labels, best_predictions, actual_class_names)
        
        # ä¿å­˜åˆ†ç±»æŠ¥å‘Š
        self.persistence.save_classification_report(best_labels, best_predictions, actual_class_names)
        
        # ä¿å­˜ä¼šè¯æ€»ç»“
        summary = {
            'model_type': self.model_type,
            'best_val_acc': best_acc,
            'best_f1': best_f1,
            'test_acc': test_acc,
            'test_f1': test_f1,
            'total_epochs': len(self.training_history['train_loss']),
            'final_epoch': final_epoch,
            'num_classes': len(self.label_encoder),
            'actual_classes': actual_class_names,
            'device': str(self.device),
            'use_class_weights': True
        }
        self.persistence.save_session_summary(summary)
        
        # åˆ›å»ºREADME
        training_info = {
            'model_type': self.model_type,
            'epochs': len(self.training_history['train_loss']),
            'batch_size': 32,
            'learning_rate': 0.0005,
            'best_val_acc': best_acc,
            'best_f1': best_f1,
            'test_acc': test_acc,
            'test_f1': test_f1,
            'num_classes': len(self.label_encoder),
            'use_class_weights': True
        }
        self.persistence.create_readme(training_info)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ”¹è¿›çš„Intel Arc GPU è®­ç»ƒå™¨")
    parser.add_argument("--model", type=str, default="textcnn",
                       choices=["textcnn", "fasttext"], help="æ¨¡å‹ç±»å‹")
    parser.add_argument("--data", type=str, default="data/processed_logs_improved.csv", 
                       help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=30, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--patience", type=int, default=8, help="æ—©åœè€å¿ƒå€¼")
    parser.add_argument("--batch_size", type=int, default=32, help="æ‰¹æ¬¡å¤§å°")
    
    args = parser.parse_args()
    
    logger.info("ğŸ¯ æ”¹è¿›çš„Intel Arc GPU è®­ç»ƒå™¨")
    
    trainer = ImprovedTrainer(model_type=args.model)
    trainer.train(args.data, args.epochs, args.patience, args.batch_size)


if __name__ == "__main__":
    main() 