#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†é˜¶æ®µè®­ç»ƒè„šæœ¬
å…ˆä½¿ç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯ï¼Œå†ä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
"""

import os
import sys
import subprocess
import logging
import time
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒ"""
    logger.info("ğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    try:
        result = subprocess.run([sys.executable, "quick_start.py"], 
                              capture_output=True, text=True, check=True)
        logger.info("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False


def prepare_staged_data():
    """å‡†å¤‡åˆ†é˜¶æ®µæ•°æ®"""
    logger.info("ğŸ“‚ å‡†å¤‡åˆ†é˜¶æ®µè®­ç»ƒæ•°æ®...")
    try:
        result = subprocess.run([sys.executable, "scripts/prepare_data_staged.py"], 
                              capture_output=True, text=True, check=True)
        logger.info("âœ… åˆ†é˜¶æ®µæ•°æ®å‡†å¤‡å®Œæˆ")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False


def run_small_dataset_training():
    """è¿è¡Œå°æ•°æ®é›†è®­ç»ƒï¼ˆå¿«é€ŸéªŒè¯ï¼‰"""
    logger.info("ğŸ”¬ å¼€å§‹å°æ•°æ®é›†è®­ç»ƒï¼ˆå¿«é€ŸéªŒè¯ï¼‰...")
    
    small_data_path = "data/processed_logs_small.csv"
    if not os.path.exists(small_data_path):
        logger.error(f"âŒ å°æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {small_data_path}")
        return False
    
    # å°æ•°æ®é›†è®­ç»ƒå‚æ•°
    cmd = [
        sys.executable, "scripts/train.py",
        "--model", "textcnn",
        "--data", small_data_path,
        "--epochs", "3",  # è¾ƒå°‘çš„epochç”¨äºå¿«é€ŸéªŒè¯
        "--save_dir", "results/models_small"
    ]
    
    try:
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        start_time = time.time()
        result = subprocess.run(cmd, check=True)
        end_time = time.time()
        
        training_time = end_time - start_time
        logger.info(f"âœ… å°æ•°æ®é›†è®­ç»ƒå®Œæˆï¼è€—æ—¶: {training_time:.1f} ç§’")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ å°æ•°æ®é›†è®­ç»ƒå¤±è´¥: {e}")
        return False


def run_large_dataset_training():
    """è¿è¡Œå®Œæ•´æ•°æ®é›†è®­ç»ƒ"""
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®é›†è®­ç»ƒ...")
    
    large_data_path = "data/processed_logs_large.csv"
    if not os.path.exists(large_data_path):
        logger.error(f"âŒ å®Œæ•´æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {large_data_path}")
        return False
    
    # å®Œæ•´æ•°æ®é›†è®­ç»ƒå‚æ•°
    cmd = [
        sys.executable, "scripts/train.py",
        "--model", "textcnn",
        "--data", large_data_path,
        "--epochs", "10",  # å®Œæ•´çš„epochç”¨äºæ­£å¼è®­ç»ƒ
        "--save_dir", "results/models_large"
    ]
    
    try:
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        start_time = time.time()
        result = subprocess.run(cmd, check=True)
        end_time = time.time()
        
        training_time = end_time - start_time
        logger.info(f"âœ… å®Œæ•´æ•°æ®é›†è®­ç»ƒå®Œæˆï¼è€—æ—¶: {training_time:.1f} ç§’")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ å®Œæ•´æ•°æ®é›†è®­ç»ƒå¤±è´¥: {e}")
        return False


def compare_results():
    """æ¯”è¾ƒè®­ç»ƒç»“æœ"""
    logger.info("ğŸ“Š æ¯”è¾ƒè®­ç»ƒç»“æœ...")
    
    small_model_dir = "results/models_small"
    large_model_dir = "results/models_large"
    
    if os.path.exists(small_model_dir) and os.path.exists(large_model_dir):
        logger.info("âœ… ä¸¤ä¸ªé˜¶æ®µçš„æ¨¡å‹éƒ½å·²ä¿å­˜")
        logger.info(f"   å°æ•°æ®é›†æ¨¡å‹: {small_model_dir}")
        logger.info(f"   å®Œæ•´æ•°æ®é›†æ¨¡å‹: {large_model_dir}")
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æ¨¡å‹æ–‡ä»¶ç¼ºå¤±")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="åˆ†é˜¶æ®µè®­ç»ƒå·¥å…·")
    parser.add_argument("--skip_small", action="store_true", 
                       help="è·³è¿‡å°æ•°æ®é›†è®­ç»ƒ")
    parser.add_argument("--skip_large", action="store_true", 
                       help="è·³è¿‡å®Œæ•´æ•°æ®é›†è®­ç»ƒ")
    parser.add_argument("--skip_data_prep", action="store_true", 
                       help="è·³è¿‡æ•°æ®å‡†å¤‡")
    
    args = parser.parse_args()
    
    logger.info("ğŸ¯ Intel Arc GPU åˆ†é˜¶æ®µè®­ç»ƒ")
    logger.info("=" * 60)
    logger.info("ğŸ“‹ è®­ç»ƒè®¡åˆ’:")
    logger.info("   é˜¶æ®µ1: å°æ•°æ®é›†å¿«é€ŸéªŒè¯ (3 epochs)")
    logger.info("   é˜¶æ®µ2: å®Œæ•´æ•°æ®é›†æ­£å¼è®­ç»ƒ (10 epochs)")
    logger.info("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        logger.error("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œé€€å‡º")
        return
    
    # å‡†å¤‡æ•°æ®
    if not args.skip_data_prep:
        if not prepare_staged_data():
            logger.error("âŒ æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡º")
            return
    else:
        logger.info("â­ï¸ è·³è¿‡æ•°æ®å‡†å¤‡")
    
    # é˜¶æ®µ1: å°æ•°æ®é›†è®­ç»ƒ
    if not args.skip_small:
        logger.info("\n" + "="*60)
        logger.info("ğŸ”¬ é˜¶æ®µ1: å°æ•°æ®é›†å¿«é€ŸéªŒè¯")
        logger.info("="*60)
        
        if not run_small_dataset_training():
            logger.error("âŒ å°æ•°æ®é›†è®­ç»ƒå¤±è´¥")
            return
    else:
        logger.info("â­ï¸ è·³è¿‡å°æ•°æ®é›†è®­ç»ƒ")
    
    # é˜¶æ®µ2: å®Œæ•´æ•°æ®é›†è®­ç»ƒ
    if not args.skip_large:
        logger.info("\n" + "="*60)
        logger.info("ğŸš€ é˜¶æ®µ2: å®Œæ•´æ•°æ®é›†æ­£å¼è®­ç»ƒ")
        logger.info("="*60)
        
        if not run_large_dataset_training():
            logger.error("âŒ å®Œæ•´æ•°æ®é›†è®­ç»ƒå¤±è´¥")
            return
    else:
        logger.info("â­ï¸ è·³è¿‡å®Œæ•´æ•°æ®é›†è®­ç»ƒ")
    
    # æ¯”è¾ƒç»“æœ
    compare_results()
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ‰ åˆ†é˜¶æ®µè®­ç»ƒå®Œæˆï¼")
    logger.info("ğŸ“ æ¨¡å‹ä¿å­˜åœ¨:")
    logger.info("   results/models_small/  (å°æ•°æ®é›†æ¨¡å‹)")
    logger.info("   results/models_large/  (å®Œæ•´æ•°æ®é›†æ¨¡å‹)")
    logger.info("="*60)


if __name__ == "__main__":
    main() 