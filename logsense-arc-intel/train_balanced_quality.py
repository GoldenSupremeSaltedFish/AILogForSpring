#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºå¹³è¡¡æ•°æ®çš„è´¨é‡è®­ç»ƒè„šæœ¬
"""

import argparse
import torch
import torch.nn as nn
import logging
import os
from datetime import datetime
import numpy as np
from collections import Counter
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.textcnn import TextCNN
from utils.persistence_manager import TrainingPersistenceManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class BalancedQualityDataset(torch.utils.data.Dataset):
    """åŸºäºå¹³è¡¡æ•°æ®è´¨é‡çš„æ•°æ®é›†"""
    
    def __init__(self, texts: list, labels: list, features: dict = None, max_length: int = 128, vocab_size: int = 8000):
        self.texts = texts
        self.labels = labels
        self.features = features
        self.max_length = max_length
        self.vocab_size = vocab_size
        self.vocab = self._build_vocab()
        logger.info(f" è¯æ±‡è¡¨å¤§å°: {len(self.vocab)}")
    
    def _build_vocab(self):
        """æ„å»ºè¯æ±‡è¡¨"""
        word_counts = Counter()
        for text in self.texts:
            words = text.lower().split()
            word_counts.update(words)
        
        vocab = {'<PAD>': 0, '<UNK>': 1}
        for word, count in word_counts.most_common(self.vocab_size - 2):
            if count >= 2:
                vocab[word] = len(vocab)
        return vocab
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx]).lower()
        label = self.labels[idx]
        
        words = text.split()[:self.max_length]
        token_ids = []
        
        for word in words:
            if word in self.vocab:
                token_ids.append(self.vocab[word])
            else:
                token_ids.append(self.vocab['<UNK>'])
        
        if len(token_ids) < self.max_length:
            token_ids += [self.vocab['<PAD>']] * (self.max_length - len(token_ids))
        else:
            token_ids = token_ids[:self.max_length]
        
        return {
            'input_ids': torch.tensor(token_ids, dtype=torch.long),
            'labels': torch.tensor(label, dtype=torch.long)
        }


class BalancedQualityTrainer:
    """åŸºäºå¹³è¡¡æ•°æ®çš„è´¨é‡è®­ç»ƒå™¨"""
    
    def __init__(self):
        if torch.xpu.is_available():
            self.device = torch.device("xpu:0")
            logger.info("âœ… ä½¿ç”¨Intel XPU GPUåŠ é€Ÿ")
        else:
            self.device = torch.device("cpu")
            logger.warning("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒ")
    
    def load_balanced_data(self, data_path: str):
        """åŠ è½½å¹³è¡¡æ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½å¹³è¡¡æ•°æ®: {data_path}")
        df = pd.read_csv(data_path)
        logger.info(f"ğŸ“Š å¹³è¡¡æ•°æ®: {len(df)} æ¡è®°å½•")
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        required_cols = ['category', 'cleaned_log', 'log_level', 'error_codes', 'paths']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
        
        # æ•°æ®æ¸…æ´—
        df_cleaned = df.dropna(subset=['cleaned_log', 'category'])
        df_cleaned = df_cleaned[df_cleaned['cleaned_log'].str.strip() != '']
        
        # è¿‡æ»¤æ ·æœ¬å¤ªå°‘çš„ç±»åˆ«
        category_counts = df_cleaned['category'].value_counts()
        min_samples = 10
        valid_categories = category_counts[category_counts >= min_samples].index.tolist()
        df_filtered = df_cleaned[df_cleaned['category'].isin(valid_categories)]
        
        logger.info(f"ğŸ“Š è¿‡æ»¤åæ•°æ®: {len(df_filtered)} æ¡è®°å½•")
        logger.info(f" æœ‰æ•ˆç±»åˆ«: {len(valid_categories)} ä¸ª")
        
        # æ ‡ç­¾ç¼–ç 
        from sklearn.preprocessing import LabelEncoder
        label_encoder = LabelEncoder()
        labels = label_encoder.fit_transform(df_filtered['category'])
        
        texts = df_filtered['cleaned_log'].tolist()
        
        # åˆ†ææ•°æ®åˆ†å¸ƒ
        self._analyze_data_distribution(labels, label_encoder.classes_)
        
        # åˆ†æç‰¹å¾åˆ†å¸ƒ
        self._analyze_feature_distribution(df_filtered)
        
        return texts, labels, label_encoder, df_filtered
    
    def _analyze_data_distribution(self, labels, class_names):
        """åˆ†ææ•°æ®åˆ†å¸ƒ"""
        unique, counts = np.unique(labels, return_counts=True)
        total = len(labels)
        
        logger.info("ğŸ“Š æ•°æ®åˆ†å¸ƒ:")
        for i, (label, count) in enumerate(zip(unique, counts)):
            percentage = (count / total) * 100
            logger.info(f"  {class_names[label]}: {count} æ¡ ({percentage:.1f}%)")
        
        # è®¡ç®—ä¸å¹³è¡¡æ¯”ä¾‹
        max_count = counts.max()
        min_count = counts.min()
        imbalance_ratio = max_count / min_count
        logger.info(f"ğŸ“ˆ æ•°æ®ä¸å¹³è¡¡æ¯”ä¾‹: {imbalance_ratio:.2f}:1")
    
    def _analyze_feature_distribution(self, df):
        """åˆ†æç‰¹å¾åˆ†å¸ƒ"""
        logger.info("ğŸ” ç‰¹å¾åˆ†å¸ƒåˆ†æ:")
        
        # æ—¥å¿—çº§åˆ«åˆ†å¸ƒ
        level_counts = df['log_level'].value_counts()
        logger.info("ğŸ“Š æ—¥å¿—çº§åˆ«åˆ†å¸ƒ:")
        for level, count in level_counts.items():
            percentage = (count / len(df)) * 100
            logger.info(f"  {level}: {count} æ¡ ({percentage:.1f}%)")
        
        # é”™è¯¯ç åˆ†å¸ƒ
        error_codes_count = (df['error_codes'] != '').sum()
        error_codes_percentage = (error_codes_count / len(df)) * 100
        logger.info(f"ğŸ” åŒ…å«é”™è¯¯ç : {error_codes_count} æ¡ ({error_codes_percentage:.1f}%)")
        
        # è·¯å¾„åˆ†å¸ƒ
        paths_count = (df['paths'] != '').sum()
        paths_percentage = (paths_count / len(df)) * 100
        logger.info(f"ğŸ“ åŒ…å«è·¯å¾„: {paths_count} æ¡ ({paths_percentage:.1f}%)")
    
    def train_model(self, model, train_loader, val_loader, epochs=15, model_name="BalancedQualityModel"):
        """è®­ç»ƒæ¨¡å‹"""
        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒ {model_name}")
        
        model.to(self.device)
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3)
        
        best_f1 = 0
        best_acc = 0
        patience = 5
        patience_counter = 0
        
        train_losses = []
        val_losses = []
        train_accs = []
        val_accs = []
        val_f1s = []
        
        for epoch in range(epochs):
            # è®­ç»ƒ
            model.train()
            train_loss = 0
            train_correct = 0
            train_total = 0
            
            for batch in train_loader:
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                optimizer.zero_grad()
                outputs = model(input_ids)
                loss = criterion(outputs, labels)
                loss.backward()
                
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()
            
            train_acc = 100 * train_correct / train_total
            train_losses.append(train_loss / len(train_loader))
            train_accs.append(train_acc)
            
            # éªŒè¯
            model.eval()
            val_loss = 0
            val_correct = 0
            val_total = 0
            all_predictions = []
            all_labels = []
            
            with torch.no_grad():
                for batch in val_loader:
                    input_ids = batch['input_ids'].to(self.device)
                    labels = batch['labels'].to(self.device)
                    
                    outputs = model(input_ids)
                    loss = criterion(outputs, labels)
                    
                    val_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    val_total += labels.size(0)
                    val_correct += (predicted == labels).sum().item()
                    
                    all_predictions.extend(predicted.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())
            
            val_acc = 100 * val_correct / val_total
            val_f1 = f1_score(all_labels, all_predictions, average='weighted')
            
            val_losses.append(val_loss / len(val_loader))
            val_accs.append(val_acc)
            val_f1s.append(val_f1)
            
            logger.info(f"ğŸ“ˆ Epoch {epoch+1}/{epochs}")
            logger.info(f"   è®­ç»ƒ: æŸå¤±={train_losses[-1]:.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
            logger.info(f"   éªŒè¯: æŸå¤±={val_losses[-1]:.4f}, å‡†ç¡®ç‡={val_acc:.2f}%, F1={val_f1:.4f}")
            
            # æ—©åœ
            if val_f1 > best_f1:
                best_f1 = val_f1
                best_acc = val_acc
                patience_counter = 0
            else:
                patience_counter += 1
            
            scheduler.step(val_f1)
            
            if patience_counter >= patience:
                logger.info(f"â³ æ—©åœè§¦å‘ - {patience} è½®æœªæ”¹å–„")
                break
        
        # è¿”å›è®­ç»ƒå†å²
        history = {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'train_accs': train_accs,
            'val_accs': val_accs,
            'val_f1s': val_f1s
        }
        
        return best_acc, best_f1, history
    
    def train_balanced_quality(self, data_path: str, epochs: int = 15):
        """åŸºäºå¹³è¡¡æ•°æ®çš„è´¨é‡è®­ç»ƒ"""
        logger.info("ğŸ¯ åŸºäºå¹³è¡¡æ•°æ®çš„è´¨é‡è®­ç»ƒ")
        
        # åŠ è½½å¹³è¡¡æ•°æ®
        texts, labels, label_encoder, df_balanced = self.load_balanced_data(data_path)
        
        # æ•°æ®åˆ†å‰²
        train_texts, val_texts, train_labels, val_labels = train_test_split(
            texts, labels, test_size=0.2, stratify=labels, random_state=42
        )
        
        logger.info(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
        logger.info(f"   è®­ç»ƒé›†: {len(train_texts)} æ¡")
        logger.info(f"   éªŒè¯é›†: {len(val_texts)} æ¡")
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = BalancedQualityDataset(train_texts, train_labels)
        val_dataset = BalancedQualityDataset(val_texts, val_labels)
        
        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)
        
        num_classes = len(label_encoder.classes_)
        logger.info(f"ğŸ“Š ç±»åˆ«æ•°: {num_classes}")
        
        # æ¨¡å‹é…ç½®
        model_config = {
            'vocab_size': 8000,
            'embed_dim': 128,
            'num_classes': num_classes,
            'filter_sizes': [3, 4, 5],
            'num_filters': 128,
            'dropout': 0.5
        }
        
        # è®­ç»ƒæ¨¡å‹
        logger.info("ğŸ” è®­ç»ƒåŸºäºå¹³è¡¡æ•°æ®çš„TextCNN")
        model = TextCNN(**model_config)
        best_acc, best_f1, history = self.train_model(
            model, train_loader, val_loader, epochs, "BalancedQualityTextCNN"
        )
        
        logger.info("ğŸ“Š è®­ç»ƒç»“æœ:")
        logger.info(f"  æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
        logger.info(f"  æœ€ä½³F1åˆ†æ•°: {best_f1:.4f}")
        
        # ä¿å­˜ç»“æœ
        self._save_results(model, label_encoder, history, best_acc, best_f1, df_balanced)
        
        return model, label_encoder, history
    
    def _save_results(self, model, label_encoder, history, best_acc, best_f1, df_balanced):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        # åˆ›å»ºæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜æ¨¡å‹
        model_path = f"results/models/balanced_quality_model_{timestamp}.pth"
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        
        torch.save({
            'model_state_dict': model.state_dict(),
            'model_config': model.get_config(),
            'label_encoder': label_encoder,
            'best_acc': best_acc,
            'best_f1': best_f1,
            'timestamp': timestamp
        }, model_path)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = f"results/history/balanced_quality_history_{timestamp}.json"
        os.makedirs(os.path.dirname(history_path), exist_ok=True)
        
        import json
        with open(history_path, 'w') as f:
            json.dump(history, f, indent=2)
        
        logger.info(f"ğŸ’¾ è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
        
        # ç”Ÿæˆè®­ç»ƒæ›²çº¿
        self._plot_training_curves(history, timestamp)
    
    def _plot_training_curves(self, history, timestamp):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(history['train_losses'], label='è®­ç»ƒæŸå¤±')
        axes[0, 0].plot(history['val_losses'], label='éªŒè¯æŸå¤±')
        axes[0, 0].set_title('æŸå¤±æ›²çº¿')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(history['train_accs'], label='è®­ç»ƒå‡†ç¡®ç‡')
        axes[0, 1].plot(history['val_accs'], label='éªŒè¯å‡†ç¡®ç‡')
        axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy (%)')
        axes[0, 1].legend()
        
        # F1åˆ†æ•°æ›²çº¿
        axes[1, 0].plot(history['val_f1s'], label='éªŒè¯F1åˆ†æ•°')
        axes[1, 0].set_title('F1åˆ†æ•°æ›²çº¿')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('F1 Score')
        axes[1, 0].legend()
        
        # è®­ç»ƒè¿›åº¦
        epochs = range(1, len(history['train_losses']) + 1)
        axes[1, 1].plot(epochs, history['train_losses'], 'b-', label='è®­ç»ƒæŸå¤±')
        axes[1, 1].plot(epochs, history['val_losses'], 'r-', label='éªŒè¯æŸå¤±')
        axes[1, 1].set_title('è®­ç»ƒè¿›åº¦')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Loss')
        axes[1, 1].legend()
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plot_path = f"results/plots/balanced_quality_training_{timestamp}.png"
        os.makedirs(os.path.dirname(plot_path), exist_ok=True)
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {plot_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åŸºäºå¹³è¡¡æ•°æ®çš„è´¨é‡è®­ç»ƒ')
    parser.add_argument('--data', type=str, default='data/processed_logs_advanced_enhanced.csv',
                       help='å¹³è¡¡æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--epochs', type=int, default=15, help='è®­ç»ƒè½®æ•°')
    
    args = parser.parse_args()
    
    trainer = BalancedQualityTrainer()
    model, label_encoder, history = trainer.train_balanced_quality(args.data, args.epochs)
    
    logger.info("âœ… åŸºäºå¹³è¡¡æ•°æ®çš„è´¨é‡è®­ç»ƒå®Œæˆ!")


if __name__ == "__main__":
    main() 