#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Intel Arc GPU è®­ç»ƒè„šæœ¬
"""

import argparse
import torch
import torch.nn as nn
import logging
import os
from datetime import datetime
from typing import Dict, Any

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import ModelFactory
from data import DataLoaderFactory, LogPreprocessor
from utils import ArcGPUDetector

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ArcTrainer:
    """Intel Arc GPU è®­ç»ƒå™¨"""

    def __init__(self, model_type: str = "textcnn"):
        self.model_type = model_type
        # ä¼˜å…ˆä½¿ç”¨XPUï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨CPU
        if torch.xpu.is_available():
            self.device = torch.device("xpu:0")
            logger.info("âœ… ä½¿ç”¨Intel XPU GPUåŠ é€Ÿ")
        else:
            self.device = torch.device("cpu")
            logger.warning("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒ")

        self.model = None
        self.label_encoder = None

        logger.info(f"ğŸ¯ åˆå§‹åŒ–è®­ç»ƒå™¨ - æ¨¡å‹ç±»å‹: {model_type}")
        logger.info(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {self.device}")

    def load_data(self, data_path: str):
        """åŠ è½½æ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")

        # åŠ è½½å’Œåˆ†å‰²æ•°æ®
        texts, labels, label_encoder = DataLoaderFactory.load_csv_data(data_path)
        train_texts, val_texts, test_texts, train_labels, val_labels, test_labels = \
            DataLoaderFactory.split_data(texts, labels)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = DataLoaderFactory.create_data_loaders(
            train_texts, val_texts, test_texts,
            train_labels, val_labels, test_labels
        )

        self.label_encoder = label_encoder
        logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ - ç±»åˆ«æ•°: {len(label_encoder)}")

        return train_loader, val_loader, test_loader

    def create_model(self, num_classes: int):
        """åˆ›å»ºæ¨¡å‹"""
        logger.info(f"ğŸ—ï¸ åˆ›å»ºæ¨¡å‹: {self.model_type}")

        model_config = ModelFactory.get_default_config(self.model_type)
        model_config['num_classes'] = num_classes

        self.model = ModelFactory.create_model(self.model_type, **model_config)
        self.model.to(self.device)

        param_count = self.model.count_parameters()
        logger.info(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ - å‚æ•°æ•°é‡: {param_count:,}")

    def train_epoch(self, train_loader, criterion, optimizer):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0

        for batch in train_loader:
            input_ids = batch['input_ids'].to(self.device)
            labels = batch['labels'].to(self.device)

            optimizer.zero_grad()
            outputs = self.model(input_ids)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        return total_loss / len(train_loader), 100 * correct / total

    def validate_epoch(self, val_loader, criterion):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)

                outputs = self.model(input_ids)
                loss = criterion(outputs, labels)

                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return total_loss / len(val_loader), 100 * correct / total

    def train(self, data_path: str, epochs: int = 10, save_dir: str = "results/models"):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒ")

        # æ£€æŸ¥GPUçŠ¶æ€
        if torch.xpu.is_available():
            logger.info(f"ğŸ–¥ï¸ ä½¿ç”¨Intel XPU GPU: {torch.xpu.get_device_name(0)}")
            logger.info(f"ğŸ’¾ GPUå†…å­˜: {torch.xpu.get_device_properties(0).total_memory / (1024**3):.1f} GB")
        else:
            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°Intel XPU GPUï¼Œä½¿ç”¨CPUè®­ç»ƒ")

        # åŠ è½½æ•°æ®
        train_loader, val_loader, test_loader = self.load_data(data_path)

        # åˆ›å»ºæ¨¡å‹
        num_classes = len(self.label_encoder)
        self.create_model(num_classes)

        # è®¾ç½®è®­ç»ƒç»„ä»¶
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)

        best_acc = 0

        for epoch in range(epochs):
            logger.info(f"ğŸ“ˆ Epoch {epoch+1}/{epochs}")

            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)

            # éªŒè¯
            val_loss, val_acc = self.validate_epoch(val_loader, criterion)

            logger.info(f"  è®­ç»ƒ: æŸå¤±={train_loss:.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
            logger.info(f"  éªŒè¯: æŸå¤±={val_loss:.4f}, å‡†ç¡®ç‡={val_acc:.2f}%")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                self.save_model(save_dir, "best")
                logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_acc:.2f}%)")

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.save_model(save_dir, "final")

        # æµ‹è¯•é›†è¯„ä¼°
        test_loss, test_acc = self.validate_epoch(test_loader, criterion)
        logger.info(f"ğŸ§ª æµ‹è¯•é›†: æŸå¤±={test_loss:.4f}, å‡†ç¡®ç‡={test_acc:.2f}%")

        logger.info(f"âœ… è®­ç»ƒå®Œæˆ - æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")

    def save_model(self, save_dir: str, suffix: str = ""):
        """ä¿å­˜æ¨¡å‹"""
        os.makedirs(save_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        model_path = os.path.join(save_dir, f"arc_gpu_model_{self.model_type}_{suffix}_{timestamp}.pth")
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'model_config': self.model.get_config(),
            'label_encoder': self.label_encoder
        }, model_path)

        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Intel Arc GPU è®­ç»ƒå™¨")
    parser.add_argument("--model", type=str, default="textcnn",
                       choices=["textcnn", "fasttext"], help="æ¨¡å‹ç±»å‹")
    parser.add_argument("--data", type=str, required=True, help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=10, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--save_dir", type=str, default="results/models", help="æ¨¡å‹ä¿å­˜ç›®å½•")

    args = parser.parse_args()

    logger.info("ğŸ¯ Intel Arc GPU è®­ç»ƒå™¨")

    trainer = ArcTrainer(model_type=args.model)
    trainer.train(args.data, args.epochs, args.save_dir)


if __name__ == "__main__":
    main() 