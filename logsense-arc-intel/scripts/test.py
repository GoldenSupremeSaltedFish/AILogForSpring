#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Intel Arc GPU æµ‹è¯•è„šæœ¬
"""

import argparse
import torch
import logging
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import ModelFactory
from utils import ArcGPUDetector

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    logger.info("ğŸ§ª æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    # æµ‹è¯•TextCNN
    try:
        textcnn = ModelFactory.create_model("textcnn", num_classes=5)
        logger.info("âœ… TextCNN åˆ›å»ºæˆåŠŸ")
        logger.info(f"   å‚æ•°æ•°é‡: {textcnn.count_parameters():,}")
    except Exception as e:
        logger.error(f"âŒ TextCNN åˆ›å»ºå¤±è´¥: {e}")
    
    # æµ‹è¯•FastText
    try:
        fasttext = ModelFactory.create_model("fasttext", num_classes=5)
        logger.info("âœ… FastText åˆ›å»ºæˆåŠŸ")
        logger.info(f"   å‚æ•°æ•°é‡: {fasttext.count_parameters():,}")
    except Exception as e:
        logger.error(f"âŒ FastText åˆ›å»ºå¤±è´¥: {e}")


def test_gpu_inference():
    """æµ‹è¯•GPUæ¨ç†"""
    logger.info("ğŸ§ª æµ‹è¯•GPUæ¨ç†...")
    
    device = ArcGPUDetector.get_device()
    logger.info(f"   ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = ModelFactory.create_model("textcnn", num_classes=5)
    model.to(device)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 4
    seq_len = 128
    test_input = torch.randint(0, 10000, (batch_size, seq_len)).to(device)
    
    try:
        with torch.no_grad():
            output = model(test_input)
            logger.info("âœ… GPUæ¨ç†æˆåŠŸ")
            logger.info(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
            logger.info(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
    except Exception as e:
        logger.error(f"âŒ GPUæ¨ç†å¤±è´¥: {e}")


def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    logger.info("ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        from data import DataLoaderFactory
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        import pandas as pd
        test_data = {
            'message': [
                'Error: Connection timeout',
                'Info: User login successful',
                'Warning: Disk space low',
                'Error: Database connection failed',
                'Info: Backup completed'
            ],
            'category': ['error', 'info', 'warning', 'error', 'info']
        }
        
        df = pd.DataFrame(test_data)
        df.to_csv('test_data.csv', index=False)
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        texts, labels, label_encoder = DataLoaderFactory.load_csv_data('test_data.csv')
        logger.info("âœ… æ•°æ®åŠ è½½æˆåŠŸ")
        logger.info(f"   æ–‡æœ¬æ•°é‡: {len(texts)}")
        logger.info(f"   æ ‡ç­¾æ•°é‡: {len(labels)}")
        logger.info(f"   ç±»åˆ«æ•°: {len(label_encoder)}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove('test_data.csv')
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Intel Arc GPU æµ‹è¯•å·¥å…·")
    parser.add_argument("--test", type=str, default="all", 
                       choices=["all", "model", "gpu", "data"], help="æµ‹è¯•ç±»å‹")
    
    args = parser.parse_args()
    
    logger.info("ğŸ¯ Intel Arc GPU æµ‹è¯•å·¥å…·")
    logger.info("=" * 50)
    
    if args.test in ["all", "model"]:
        test_model_creation()
        print()
    
    if args.test in ["all", "gpu"]:
        test_gpu_inference()
        print()
    
    if args.test in ["all", "data"]:
        test_data_loading()
        print()
    
    logger.info("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main() 