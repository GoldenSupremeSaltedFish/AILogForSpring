#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§æ•°æ®å¹³è¡¡è„šæœ¬ - é’ˆå¯¹Attentionæœºåˆ¶ä¼˜åŒ–
"""

import pandas as pd
import numpy as np
import logging
from collections import Counter
from sklearn.utils import resample
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AdvancedDataBalancer:
    """é«˜çº§æ•°æ®å¹³è¡¡å™¨"""
    
    def __init__(self, target_samples_per_class=1000):
        self.target_samples_per_class = target_samples_per_class
    
    def load_and_analyze_data(self, data_path: str):
        """åŠ è½½å¹¶åˆ†ææ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
        df = pd.read_csv(data_path)
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
        
        # æ•°æ®æ¸…æ´—
        df_cleaned = df.dropna(subset=['original_log', 'category'])
        df_cleaned = df_cleaned[df_cleaned['original_log'].str.strip() != '']
        
        # åˆ†æç±»åˆ«åˆ†å¸ƒ
        category_counts = df_cleaned['category'].value_counts()
        logger.info("ğŸ“Š åŸå§‹æ•°æ®åˆ†å¸ƒ:")
        for category, count in category_counts.items():
            percentage = (count / len(df_cleaned)) * 100
            logger.info(f"  {category}: {count} æ¡ ({percentage:.1f}%)")
        
        return df_cleaned, category_counts
    
    def balance_data(self, df: pd.DataFrame, category_counts: pd.Series):
        """å¹³è¡¡æ•°æ®"""
        logger.info(f"ğŸ¯ ç›®æ ‡æ¯ç±»æ ·æœ¬æ•°: {self.target_samples_per_class}")
        
        balanced_dfs = []
        
        for category in category_counts.index:
            category_df = df[df['category'] == category].copy()
            current_count = len(category_df)
            
            logger.info(f"ğŸ“Š å¤„ç†ç±»åˆ«: {category} (å½“å‰: {current_count} æ¡)")
            
            if current_count < self.target_samples_per_class:
                # ä¸Šé‡‡æ ·
                if current_count > 0:
                    # ä½¿ç”¨é‡å¤é‡‡æ ·
                    oversampled = resample(
                        category_df,
                        n_samples=self.target_samples_per_class,
                        replace=True,
                        random_state=42
                    )
                    logger.info(f"  âœ… ä¸Šé‡‡æ ·åˆ° {self.target_samples_per_class} æ¡")
                    balanced_dfs.append(oversampled)
                else:
                    logger.warning(f"  âš ï¸ ç±»åˆ« {category} æ— æ ·æœ¬ï¼Œè·³è¿‡")
                    continue
            elif current_count > self.target_samples_per_class:
                # ä¸‹é‡‡æ ·
                undersampled = resample(
                    category_df,
                    n_samples=self.target_samples_per_class,
                    replace=False,
                    random_state=42
                )
                logger.info(f"  âœ… ä¸‹é‡‡æ ·åˆ° {self.target_samples_per_class} æ¡")
                balanced_dfs.append(undersampled)
            else:
                # ä¿æŒåŸæ ·
                logger.info(f"  âœ… ä¿æŒ {current_count} æ¡")
                balanced_dfs.append(category_df)
        
        # åˆå¹¶æ‰€æœ‰ç±»åˆ«
        balanced_df = pd.concat(balanced_dfs, ignore_index=True)
        
        # æ‰“ä¹±æ•°æ®
        balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)
        
        logger.info(f"ğŸ“Š å¹³è¡¡åæ•°æ®: {len(balanced_df)} æ¡è®°å½•")
        
        # éªŒè¯å¹³è¡¡ç»“æœ
        final_counts = balanced_df['category'].value_counts()
        logger.info("ğŸ“Š å¹³è¡¡ååˆ†å¸ƒ:")
        for category, count in final_counts.items():
            percentage = (count / len(balanced_df)) * 100
            logger.info(f"  {category}: {count} æ¡ ({percentage:.1f}%)")
        
        return balanced_df
    
    def create_attention_optimized_data(self, data_path: str, output_path: str):
        """åˆ›å»ºé’ˆå¯¹Attentionä¼˜åŒ–çš„æ•°æ®"""
        logger.info("ğŸš€ å¼€å§‹åˆ›å»ºAttentionä¼˜åŒ–æ•°æ®")
        
        # åŠ è½½æ•°æ®
        df, category_counts = self.load_and_analyze_data(data_path)
        
        # å¹³è¡¡æ•°æ®
        balanced_df = self.balance_data(df, category_counts)
        
        # ä¿å­˜ç»“æœ
        balanced_df.to_csv(output_path, index=False)
        logger.info(f"ğŸ’¾ ä¿å­˜åˆ°: {output_path}")
        
        return balanced_df


def main():
    """ä¸»å‡½æ•°"""
    balancer = AdvancedDataBalancer(target_samples_per_class=1000)
    
    input_path = "data/processed_logs_final_cleaned.csv"
    output_path = "data/processed_logs_balanced_attention.csv"
    
    balanced_df = balancer.create_attention_optimized_data(input_path, output_path)
    
    logger.info("âœ… æ•°æ®å¹³è¡¡å®Œæˆ!")


if __name__ == "__main__":
    main() 