#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸¦æŒä¹…åŒ–åŠŸèƒ½çš„æ”¹è¿›Intel Arc GPU è®­ç»ƒè„šæœ¬
"""

import argparse
import torch
import torch.nn as nn
import logging
import os
from datetime import datetime
from typing import Dict, Any, List
import numpy as np
from collections import Counter
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, confusion_matrix, classification_report

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import ModelFactory
from data import LogPreprocessor
from utils import create_persistence_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ImprovedLogDataset(torch.utils.data.Dataset):
    """æ”¹è¿›çš„æ—¥å¿—æ•°æ®é›† - è§£å†³Tokenizeré—®é¢˜"""
    
    def __init__(self, texts: list, labels: list, max_length: int = 128, vocab_size: int = 5000):
        self.texts = texts
        self.labels = labels
        self.max_length = max_length
        self.vocab_size = vocab_size
        
        # æ„å»ºè¯æ±‡è¡¨
        self.vocab = self._build_vocab()
        logger.info(f" è¯æ±‡è¡¨å¤§å°: {len(self.vocab)}")
    
    def _build_vocab(self):
        """æ„å»ºè¯æ±‡è¡¨"""
        word_counts = Counter()
        
        # ç»Ÿè®¡æ‰€æœ‰è¯æ±‡
        for text in self.texts:
            words = text.lower().split()
            word_counts.update(words)
        
        # é€‰æ‹©æœ€å¸¸è§çš„è¯æ±‡
        vocab = {'<PAD>': 0, '<UNK>': 1}
        for word, count in word_counts.most_common(self.vocab_size - 2):
            if count >= 2:  # è‡³å°‘å‡ºç°2æ¬¡
                vocab[word] = len(vocab)
        
        return vocab
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx]).lower()
        label = self.labels[idx]
        
        # æ”¹è¿›çš„åˆ†è¯å¤„ç†
        words = text.split()[:self.max_length]
        token_ids = []
        
        for word in words:
            if word in self.vocab:
                token_ids.append(self.vocab[word])
            else:
                token_ids.append(self.vocab['<UNK>'])
        
        # è¡¥é½åˆ°å›ºå®šé•¿åº¦
        if len(token_ids) < self.max_length:
            token_ids += [self.vocab['<PAD>']] * (self.max_length - len(token_ids))
        else:
            token_ids = token_ids[:self.max_length]
        
        return {
            'input_ids': torch.tensor(token_ids, dtype=torch.long),
            'labels': torch.tensor(label, dtype=torch.long)
        }


class PersistentArcTrainer:
    """å¸¦æŒä¹…åŒ–åŠŸèƒ½çš„Intel Arc GPU è®­ç»ƒå™¨"""

    def __init__(self, model_type: str = "textcnn"):
        self.model_type = model_type
        # ä¼˜å…ˆä½¿ç”¨XPUï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨CPU
        if torch.xpu.is_available():
            self.device = torch.device("xpu:0")
            logger.info("âœ… ä½¿ç”¨Intel XPU GPUåŠ é€Ÿ")
        else:
            self.device = torch.device("cpu")
            logger.warning("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒ")
        
        self.model = None
        self.label_encoder = None
        self.vocab = None
        
        # åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨
        self.persistence_manager = create_persistence_manager()
        
        # è®­ç»ƒå†å²è®°å½•
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'val_f1': [],
            'learning_rate': []
        }

        logger.info(f" åˆå§‹åŒ–æŒä¹…åŒ–è®­ç»ƒå™¨ - æ¨¡å‹ç±»å‹: {model_type}")
        logger.info(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {self.device}")

    def load_and_clean_data(self, data_path: str):
        """åŠ è½½å’Œæ¸…æ´—æ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")

        # åŠ è½½æ•°æ®
        df = pd.read_csv(data_path)
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        logger.info("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
        logger.info(f"   ç©ºå€¼æ•°é‡: {df.isnull().sum().sum()}")
        logger.info(f"   é‡å¤æ ·æœ¬: {df.duplicated().sum()}")
        
        # æ£€æŸ¥åˆ—å
        logger.info(f"   åˆ—å: {list(df.columns)}")
        
        # æ‰¾åˆ°æ­£ç¡®çš„æ–‡æœ¬åˆ—å’Œæ ‡ç­¾åˆ—
        text_column = None
        label_column = None
        
        # å°è¯•æ‰¾åˆ°æ–‡æœ¬åˆ—
        possible_text_cols = ['original_log', 'message', 'content', 'text']
        for col in possible_text_cols:
            if col in df.columns:
                text_column = col
                break
        
        if not text_column:
            logger.error("âŒ æœªæ‰¾åˆ°åˆé€‚çš„æ–‡æœ¬åˆ—")
            return None, None, None
        
        # æ ‡ç­¾åˆ—
        label_column = 'category'
        
        logger.info(f"ğŸ” ä½¿ç”¨æ–‡æœ¬åˆ—: {text_column}")
        logger.info(f"ğŸ” ä½¿ç”¨æ ‡ç­¾åˆ—: {label_column}")
        
        # æ•°æ®æ¸…æ´—
        df_cleaned = df.dropna(subset=[text_column, label_column])
        df_cleaned = df_cleaned[df_cleaned[label_column] != 'other']
        
        logger.info(f" æ¸…æ´—åæ•°æ®: {len(df_cleaned)} æ¡è®°å½•")
        
        # åˆ†ææ•°æ®åˆ†å¸ƒ
        texts = df_cleaned[text_column].fillna('').tolist()
        labels = df_cleaned[label_column].tolist()
        
        data_info = self._analyze_data_distribution(labels)
        
        # ä¿å­˜æ•°æ®ä¿¡æ¯
        self.persistence_manager.save_data_info(data_info)
        
        # å¤åˆ¶æ•°æ®æ–‡ä»¶
        self.persistence_manager.copy_data_files(data_path)
        
        # æ ‡ç­¾ç¼–ç 
        unique_labels = sorted(list(set(labels)))
        label_to_id = {label: idx for idx, label in enumerate(unique_labels)}
        encoded_labels = [label_to_id[label] for label in labels]
        
        self.label_encoder = {idx: label for label, idx in label_to_id.items()}
        
        logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ - ç±»åˆ«æ•°: {len(self.label_encoder)}")
        
        return texts, encoded_labels, self.label_encoder

    def _analyze_data_distribution(self, labels):
        """åˆ†ææ•°æ®åˆ†å¸ƒ"""
        label_counts = Counter(labels)
        total = len(labels)
        
        logger.info("ğŸ“Š æ•°æ®åˆ†å¸ƒåˆ†æ:")
        distribution = {}
        for label, count in label_counts.items():
            percentage = (count / total) * 100
            distribution[label] = {'count': count, 'percentage': percentage}
            logger.info(f"   {label}: {count} æ¡ ({percentage:.1f}%)")
        
        # æ£€æŸ¥æ•°æ®ä¸å¹³è¡¡
        max_count = max(label_counts.values())
        min_count = min(label_counts.values())
        imbalance_ratio = max_count / min_count
        
        if imbalance_ratio > 2:
            logger.warning(f"âš ï¸ æ•°æ®ä¸¥é‡ä¸å¹³è¡¡ (æ¯”ä¾‹: {imbalance_ratio:.1f}:1)")
        else:
            logger.info("âœ… æ•°æ®åˆ†å¸ƒç›¸å¯¹å‡è¡¡")
        
        return {
            'total_samples': total,
            'label_distribution': distribution,
            'imbalance_ratio': imbalance_ratio,
            'num_classes': len(label_counts)
        }

    def create_improved_model(self, num_classes: int):
        """åˆ›å»ºæ”¹è¿›çš„æ¨¡å‹ - å‡å°‘å¤æ‚åº¦"""
        logger.info(f"ğŸ—ï¸ åˆ›å»ºæ”¹è¿›æ¨¡å‹: {self.model_type}")

        # ä½¿ç”¨æ›´å°çš„æ¨¡å‹é…ç½®
        model_config = {
            'vocab_size': 5000,  # å‡å°‘è¯æ±‡è¡¨å¤§å°
            'embed_dim': 64,      # å‡å°‘åµŒå…¥ç»´åº¦
            'num_classes': num_classes,
            'filter_sizes': [3, 4, 5],
            'num_filters': 64,    # å‡å°‘å·ç§¯æ ¸æ•°é‡
            'dropout': 0.7        # å¢åŠ Dropout
        }

        self.model = ModelFactory.create_model(self.model_type, **model_config)
        self.model.to(self.device)

        param_count = self.model.count_parameters()
        logger.info(f"âœ… æ”¹è¿›æ¨¡å‹åˆ›å»ºæˆåŠŸ - å‚æ•°æ•°é‡: {param_count:,}")
        logger.info(f"ğŸ“Š å‚æ•°/æ ·æœ¬æ¯”: {param_count / 3288:.1f}:1")
        
        return model_config

    def train_epoch(self, train_loader, criterion, optimizer, scheduler=None):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0

        for batch in train_loader:
            input_ids = batch['input_ids'].to(self.device)
            labels = batch['labels'].to(self.device)

            optimizer.zero_grad()
            outputs = self.model(input_ids)
            loss = criterion(outputs, labels)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            if scheduler:
                scheduler.step()

            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        return total_loss / len(train_loader), 100 * correct / total

    def validate_epoch(self, val_loader, criterion):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        all_predictions = []
        all_labels = []

        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)

                outputs = self.model(input_ids)
                loss = criterion(outputs, labels)

                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        # è®¡ç®—F1åˆ†æ•°
        f1 = f1_score(all_labels, all_predictions, average='weighted')
        
        return total_loss / len(val_loader), 100 * correct / total, f1, all_predictions, all_labels

    def train_with_persistence(self, data_path: str, epochs: int = 20, 
                             patience: int = 5, batch_size: int = 16):
        """å¸¦æŒä¹…åŒ–çš„è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹æŒä¹…åŒ–è®­ç»ƒ")

        # æ£€æŸ¥GPUçŠ¶æ€
        if torch.xpu.is_available():
            logger.info(f"ğŸ–¥ï¸ ä½¿ç”¨Intel XPU GPU: {torch.xpu.get_device_name(0)}")
            logger.info(f"ğŸ’¾ GPUå†…å­˜: {torch.xpu.get_device_properties(0).total_memory / (1024**3):.1f} GB")
        else:
            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°Intel XPU GPUï¼Œä½¿ç”¨CPUè®­ç»ƒ")

        # åŠ è½½å’Œæ¸…æ´—æ•°æ®
        texts, labels, label_encoder = self.load_and_clean_data(data_path)
        if texts is None:
            logger.error("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return

        # ä½¿ç”¨Stratified Split
        train_texts, val_texts, train_labels, val_labels = train_test_split(
            texts, labels, test_size=0.2, stratify=labels, random_state=42
        )
        
        # è¿›ä¸€æ­¥åˆ†å‰²éªŒè¯é›†
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            train_texts, train_labels, test_size=0.2, stratify=train_labels, random_state=42
        )

        logger.info(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
        logger.info(f"   è®­ç»ƒé›†: {len(train_texts)} æ¡")
        logger.info(f"   éªŒè¯é›†: {len(val_texts)} æ¡")
        logger.info(f"   æµ‹è¯•é›†: {len(test_texts)} æ¡")

        # åˆ›å»ºæ”¹è¿›çš„æ•°æ®é›†
        train_dataset = ImprovedLogDataset(train_texts, train_labels)
        val_dataset = ImprovedLogDataset(val_texts, val_labels)
        test_dataset = ImprovedLogDataset(test_texts, test_labels)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        # åˆ›å»ºæ”¹è¿›çš„æ¨¡å‹
        num_classes = len(self.label_encoder)
        model_config = self.create_improved_model(num_classes)

        # è®¾ç½®è®­ç»ƒç»„ä»¶ - æ·»åŠ L2æ­£åˆ™åŒ–
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=0.01)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)

        # ä¿å­˜è®­ç»ƒé…ç½®
        training_config = {
            'model_type': self.model_type,
            'epochs': epochs,
            'patience': patience,
            'batch_size': batch_size,
            'learning_rate': 0.001,
            'weight_decay': 0.01,
            'model_config': model_config,
            'device': str(self.device),
            'data_path': data_path
        }
        self.persistence_manager.save_training_config(training_config)

        best_acc = 0
        best_f1 = 0
        patience_counter = 0
        best_predictions = None
        best_labels = None

        for epoch in range(epochs):
            logger.info(f"ğŸ“ˆ Epoch {epoch+1}/{epochs}")

            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)

            # éªŒè¯
            val_loss, val_acc, val_f1, val_predictions, val_labels = self.validate_epoch(val_loader, criterion)

            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_f1)
            current_lr = optimizer.param_groups[0]['lr']

            # è®°å½•è®­ç»ƒå†å²
            self.training_history['train_loss'].append(train_loss)
            self.training_history['val_loss'].append(val_loss)
            self.training_history['train_acc'].append(train_acc)
            self.training_history['val_acc'].append(val_acc)
            self.training_history['val_f1'].append(val_f1)
            self.training_history['learning_rate'].append(current_lr)

            logger.info(f"  è®­ç»ƒ: æŸå¤±={train_loss:.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
            logger.info(f"  éªŒè¯: æŸå¤±={val_loss:.4f}, å‡†ç¡®ç‡={val_acc:.2f}%, F1={val_f1:.4f}")
            logger.info(f"  å­¦ä¹ ç‡: {current_lr:.6f}")

            # æ—©åœæ£€æŸ¥
            if val_f1 > best_f1:
                best_f1 = val_f1
                best_acc = val_acc
                best_predictions = val_predictions
                best_labels = val_labels
                patience_counter = 0
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                self.persistence_manager.save_model(self.model, "best", model_config)
                logger.info(f" ä¿å­˜æœ€ä½³æ¨¡å‹ (F1: {val_f1:.4f}, å‡†ç¡®ç‡: {val_acc:.2f}%)")
            else:
                patience_counter += 1
                logger.info(f"â³ æ—©åœè®¡æ•°: {patience_counter}/{patience}")

            # æ—©åœ
            if patience_counter >= patience:
                logger.info(f" æ—©åœè§¦å‘ - {patience} è½®æœªæ”¹å–„")
                break

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.persistence_manager.save_model(self.model, "final", model_config)

        # æµ‹è¯•é›†è¯„ä¼°
        test_loss, test_acc, test_f1, test_predictions, test_labels = self.validate_epoch(test_loader, criterion)
        logger.info(f" æµ‹è¯•é›†: æŸå¤±={test_loss:.4f}, å‡†ç¡®ç‡={test_acc:.2f}%, F1={test_f1:.4f}")

        # ä¿å­˜è®­ç»ƒå†å²
        self.persistence_manager.save_training_history(self.training_history)

        # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
        metrics = {
            'best_val_acc': best_acc,
            'best_val_f1': best_f1,
            'test_acc': test_acc,
            'test_f1': test_f1,
            'final_epoch': epoch + 1,
            'total_epochs': len(self.training_history['train_loss'])
        }
        self.persistence_manager.save_training_metrics(metrics)

        # ä¿å­˜è®­ç»ƒå›¾è¡¨
        self.persistence_manager.save_plots(self.training_history)

        # ä¿å­˜æ··æ·†çŸ©é˜µ
        class_names = [self.label_encoder[i] for i in range(len(self.label_encoder))]
        self.persistence_manager.save_confusion_matrix(best_labels, best_predictions, class_names)

        # ä¿å­˜åˆ†ç±»æŠ¥å‘Š
        self.persistence_manager.save_classification_report(best_labels, best_predictions, class_names)

        # ä¿å­˜ä¼šè¯æ€»ç»“
        summary = {
            'model_type': self.model_type,
            'best_val_acc': best_acc,
            'best_f1': best_f1,
            'test_acc': test_acc,
            'test_f1': test_f1,
            'total_epochs': len(self.training_history['train_loss']),
            'final_epoch': epoch + 1,
            'data_samples': len(texts),
            'num_classes': len(self.label_encoder),
            'device': str(self.device)
        }
        self.persistence_manager.save_session_summary(summary)

        # åˆ›å»ºREADME
        training_info = {
            'model_type': self.model_type,
            'epochs': epochs,
            'batch_size': batch_size,
            'learning_rate': 0.001,
            'best_val_acc': best_acc,
            'best_f1': best_f1,
            'test_acc': test_acc,
            'test_f1': test_f1
        }
        self.persistence_manager.create_readme(training_info)

        logger.info(f"âœ… æŒä¹…åŒ–è®­ç»ƒå®Œæˆ - æœ€ä½³F1: {best_f1:.4f}, æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
        logger.info(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {self.persistence_manager.session_dir}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¸¦æŒä¹…åŒ–åŠŸèƒ½çš„Intel Arc GPU è®­ç»ƒå™¨")
    parser.add_argument("--model", type=str, default="textcnn",
                       choices=["textcnn", "fasttext"], help="æ¨¡å‹ç±»å‹")
    parser.add_argument("--data", type=str, required=True, help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=20, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--patience", type=int, default=5, help="æ—©åœè€å¿ƒå€¼")
    parser.add_argument("--batch_size", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")

    args = parser.parse_args()

    logger.info("ğŸ¯ å¸¦æŒä¹…åŒ–åŠŸèƒ½çš„Intel Arc GPU è®­ç»ƒå™¨")

    trainer = PersistentArcTrainer(model_type=args.model)
    trainer.train_with_persistence(args.data, args.epochs, args.patience, args.batch_size)


if __name__ == "__main__":
    main() 