#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Intel Arc GPU ä¼˜åŒ–è®­ç»ƒè„šæœ¬
é’ˆå¯¹å†…å­˜ä½¿ç”¨è¿›è¡Œä¼˜åŒ–ï¼Œé¿å…OOM
"""

import argparse
import torch
import torch.nn as nn
import logging
import os
import gc
from datetime import datetime
from typing import Dict, Any

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import ModelFactory
from data import DataLoaderFactory, LogPreprocessor
from utils import ArcGPUDetector

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class OptimizedArcTrainer:
    """ä¼˜åŒ–çš„Intel Arc GPU è®­ç»ƒå™¨"""
    
    def __init__(self, model_type: str = "textcnn", batch_size: int = 16):
        self.model_type = model_type
        self.device = ArcGPUDetector.get_device()
        self.model = None
        self.label_encoder = None
        self.batch_size = batch_size
        
        logger.info(f"ğŸ¯ åˆå§‹åŒ–ä¼˜åŒ–è®­ç»ƒå™¨ - æ¨¡å‹ç±»å‹: {model_type}")
        logger.info(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {self.device}")
        logger.info(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    def load_data(self, data_path: str):
        """åŠ è½½æ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
        
        # åŠ è½½å’Œåˆ†å‰²æ•°æ®
        texts, labels, label_encoder = DataLoaderFactory.load_csv_data(data_path)
        train_texts, val_texts, test_texts, train_labels, val_labels, test_labels = \
            DataLoaderFactory.split_data(texts, labels)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡å¤§å°ï¼‰
        train_loader, val_loader, test_loader = DataLoaderFactory.create_data_loaders(
            train_texts, val_texts, test_texts,
            train_labels, val_labels, test_labels,
            batch_size=self.batch_size
        )
        
        self.label_encoder = label_encoder
        logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ - ç±»åˆ«æ•°: {len(label_encoder)}")
        
        return train_loader, val_loader, test_loader
    
    def create_model(self, num_classes: int):
        """åˆ›å»ºæ¨¡å‹"""
        logger.info(f"ğŸ—ï¸ åˆ›å»ºæ¨¡å‹: {self.model_type}")
        
        # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹é…ç½®ä»¥é¿å…OOM
        model_config = ModelFactory.get_default_config(self.model_type)
        model_config['num_classes'] = num_classes
        
        # é’ˆå¯¹Intel Arc GPUä¼˜åŒ–é…ç½®
        if self.model_type == "textcnn":
            model_config.update({
                'embed_dim': 64,  # å‡å°åµŒå…¥ç»´åº¦
                'num_filters': 64,  # å‡å°å·ç§¯æ ¸æ•°é‡
                'dropout': 0.3
            })
        elif self.model_type == "fasttext":
            model_config.update({
                'embed_dim': 64,  # å‡å°åµŒå…¥ç»´åº¦
                'dropout': 0.2
            })
        
        self.model = ModelFactory.create_model(self.model_type, **model_config)
        self.model.to(self.device)
        
        param_count = self.model.count_parameters()
        logger.info(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ - å‚æ•°æ•°é‡: {param_count:,}")
        logger.info(f"ğŸ“‹ æ¨¡å‹é…ç½®: {self.model.get_config()}")
    
    def train_epoch(self, train_loader, criterion, optimizer):
        """è®­ç»ƒä¸€ä¸ªepochï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, batch in enumerate(train_loader):
            # æ¸…ç†GPUå†…å­˜
            if batch_idx % 10 == 0:
                torch.cuda.empty_cache() if torch.cuda.is_available() else None
                if hasattr(torch, 'xpu') and torch.xpu.is_available():
                    torch.xpu.empty_cache()
            
            input_ids = batch['input_ids'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            optimizer.zero_grad()
            outputs = self.model(input_ids)
            loss = criterion(outputs, labels)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # æ¸…ç†ä¸­é—´å˜é‡
            del outputs, loss
            if batch_idx % 50 == 0:
                logger.info(f"   æ‰¹æ¬¡ {batch_idx}/{len(train_loader)} - æŸå¤±: {total_loss/(batch_idx+1):.4f}")
        
        return total_loss / len(train_loader), 100 * correct / total
    
    def validate_epoch(self, val_loader, criterion):
        """éªŒè¯ä¸€ä¸ªepochï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                # æ¸…ç†GPUå†…å­˜
                if batch_idx % 10 == 0:
                    torch.cuda.empty_cache() if torch.cuda.is_available() else None
                    if hasattr(torch, 'xpu') and torch.xpu.is_available():
                        torch.xpu.empty_cache()
                
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = self.model(input_ids)
                loss = criterion(outputs, labels)
                
                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                # æ¸…ç†ä¸­é—´å˜é‡
                del outputs, loss
        
        return total_loss / len(val_loader), 100 * correct / total
    
    def train(self, data_path: str, epochs: int = 10, save_dir: str = "results/models"):
        """å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        logger.info("ğŸš€ å¼€å§‹ä¼˜åŒ–è®­ç»ƒ")
        
        # æ£€æŸ¥GPUçŠ¶æ€
        ArcGPUDetector.print_gpu_status()
        
        # åŠ è½½æ•°æ®
        train_loader, val_loader, test_loader = self.load_data(data_path)
        
        # åˆ›å»ºæ¨¡å‹
        num_classes = len(self.label_encoder)
        self.create_model(num_classes)
        
        # è®¾ç½®è®­ç»ƒç»„ä»¶
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, weight_decay=1e-5)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=2, verbose=True
        )
        
        best_acc = 0
        patience_counter = 0
        max_patience = 5
        
        for epoch in range(epochs):
            logger.info(f"ğŸ“ˆ Epoch {epoch+1}/{epochs}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)
            
            # éªŒè¯
            val_loss, val_acc = self.validate_epoch(val_loader, criterion)
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step(val_acc)
            
            logger.info(f"  è®­ç»ƒ: æŸå¤±={train_loss:.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
            logger.info(f"  éªŒè¯: æŸå¤±={val_loss:.4f}, å‡†ç¡®ç‡={val_acc:.2f}%")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                patience_counter = 0
                self.save_model(save_dir, "best")
                logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_acc:.2f}%)")
            else:
                patience_counter += 1
                logger.info(f"â³ è€å¿ƒè®¡æ•°: {patience_counter}/{max_patience}")
            
            # æ—©åœæœºåˆ¶
            if patience_counter >= max_patience:
                logger.info(f"ğŸ›‘ æ—©åœè§¦å‘ï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
                break
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            if hasattr(torch, 'xpu') and torch.xpu.is_available():
                torch.xpu.empty_cache()
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.save_model(save_dir, "final")
        
        # æµ‹è¯•é›†è¯„ä¼°
        test_loss, test_acc = self.validate_epoch(test_loader, criterion)
        logger.info(f"ğŸ§ª æµ‹è¯•é›†: æŸå¤±={test_loss:.4f}, å‡†ç¡®ç‡={test_acc:.2f}%")
        
        logger.info(f"âœ… è®­ç»ƒå®Œæˆ - æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
    
    def save_model(self, save_dir: str, suffix: str = ""):
        """ä¿å­˜æ¨¡å‹"""
        os.makedirs(save_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        model_path = os.path.join(save_dir, f"arc_gpu_optimized_{self.model_type}_{suffix}_{timestamp}.pth")
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'model_config': self.model.get_config(),
            'label_encoder': self.label_encoder,
            'training_config': {
                'model_type': self.model_type,
                'batch_size': self.batch_size,
                'device': str(self.device)
            }
        }, model_path)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Intel Arc GPU ä¼˜åŒ–è®­ç»ƒå™¨")
    parser.add_argument("--model", type=str, default="textcnn", 
                       choices=["textcnn", "fasttext"], help="æ¨¡å‹ç±»å‹")
    parser.add_argument("--data", type=str, required=True, help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=10, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--save_dir", type=str, default="results/models", help="æ¨¡å‹ä¿å­˜ç›®å½•")
    
    args = parser.parse_args()
    
    logger.info("ğŸ¯ Intel Arc GPU ä¼˜åŒ–è®­ç»ƒå™¨")
    logger.info(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    
    if not ArcGPUDetector.check_arc_gpu():
        logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°Intel Arc GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    trainer = OptimizedArcTrainer(model_type=args.model, batch_size=args.batch_size)
    trainer.train(args.data, args.epochs, args.save_dir)


if __name__ == "__main__":
    main() 