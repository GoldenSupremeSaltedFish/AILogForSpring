#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒç»“æœæŒä¹…åŒ–ç®¡ç†å™¨
"""

import os
import json
import shutil
import logging
from datetime import datetime
from typing import Dict, Any, List
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

logger = logging.getLogger(__name__)


class TrainingPersistenceManager:
    """è®­ç»ƒç»“æœæŒä¹…åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, base_dir: str = "results/history_results"):
        self.base_dir = base_dir
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_dir = os.path.join(base_dir, f"training_session_{self.timestamp}")
        
        # åˆ›å»ºç›®å½•ç»“æ„
        self._create_directory_structure()
        
        logger.info(f"ğŸ“ è®­ç»ƒä¼šè¯ç›®å½•: {self.session_dir}")
    
    def _create_directory_structure(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        directories = [
            self.session_dir,
            os.path.join(self.session_dir, "models"),
            os.path.join(self.session_dir, "logs"),
            os.path.join(self.session_dir, "plots"),
            os.path.join(self.session_dir, "data"),
            os.path.join(self.session_dir, "configs"),
            os.path.join(self.session_dir, "metrics")
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def save_training_config(self, config: Dict[str, Any]):
        """ä¿å­˜è®­ç»ƒé…ç½®"""
        config_file = os.path.join(self.session_dir, "configs", "training_config.json")
        
        # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯
        config['timestamp'] = self.timestamp
        config['session_dir'] = self.session_dir
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ è®­ç»ƒé…ç½®å·²ä¿å­˜: {config_file}")
        return config_file
    
    def save_model(self, model, model_name: str, model_config: Dict[str, Any] = None):
        """ä¿å­˜æ¨¡å‹æ–‡ä»¶"""
        model_dir = os.path.join(self.session_dir, "models")
        model_path = os.path.join(model_dir, f"{model_name}_{self.timestamp}.pth")
        
        # ä¿å­˜æ¨¡å‹
        torch.save({
            'model_state_dict': model.state_dict(),
            'model_config': model_config or model.get_config(),
            'timestamp': self.timestamp,
            'session_dir': self.session_dir
        }, model_path)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
        return model_path
    
    def save_training_metrics(self, metrics: Dict[str, Any]):
        """ä¿å­˜è®­ç»ƒæŒ‡æ ‡"""
        metrics_file = os.path.join(self.session_dir, "metrics", "training_metrics.json")
        
        # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯
        metrics['timestamp'] = self.timestamp
        metrics['session_dir'] = self.session_dir
        
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜: {metrics_file}")
        return metrics_file
    
    def save_training_history(self, history: Dict[str, List[float]]):
        """ä¿å­˜è®­ç»ƒå†å²"""
        history_file = os.path.join(self.session_dir, "metrics", "training_history.json")
        
        # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯
        history['timestamp'] = self.timestamp
        history['session_dir'] = self.session_dir
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“ˆ è®­ç»ƒå†å²å·²ä¿å­˜: {history_file}")
        return history_file
    
    def save_data_info(self, data_info: Dict[str, Any]):
        """ä¿å­˜æ•°æ®ä¿¡æ¯"""
        data_file = os.path.join(self.session_dir, "data", "data_info.json")
        
        # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯
        data_info['timestamp'] = self.timestamp
        data_info['session_dir'] = self.session_dir
        
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data_info, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‚ æ•°æ®ä¿¡æ¯å·²ä¿å­˜: {data_file}")
        return data_file
    
    def save_plots(self, history: Dict[str, List[float]]):
        """ä¿å­˜è®­ç»ƒå›¾è¡¨"""
        plots_dir = os.path.join(self.session_dir, "plots")
        
        # åˆ›å»ºæŸå¤±æ›²çº¿å›¾
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        plt.plot(history.get('train_loss', []), label='è®­ç»ƒæŸå¤±')
        plt.plot(history.get('val_loss', []), label='éªŒè¯æŸå¤±')
        plt.title('æŸå¤±æ›²çº¿')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True)
        
        plt.subplot(2, 2, 2)
        plt.plot(history.get('train_acc', []), label='è®­ç»ƒå‡†ç¡®ç‡')
        plt.plot(history.get('val_acc', []), label='éªŒè¯å‡†ç¡®ç‡')
        plt.title('å‡†ç¡®ç‡æ›²çº¿')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy (%)')
        plt.legend()
        plt.grid(True)
        
        plt.subplot(2, 2, 3)
        plt.plot(history.get('val_f1', []), label='éªŒè¯F1åˆ†æ•°')
        plt.title('F1åˆ†æ•°æ›²çº¿')
        plt.xlabel('Epoch')
        plt.ylabel('F1 Score')
        plt.legend()
        plt.grid(True)
        
        plt.subplot(2, 2, 4)
        plt.plot(history.get('learning_rate', []), label='å­¦ä¹ ç‡')
        plt.title('å­¦ä¹ ç‡å˜åŒ–')
        plt.xlabel('Epoch')
        plt.ylabel('Learning Rate')
        plt.legend()
        plt.grid(True)
        
        plt.tight_layout()
        plot_path = os.path.join(plots_dir, f"training_plots_{self.timestamp}.png")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š è®­ç»ƒå›¾è¡¨å·²ä¿å­˜: {plot_path}")
        return plot_path
    
    def save_confusion_matrix(self, y_true: List[int], y_pred: List[int], 
                            class_names: List[str] = None):
        """ä¿å­˜æ··æ·†çŸ©é˜µ"""
        from sklearn.metrics import confusion_matrix
        
        plots_dir = os.path.join(self.session_dir, "plots")
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_true, y_pred)
        
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title('æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        
        cm_path = os.path.join(plots_dir, f"confusion_matrix_{self.timestamp}.png")
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜: {cm_path}")
        return cm_path
    
    def save_classification_report(self, y_true: List[int], y_pred: List[int], 
                                 class_names: List[str] = None):
        """ä¿å­˜åˆ†ç±»æŠ¥å‘Š"""
        from sklearn.metrics import classification_report
        
        reports_dir = os.path.join(self.session_dir, "metrics")
        
        # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
        report = classification_report(y_true, y_pred, 
                                    target_names=class_names,
                                    output_dict=True)
        
        # ä¿å­˜ä¸ºJSON
        report_path = os.path.join(reports_dir, f"classification_report_{self.timestamp}.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ åˆ†ç±»æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report_path
    
    def save_session_summary(self, summary: Dict[str, Any]):
        """ä¿å­˜ä¼šè¯æ€»ç»“"""
        summary_file = os.path.join(self.session_dir, "session_summary.json")
        
        # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯
        summary['timestamp'] = self.timestamp
        summary['session_dir'] = self.session_dir
        summary['created_at'] = datetime.now().isoformat()
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“ ä¼šè¯æ€»ç»“å·²ä¿å­˜: {summary_file}")
        return summary_file
    
    def copy_data_files(self, data_path: str):
        """å¤åˆ¶æ•°æ®æ–‡ä»¶"""
        data_dir = os.path.join(self.session_dir, "data")
        data_filename = os.path.basename(data_path)
        data_copy_path = os.path.join(data_dir, data_filename)
        
        shutil.copy2(data_path, data_copy_path)
        logger.info(f"ğŸ“ æ•°æ®æ–‡ä»¶å·²å¤åˆ¶: {data_copy_path}")
        return data_copy_path
    
    def create_readme(self, training_info: Dict[str, Any]):
        """åˆ›å»ºREADMEæ–‡ä»¶"""
        readme_path = os.path.join(self.session_dir, "README.md")
        
        readme_content = f"""# è®­ç»ƒä¼šè¯è®°å½•

## åŸºæœ¬ä¿¡æ¯
- **ä¼šè¯æ—¶é—´**: {self.timestamp}
- **ä¼šè¯ç›®å½•**: {self.session_dir}
- **åˆ›å»ºæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## è®­ç»ƒé…ç½®
- **æ¨¡å‹ç±»å‹**: {training_info.get('model_type', 'N/A')}
- **è®­ç»ƒè½®æ•°**: {training_info.get('epochs', 'N/A')}
- **æ‰¹æ¬¡å¤§å°**: {training_info.get('batch_size', 'N/A')}
- **å­¦ä¹ ç‡**: {training_info.get('learning_rate', 'N/A')}

## è®­ç»ƒç»“æœ
- **æœ€ä½³éªŒè¯å‡†ç¡®ç‡**: {training_info.get('best_val_acc', 'N/A')}%
- **æœ€ä½³F1åˆ†æ•°**: {training_info.get('best_f1', 'N/A')}
- **æµ‹è¯•é›†å‡†ç¡®ç‡**: {training_info.get('test_acc', 'N/A')}%
- **æµ‹è¯•é›†F1åˆ†æ•°**: {training_info.get('test_f1', 'N/A')}

## æ–‡ä»¶ç»“æ„
```
{self.session_dir}/
â”œâ”€â”€ models/           # æ¨¡å‹æ–‡ä»¶
â”œâ”€â”€ logs/            # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ plots/           # å›¾è¡¨æ–‡ä»¶
â”œâ”€â”€ data/            # æ•°æ®æ–‡ä»¶
â”œâ”€â”€ configs/         # é…ç½®æ–‡ä»¶
â”œâ”€â”€ metrics/         # æŒ‡æ ‡æ–‡ä»¶
â””â”€â”€ README.md        # æœ¬æ–‡ä»¶
```

## ä½¿ç”¨è¯´æ˜
1. æ¨¡å‹æ–‡ä»¶ä½äº `models/` ç›®å½•
2. è®­ç»ƒå›¾è¡¨ä½äº `plots/` ç›®å½•
3. è¯¦ç»†æŒ‡æ ‡ä½äº `metrics/` ç›®å½•
4. é…ç½®æ–‡ä»¶ä½äº `configs/` ç›®å½•
"""
        
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        logger.info(f"ğŸ“– READMEæ–‡ä»¶å·²åˆ›å»º: {readme_path}")
        return readme_path
    
    def get_session_info(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        return {
            'timestamp': self.timestamp,
            'session_dir': self.session_dir,
            'created_at': datetime.now().isoformat()
        }


def create_persistence_manager(base_dir: str = "results/history_results") -> TrainingPersistenceManager:
    """åˆ›å»ºæŒä¹…åŒ–ç®¡ç†å™¨"""
    return TrainingPersistenceManager(base_dir) 