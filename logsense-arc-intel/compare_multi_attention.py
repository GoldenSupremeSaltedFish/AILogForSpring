#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šå±‚Attentionå¯¹æ¯”è®­ç»ƒè„šæœ¬
"""

import argparse
import torch
import torch.nn as nn
import logging
import os
from datetime import datetime
import numpy as np
from collections import Counter
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, classification_report

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.textcnn import TextCNN
from models.textcnn_with_attention import TextCNNWithAttention
from models.textcnn_multi_attention import TextCNNMultiAttention

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class Dataset(torch.utils.data.Dataset):
    """æ•°æ®é›†"""
    
    def __init__(self, texts: list, labels: list, max_length: int = 128, vocab_size: int = 8000):
        self.texts = texts
        self.labels = labels
        self.max_length = max_length
        self.vocab_size = vocab_size
        self.vocab = self._build_vocab()
        logger.info(f" è¯æ±‡è¡¨å¤§å°: {len(self.vocab)}")
    
    def _build_vocab(self):
        """æ„å»ºè¯æ±‡è¡¨"""
        word_counts = Counter()
        for text in self.texts:
            words = text.lower().split()
            word_counts.update(words)
        
        vocab = {'<PAD>': 0, '<UNK>': 1}
        for word, count in word_counts.most_common(self.vocab_size - 2):
            if count >= 2:
                vocab[word] = len(vocab)
        return vocab
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx]).lower()
        label = self.labels[idx]
        
        words = text.split()[:self.max_length]
        token_ids = []
        
        for word in words:
            if word in self.vocab:
                token_ids.append(self.vocab[word])
            else:
                token_ids.append(self.vocab['<UNK>'])
        
        if len(token_ids) < self.max_length:
            token_ids += [self.vocab['<PAD>']] * (self.max_length - len(token_ids))
        else:
            token_ids = token_ids[:self.max_length]
        
        return {
            'input_ids': torch.tensor(token_ids, dtype=torch.long),
            'labels': torch.tensor(label, dtype=torch.long)
        }


class MultiAttentionComparisonTrainer:
    """å¤šå±‚Attentionå¯¹æ¯”è®­ç»ƒå™¨"""

    def __init__(self):
        if torch.xpu.is_available():
            self.device = torch.device("xpu:0")
            logger.info("âœ… ä½¿ç”¨Intel XPU GPUåŠ é€Ÿ")
        else:
            self.device = torch.device("cpu")
            logger.warning("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒ")
    
    def load_data(self, data_path: str):
        """åŠ è½½æ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
        df = pd.read_csv(data_path)
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
        
        # æ•°æ®æ¸…æ´—
        df_cleaned = df.dropna(subset=['original_log', 'category'])
        df_cleaned = df_cleaned[df_cleaned['original_log'].str.strip() != '']
        
        # è¿‡æ»¤æ ·æœ¬å¤ªå°‘çš„ç±»åˆ«
        category_counts = df_cleaned['category'].value_counts()
        min_samples = 10
        valid_categories = category_counts[category_counts >= min_samples].index.tolist()
        df_filtered = df_cleaned[df_cleaned['category'].isin(valid_categories)]
        
        logger.info(f"ğŸ“Š è¿‡æ»¤åæ•°æ®: {len(df_filtered)} æ¡è®°å½•")
        logger.info(f" æœ‰æ•ˆç±»åˆ«: {len(valid_categories)} ä¸ª")
        
        # æ ‡ç­¾ç¼–ç 
        from sklearn.preprocessing import LabelEncoder
        label_encoder = LabelEncoder()
        labels = label_encoder.fit_transform(df_filtered['category'])
        
        texts = df_filtered['original_log'].tolist()
        
        # åˆ†ææ•°æ®åˆ†å¸ƒ
        self._analyze_data_distribution(labels, label_encoder.classes_)
        
        return texts, labels, label_encoder
    
    def _analyze_data_distribution(self, labels, class_names):
        """åˆ†ææ•°æ®åˆ†å¸ƒ"""
        unique, counts = np.unique(labels, return_counts=True)
        total = len(labels)
        
        logger.info("ğŸ“Š æ•°æ®åˆ†å¸ƒ:")
        for i, (label, count) in enumerate(zip(unique, counts)):
            percentage = (count / total) * 100
            logger.info(f"  {class_names[label]}: {count} æ¡ ({percentage:.1f}%)")
        
        # è®¡ç®—ä¸å¹³è¡¡æ¯”ä¾‹
        max_count = counts.max()
        min_count = counts.min()
        imbalance_ratio = max_count / min_count
        logger.info(f"ğŸ“ˆ æ•°æ®ä¸å¹³è¡¡æ¯”ä¾‹: {imbalance_ratio:.2f}:1")
    
    def train_model(self, model, train_loader, val_loader, epochs=10, model_name="Model"):
        """è®­ç»ƒæ¨¡å‹"""
        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒ {model_name}")
        
        model.to(self.device)
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3)
        
        best_f1 = 0
        best_acc = 0
        patience = 5
        patience_counter = 0
        
        for epoch in range(epochs):
            # è®­ç»ƒ
            model.train()
            train_loss = 0
            train_correct = 0
            train_total = 0
            
            for batch in train_loader:
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                optimizer.zero_grad()
                outputs = model(input_ids)
                loss = criterion(outputs, labels)
                loss.backward()
                
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()
            
            train_acc = 100 * train_correct / train_total
            
            # éªŒè¯
            model.eval()
            val_loss = 0
            val_correct = 0
            val_total = 0
            all_predictions = []
            all_labels = []
            
            with torch.no_grad():
                for batch in val_loader:
                    input_ids = batch['input_ids'].to(self.device)
                    labels = batch['labels'].to(self.device)
                    
                    outputs = model(input_ids)
                    loss = criterion(outputs, labels)
                    
                    val_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    val_total += labels.size(0)
                    val_correct += (predicted == labels).sum().item()
                    
                    all_predictions.extend(predicted.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())
            
            val_acc = 100 * val_correct / val_total
            val_f1 = f1_score(all_labels, all_predictions, average='weighted')
            
            logger.info(f"ğŸ“ˆ Epoch {epoch+1}/{epochs}")
            logger.info(f"   è®­ç»ƒ: æŸå¤±={train_loss/len(train_loader):.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
            logger.info(f"   éªŒè¯: æŸå¤±={val_loss/len(val_loader):.4f}, å‡†ç¡®ç‡={val_acc:.2f}%, F1={val_f1:.4f}")
            
            # æ—©åœ
            if val_f1 > best_f1:
                best_f1 = val_f1
                best_acc = val_acc
                patience_counter = 0
            else:
                patience_counter += 1
            
            scheduler.step(val_f1)
            
            if patience_counter >= patience:
                logger.info(f"â³ æ—©åœè§¦å‘ - {patience} è½®æœªæ”¹å–„")
                break
        
        return best_acc, best_f1
    
    def compare_models(self, data_path: str, epochs: int = 10):
        """å¯¹æ¯”æ¨¡å‹"""
        logger.info("ğŸ¯ å¤šå±‚Attentionå¯¹æ¯”è®­ç»ƒ")
        
        # åŠ è½½æ•°æ®
        texts, labels, label_encoder = self.load_data(data_path)
        
        # æ•°æ®åˆ†å‰²
        train_texts, val_texts, train_labels, val_labels = train_test_split(
            texts, labels, test_size=0.2, stratify=labels, random_state=42
        )
        
        logger.info(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
        logger.info(f"   è®­ç»ƒé›†: {len(train_texts)} æ¡")
        logger.info(f"   éªŒè¯é›†: {len(val_texts)} æ¡")
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = Dataset(train_texts, train_labels)
        val_dataset = Dataset(val_texts, val_labels)
        
        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)
        
        num_classes = len(label_encoder.classes_)
        logger.info(f"ğŸ“Š ç±»åˆ«æ•°: {num_classes}")
        
        # æ¨¡å‹é…ç½®
        model_config = {
            'vocab_size': 8000,
            'embed_dim': 128,
            'num_classes': num_classes,
            'filter_sizes': [3, 4, 5],
            'num_filters': 128,
            'dropout': 0.5
        }
        
        results = {}
        
        # è®­ç»ƒåŸå§‹TextCNN
        logger.info("ğŸ” è®­ç»ƒåŸå§‹TextCNN (æ— Attention)")
        original_model = TextCNN(**model_config)
        original_acc, original_f1 = self.train_model(
            original_model, train_loader, val_loader, epochs, "åŸå§‹TextCNN"
        )
        results['original'] = {'acc': original_acc, 'f1': original_f1}
        
        # è®­ç»ƒå•å±‚Attention TextCNN
        logger.info("ğŸ” è®­ç»ƒTextCNN with Single Attention")
        single_attention_model = TextCNNWithAttention(**model_config, attention_dim=128)
        single_acc, single_f1 = self.train_model(
            single_attention_model, train_loader, val_loader, epochs, "TextCNN with Single Attention"
        )
        results['single_attention'] = {'acc': single_acc, 'f1': single_f1}
        
        # è®­ç»ƒå¤šå±‚Attention TextCNN
        logger.info("ğŸ” è®­ç»ƒTextCNN with Multi-Layer Attention")
        multi_attention_model = TextCNNMultiAttention(
            **model_config, 
            attention_layers=2, 
            num_heads=4
        )
        multi_acc, multi_f1 = self.train_model(
            multi_attention_model, train_loader, val_loader, epochs, "TextCNN with Multi-Layer Attention"
        )
        results['multi_attention'] = {'acc': multi_acc, 'f1': multi_f1}
        
        # å¯¹æ¯”ç»“æœ
        logger.info("ğŸ“Š å¯¹æ¯”ç»“æœ:")
        logger.info(f"  åŸå§‹TextCNN: å‡†ç¡®ç‡={original_acc:.2f}%, F1={original_f1:.4f}")
        logger.info(f"  å•å±‚Attention: å‡†ç¡®ç‡={single_acc:.2f}%, F1={single_f1:.4f}")
        logger.info(f"  å¤šå±‚Attention: å‡†ç¡®ç‡={multi_acc:.2f}%, F1={multi_f1:.4f}")
        
        # è®¡ç®—æ”¹è¿›å¹…åº¦
        single_acc_improvement = single_acc - original_acc
        single_f1_improvement = single_f1 - original_f1
        multi_acc_improvement = multi_acc - original_acc
        multi_f1_improvement = multi_f1 - original_f1
        
        logger.info(f"ğŸ“ˆ æ”¹è¿›å¹…åº¦:")
        logger.info(f"  å•å±‚Attention vs åŸå§‹:")
        logger.info(f"    å‡†ç¡®ç‡æå‡: {single_acc_improvement:.2f}%")
        logger.info(f"    F1åˆ†æ•°æå‡: {single_f1_improvement:.4f}")
        logger.info(f"  å¤šå±‚Attention vs åŸå§‹:")
        logger.info(f"    å‡†ç¡®ç‡æå‡: {multi_acc_improvement:.2f}%")
        logger.info(f"    F1åˆ†æ•°æå‡: {multi_f1_improvement:.4f}")
        logger.info(f"  å¤šå±‚Attention vs å•å±‚Attention:")
        logger.info(f"    å‡†ç¡®ç‡æå‡: {multi_acc - single_acc:.2f}%")
        logger.info(f"    F1åˆ†æ•°æå‡: {multi_f1 - single_f1:.4f}")
        
        # åˆ¤æ–­æœ€ä½³æ¨¡å‹
        best_model = max(results.items(), key=lambda x: x[1]['f1'])
        logger.info(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]} (F1: {best_model[1]['f1']:.4f})")
        
        if multi_f1 > single_f1 and multi_f1 > original_f1:
            logger.info("âœ… å¤šå±‚Attentionæœºåˆ¶æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½!")
        elif single_f1 > original_f1:
            logger.info("âœ… å•å±‚Attentionæœºåˆ¶æœ‰æ•ˆæå‡äº†æ¨¡å‹æ€§èƒ½!")
        else:
            logger.info("âš ï¸ Attentionæœºåˆ¶æœªæ˜¾è‘—æå‡æ€§èƒ½")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¤šå±‚Attentionå¯¹æ¯”è®­ç»ƒ')
    parser.add_argument('--data', type=str, default='data/processed_logs_final_cleaned.csv',
                       help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--epochs', type=int, default=10, help='è®­ç»ƒè½®æ•°')
    
    args = parser.parse_args()
    
    trainer = MultiAttentionComparisonTrainer()
    trainer.compare_models(args.data, args.epochs)


if __name__ == "__main__":
    main() 