#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è´¨é‡å¢å¼ºå™¨ - ä¸“æ³¨äºæ—¥å¿—æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹
"""

import pandas as pd
import numpy as np
import logging
import re
from collections import Counter

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class LogCleaner:
    """æ—¥å¿—æ¸…æ´—å™¨"""
    
    def __init__(self):
        # éœ€è¦ç§»é™¤çš„å…ƒæ•°æ®æ¨¡å¼
        self.metadata_patterns = [
            r'github\.com/[^\s,]+',
            r'https://github\.com/[^\s,]+',
            r'github_issue',
            r'unknown,github_issue',
            r'[a-zA-Z0-9_-]+/[a-zA-Z0-9_-]+,\d+',
            r'https://github\.com/[^\s,]+/issues/\d+',
            r'[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]+',
            r'[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}',
            r'<[^>]+>',
            r'&[a-zA-Z]+;',
            r'\[.*?\]',
            r'^,+|,+$',
            r'^"+|"+$',
            r'unknown,,,',
            r',unknown,,,',
            r',unknown,',
            r'unknown,',
            r'https://',
        ]
        
        # æ—¥å¿—çº§åˆ«
        self.log_levels = ['DEBUG', 'INFO', 'WARN', 'WARNING', 'ERROR', 'FATAL', 'TRACE']
    
    def clean_log(self, text: str) -> str:
        """æ¸…æ´—æ—¥å¿—å†…å®¹"""
        if pd.isna(text) or text == '':
            return ''
        
        text = str(text)
        
        # ç§»é™¤å…ƒæ•°æ®
        for pattern in self.metadata_patterns:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        
        # æ ‡å‡†åŒ–
        text = re.sub(r'\s+', ' ', text)  # å¤šä¸ªç©ºæ ¼å˜å•ä¸ª
        text = text.strip()
        
        # ç§»é™¤ä»¥é€—å·å¼€å¤´çš„éƒ¨åˆ†
        if text.startswith(','):
            text = text.lstrip(',')
        
        # ç§»é™¤ä»¥unknownå¼€å¤´çš„éƒ¨åˆ†
        if text.lower().startswith('unknown'):
            text = re.sub(r'^unknown[,\s]*', '', text, flags=re.IGNORECASE)
        
        return text.strip()
    
    def extract_log_level(self, text: str) -> str:
        """æå–æ—¥å¿—çº§åˆ«"""
        text_upper = text.upper()
        for level in self.log_levels:
            if level in text_upper:
                return level
        return 'UNKNOWN'
    
    def is_valid_log(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆæ—¥å¿—"""
        if not text or len(text.strip()) < 10:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥å¿—ç‰¹å¾
        log_indicators = ['error', 'warn', 'info', 'debug', 'exception', 'failed', 'success']
        text_lower = text.lower()
        
        return any(indicator in text_lower for indicator in log_indicators)


class FeatureExtractor:
    """ç‰¹å¾æå–å™¨"""
    
    def __init__(self):
        # é”™è¯¯ç æ¨¡å¼
        self.error_patterns = [
            r'error\s*[:\s]*([A-Z0-9_]+)',
            r'err\s*[:\s]*([A-Z0-9_]+)',
            r'([A-Z]{2,10}\d{3,6})',
            r'([A-Z]{2,10}Exception)',
            r'([A-Z][a-z]+Exception)',
        ]
        
        # è·¯å¾„æ¨¡å¼
        self.path_patterns = [
            r'([A-Za-z]:\\[^\s]+)',
            r'(/[^\s]+)',
            r'([A-Za-z0-9_/.-]+\.(java|py|js|ts|go|cpp|c|h))',
        ]
        
        # æ•°å­—æ¨¡å¼
        self.number_patterns = [
            r'(\d+\.\d+)',
            r'(\d+)',
        ]
        
        # ç±»åæ¨¡å¼
        self.class_patterns = [
            r'([A-Z][a-zA-Z0-9_]*\.java)',
            r'([A-Z][a-zA-Z0-9_]*\.py)',
            r'([A-Z][a-zA-Z0-9_]*\.js)',
            r'([A-Z][a-zA-Z0-9_]*\.ts)',
        ]
    
    def extract_features(self, text: str) -> dict:
        """æå–ç‰¹å¾"""
        features = {}
        
        # æå–é”™è¯¯ç 
        error_codes = []
        for pattern in self.error_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            # å¤„ç†å…ƒç»„ç»“æœ
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        error_codes.extend([m for m in match if m])
                    else:
                        error_codes.append(match)
        features['error_codes'] = ' '.join(set(error_codes)) if error_codes else ''
        
        # æå–è·¯å¾„
        paths = []
        for pattern in self.path_patterns:
            matches = re.findall(pattern, text)
            # å¤„ç†å…ƒç»„ç»“æœ
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        paths.extend([m for m in match if m])
                    else:
                        paths.append(match)
        features['paths'] = ' '.join(set(paths)) if paths else ''
        
        # æå–æ•°å­—
        numbers = []
        for pattern in self.number_patterns:
            matches = re.findall(pattern, text)
            # å¤„ç†å…ƒç»„ç»“æœ
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        numbers.extend([m for m in match if m])
                    else:
                        numbers.append(match)
        features['numbers'] = ' '.join(set(numbers)) if numbers else ''
        
        # æå–ç±»å
        classes = []
        for pattern in self.class_patterns:
            matches = re.findall(pattern, text)
            # å¤„ç†å…ƒç»„ç»“æœ
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        classes.extend([m for m in match if m])
                    else:
                        classes.append(match)
        features['classes'] = ' '.join(set(classes)) if classes else ''
        
        return features


class DataQualityEnhancer:
    """æ•°æ®è´¨é‡å¢å¼ºå™¨"""
    
    def __init__(self):
        self.cleaner = LogCleaner()
        self.extractor = FeatureExtractor()
    
    def enhance_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¢å¼ºæ•°æ®è´¨é‡"""
        logger.info("ğŸš€ å¼€å§‹æ•°æ®è´¨é‡å¢å¼º")
        logger.info(f"ğŸ“Š åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
        
        # 1. æ•°æ®æ¸…æ´—
        logger.info("ğŸ§¹ æ­¥éª¤1: æ•°æ®æ¸…æ´—")
        df_cleaned = self._clean_data(df)
        
        # 2. ç‰¹å¾å·¥ç¨‹
        logger.info("ğŸ”§ æ­¥éª¤2: ç‰¹å¾å·¥ç¨‹")
        df_enhanced = self._extract_features(df_cleaned)
        
        # 3. è´¨é‡è¯„ä¼°
        logger.info("ğŸ“ˆ æ­¥éª¤3: è´¨é‡è¯„ä¼°")
        self._assess_quality(df_enhanced)
        
        return df_enhanced
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—æ•°æ®"""
        # ç§»é™¤ç©ºå€¼
        df_cleaned = df.dropna(subset=['original_log', 'category'])
        
        # æ¸…æ´—æ—¥å¿—å†…å®¹
        df_cleaned['cleaned_log'] = df_cleaned['original_log'].apply(self.cleaner.clean_log)
        
        # æå–æ—¥å¿—çº§åˆ«
        df_cleaned['log_level'] = df_cleaned['cleaned_log'].apply(self.cleaner.extract_log_level)
        
        # è¿‡æ»¤æ— æ•ˆæ—¥å¿—
        df_cleaned = df_cleaned[df_cleaned['cleaned_log'].apply(self.cleaner.is_valid_log)]
        
        logger.info(f"âœ… æ¸…æ´—åæ•°æ®: {len(df_cleaned)} æ¡è®°å½•")
        
        # åˆ†ææ—¥å¿—çº§åˆ«åˆ†å¸ƒ
        level_counts = df_cleaned['log_level'].value_counts()
        logger.info("ğŸ“Š æ—¥å¿—çº§åˆ«åˆ†å¸ƒ:")
        for level, count in level_counts.items():
            percentage = (count / len(df_cleaned)) * 100
            logger.info(f"  {level}: {count} æ¡ ({percentage:.1f}%)")
        
        return df_cleaned
    
    def _extract_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æå–ç‰¹å¾"""
        logger.info("ğŸ” æå–ç»“æ„åŒ–ç‰¹å¾...")
        
        # æå–ç‰¹å¾
        features_list = []
        for idx, row in df.iterrows():
            features = self.extractor.extract_features(row['cleaned_log'])
            features_list.append(features)
        
        # è½¬æ¢ä¸ºDataFrame
        features_df = pd.DataFrame(features_list)
        
        # åˆå¹¶ç‰¹å¾
        df_enhanced = pd.concat([df.reset_index(drop=True), features_df], axis=1)
        
        # ç»Ÿè®¡ç‰¹å¾æå–ç»“æœ
        logger.info("ğŸ“Š ç‰¹å¾æå–ç»Ÿè®¡:")
        for col in features_df.columns:
            non_empty = (features_df[col] != '').sum()
            percentage = (non_empty / len(features_df)) * 100
            logger.info(f"  {col}: {non_empty} æ¡ ({percentage:.1f}%)")
        
        return df_enhanced
    
    def _assess_quality(self, df: pd.DataFrame) -> None:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        logger.info("ğŸ“ˆ æ•°æ®è´¨é‡è¯„ä¼°:")
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        total_logs = len(df)
        valid_logs = len(df[df['cleaned_log'].str.len() > 10])
        logs_with_features = len(df[df['error_codes'] != ''])
        logs_with_paths = len(df[df['paths'] != ''])
        
        logger.info(f"  ğŸ“Š æ€»æ—¥å¿—æ•°: {total_logs}")
        logger.info(f"  âœ… æœ‰æ•ˆæ—¥å¿—æ•°: {valid_logs} ({valid_logs/total_logs*100:.1f}%)")
        logger.info(f"  ğŸ” åŒ…å«é”™è¯¯ç : {logs_with_features} ({logs_with_features/total_logs*100:.1f}%)")
        logger.info(f"  ğŸ“ åŒ…å«è·¯å¾„: {logs_with_paths} ({logs_with_paths/total_logs*100:.1f}%)")
        
        # ç±»åˆ«åˆ†å¸ƒ
        category_counts = df['category'].value_counts()
        logger.info("ğŸ“Š ç±»åˆ«åˆ†å¸ƒ:")
        for category, count in category_counts.items():
            percentage = (count / total_logs) * 100
            logger.info(f"  {category}: {count} æ¡ ({percentage:.1f}%)")
    
    def create_enhanced_dataset(self, input_path: str, output_path: str) -> pd.DataFrame:
        """åˆ›å»ºå¢å¼ºæ•°æ®é›†"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {input_path}")
        df = pd.read_csv(input_path)
        
        # å¢å¼ºæ•°æ®è´¨é‡
        df_enhanced = self.enhance_data(df)
        
        # ä¿å­˜ç»“æœ
        df_enhanced.to_csv(output_path, index=False)
        logger.info(f"ğŸ’¾ ä¿å­˜å¢å¼ºæ•°æ®: {output_path}")
        
        return df_enhanced


def main():
    """ä¸»å‡½æ•°"""
    enhancer = DataQualityEnhancer()
    
    input_path = "data/processed_logs_final_cleaned.csv"
    output_path = "data/processed_logs_quality_enhanced.csv"
    
    # åˆ›å»ºå¢å¼ºæ•°æ®é›†
    df_enhanced = enhancer.create_enhanced_dataset(input_path, output_path)
    
    logger.info("âœ… æ•°æ®è´¨é‡å¢å¼ºå®Œæˆ!")
    
    # æ˜¾ç¤ºå¢å¼ºåçš„æ•°æ®æ ·ä¾‹
    logger.info("ğŸ“‹ å¢å¼ºæ•°æ®æ ·ä¾‹:")
    sample_cols = ['category', 'cleaned_log', 'log_level', 'error_codes', 'paths']
    print(df_enhanced[sample_cols].head(3).to_string())


if __name__ == "__main__":
    main() 