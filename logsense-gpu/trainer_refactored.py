#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Intel Arc GPU è®­ç»ƒå™¨ - é‡æ„ç‰ˆæœ¬
"""

import torch
import torch.nn as nn
import logging
import os
from datetime import datetime
from typing import Dict, Any

# å¯¼å…¥æ¨¡å—
from arc_models import ModelFactory
from arc_data import DataLoaderFactory
from arc_utils import ArcGPUDetector

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ArcTrainerRefactored:
    """é‡æ„åçš„è®­ç»ƒå™¨"""
    
    def __init__(self, model_type: str = "textcnn"):
        self.model_type = model_type
        self.device = ArcGPUDetector.get_device()
        self.model = None
        self.label_encoder = None
        
        logger.info(f"ğŸ¯ åˆå§‹åŒ–è®­ç»ƒå™¨ - æ¨¡å‹ç±»å‹: {model_type}")
        logger.info(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {self.device}")
    
    def load_data(self, data_path: str):
        """åŠ è½½æ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
        
        # åŠ è½½å’Œåˆ†å‰²æ•°æ®
        texts, labels, label_encoder = DataLoaderFactory.load_csv_data(data_path)
        train_texts, val_texts, test_texts, train_labels, val_labels, test_labels = \
            DataLoaderFactory.split_data(texts, labels)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = DataLoaderFactory.create_data_loaders(
            train_texts, val_texts, test_texts,
            train_labels, val_labels, test_labels
        )
        
        self.label_encoder = label_encoder
        logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ - ç±»åˆ«æ•°: {len(label_encoder)}")
        
        return train_loader, val_loader, test_loader
    
    def create_model(self, num_classes: int):
        """åˆ›å»ºæ¨¡å‹"""
        logger.info(f"ğŸ—ï¸ åˆ›å»ºæ¨¡å‹: {self.model_type}")
        
        model_config = ModelFactory.get_default_config(self.model_type)
        model_config['num_classes'] = num_classes
        
        self.model = ModelFactory.create_model(self.model_type, **model_config)
        self.model.to(self.device)
        
        param_count = self.model.count_parameters()
        logger.info(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ - å‚æ•°æ•°é‡: {param_count:,}")
    
    def train_epoch(self, train_loader, criterion, optimizer):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch in train_loader:
            input_ids = batch['input_ids'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            optimizer.zero_grad()
            outputs = self.model(input_ids)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        
        return total_loss / len(train_loader), 100 * correct / total
    
    def validate_epoch(self, val_loader, criterion):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = self.model(input_ids)
                loss = criterion(outputs, labels)
                
                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        return total_loss / len(val_loader), 100 * correct / total
    
    def train(self, data_path: str, epochs: int = 10):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒ")
        
        # åŠ è½½æ•°æ®
        train_loader, val_loader, test_loader = self.load_data(data_path)
        
        # åˆ›å»ºæ¨¡å‹
        num_classes = len(self.label_encoder)
        self.create_model(num_classes)
        
        # è®¾ç½®è®­ç»ƒç»„ä»¶
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        
        best_acc = 0
        
        for epoch in range(epochs):
            logger.info(f"ğŸ“ˆ Epoch {epoch+1}/{epochs}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)
            
            # éªŒè¯
            val_loss, val_acc = self.validate_epoch(val_loader, criterion)
            
            logger.info(f"  è®­ç»ƒ: æŸå¤±={train_loss:.4f}, å‡†ç¡®ç‡={train_acc:.2f}%")
            logger.info(f"  éªŒè¯: æŸå¤±={val_loss:.4f}, å‡†ç¡®ç‡={val_acc:.2f}%")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                self.save_model("best")
                logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_acc:.2f}%)")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.save_model("final")
        
        # æµ‹è¯•é›†è¯„ä¼°
        test_loss, test_acc = self.validate_epoch(test_loader, criterion)
        logger.info(f"ğŸ§ª æµ‹è¯•é›†: æŸå¤±={test_loss:.4f}, å‡†ç¡®ç‡={test_acc:.2f}%")
        
        logger.info(f"âœ… è®­ç»ƒå®Œæˆ - æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
    
    def save_model(self, suffix: str = ""):
        """ä¿å­˜æ¨¡å‹"""
        os.makedirs("results/models", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        model_path = f"results/models/arc_gpu_model_{self.model_type}_{suffix}_{timestamp}.pth"
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'model_config': self.model.get_config(),
            'label_encoder': self.label_encoder
        }, model_path)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ Intel Arc GPU è®­ç»ƒå™¨ - é‡æ„ç‰ˆæœ¬")
    
    if not ArcGPUDetector.check_arc_gpu():
        logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°Intel Arc GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    trainer = ArcTrainerRefactored(model_type="textcnn")
    trainer.train("DATA_OUTPUT/processed_logs.csv", epochs=10)


if __name__ == "__main__":
    main() 