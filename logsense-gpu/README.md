# LogSense GPU - å¤šå¹³å°æ—¥å¿—åˆ†ææ¨¡å‹

## é¡¹ç›®æ¦‚è¿°

LogSense GPUæ˜¯ä¸€ä¸ªæ”¯æŒå¤šå¹³å°è®¡ç®—çš„æ—¥å¿—åˆ†ææ¨¡å‹è®­ç»ƒæ¡†æ¶ï¼Œä¸“é—¨ç”¨äºæ—¥å¿—åˆ†ç±»å’Œå¼‚å¸¸æ£€æµ‹ã€‚

### ä¸»è¦ç‰¹æ€§

- ğŸ–¥ï¸ **å¤šå¹³å°æ”¯æŒ**: è‡ªåŠ¨æ£€æµ‹GPU/CPUç¯å¢ƒï¼Œä¼˜åŒ–è®¡ç®—é…ç½®
- ğŸ§ª **å°æ ·æœ¬éªŒè¯**: æ”¯æŒå°æ ·æœ¬å®éªŒï¼Œå¿«é€ŸéªŒè¯æ¨¡å‹æ•ˆæœ
- ğŸ¤– **å¤šç§æ¨¡å‹**: æ”¯æŒGradientBoostingã€LightGBMç­‰æ¨¡å‹
- ğŸ“Š **å¯è§†åŒ–åˆ†æ**: è‡ªåŠ¨ç”Ÿæˆæ··æ·†çŸ©é˜µå’Œæ€§èƒ½å›¾è¡¨
- âš¡ **æ€§èƒ½ç›‘æ§**: å®æ—¶ç›‘æ§è®­ç»ƒæ€§èƒ½å’Œèµ„æºä½¿ç”¨

## ç›®å½•ç»“æ„

```
logsense-gpu/
â”œâ”€â”€ scripts/              # è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ baseline_model.py # å°æ ·æœ¬éªŒè¯ + Baseæ¨¡å‹è®­ç»ƒ
â”œâ”€â”€ utils/                # å·¥å…·è„šæœ¬
â”‚   â””â”€â”€ platform_utils.py # å¤šå¹³å°è®¡ç®—æ”¯æŒ
â”œâ”€â”€ models/               # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
â”œâ”€â”€ data/                 # æ•°æ®æ–‡ä»¶
â”œâ”€â”€ config/               # é…ç½®æ–‡ä»¶
â””â”€â”€ results/              # å®éªŒç»“æœå’Œå›¾è¡¨
```

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install pandas scikit-learn matplotlib seaborn

# å¯é€‰ï¼šå®‰è£…LightGBMï¼ˆç”¨äºæ›´å¿«çš„è®­ç»ƒï¼‰
pip install lightgbm

# å¯é€‰ï¼šå®‰è£…PyTorchï¼ˆç”¨äºGPUæ£€æµ‹ï¼‰
pip install torch
```

### 2. è¿è¡Œå°æ ·æœ¬éªŒè¯

```bash
# ä½¿ç”¨æ‰¹å¤„ç†è„šæœ¬ï¼ˆæ¨èï¼‰
batch-scripts/run_baseline_model.bat

# æˆ–ç›´æ¥è¿è¡ŒPythonè„šæœ¬
python logsense-gpu/scripts/baseline_model.py --sample-size 500 --model-type gradient_boosting
```

### 3. æŸ¥çœ‹ç»“æœ

è®­ç»ƒå®Œæˆåï¼Œç»“æœå°†ä¿å­˜åœ¨ï¼š
- `logsense-gpu/results/models/` - è®­ç»ƒå¥½çš„æ¨¡å‹
- `logsense-gpu/results/plots/` - å¯è§†åŒ–å›¾è¡¨
- `logsense-gpu/results/` - å®éªŒç»“æœJSONæ–‡ä»¶

## è¯¦ç»†ä½¿ç”¨è¯´æ˜

### å°æ ·æœ¬éªŒè¯å®éªŒ

```bash
# åŸºæœ¬ç”¨æ³•
python logsense-gpu/scripts/baseline_model.py

# è‡ªå®šä¹‰å‚æ•°
python logsense-gpu/scripts/baseline_model.py \
    --sample-size 300 \
    --model-type lightgbm \
    --data-file DATA_OUTPUT/training_dataset_20250802_013437.csv
```

### å‚æ•°è¯´æ˜

- `--sample-size N`: æ¯ç±»æ ·æœ¬æ•°ï¼ˆé»˜è®¤500ï¼‰
- `--model-type TYPE`: æ¨¡å‹ç±»å‹ï¼ˆgradient_boosting/lightgbmï¼‰
- `--data-file PATH`: è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„
- `--output-dir PATH`: è¾“å‡ºç›®å½•
- `--gpu`: å¯ç”¨GPUåŠ é€Ÿ

### æ”¯æŒçš„ç±»åˆ«

å½“å‰æ”¯æŒ5ä¸ªä¸»è¦æ—¥å¿—ç±»åˆ«ï¼š
1. `stack_exception` - å †æ ˆå¼‚å¸¸
2. `connection_issue` - è¿æ¥é—®é¢˜
3. `database_exception` - æ•°æ®åº“å¼‚å¸¸
4. `auth_authorization` - è®¤è¯æˆæƒ
5. `memory_performance` - å†…å­˜æ€§èƒ½

## å¤šå¹³å°è®¡ç®—æ”¯æŒ

### GPUæ£€æµ‹

ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹NVIDIA GPUå¹¶ä¼˜åŒ–é…ç½®ï¼š

```python
from logsense-gpu.utils.platform_utils import setup_environment

# æ£€æµ‹ç³»ç»Ÿç¯å¢ƒ
detector, optimizer, config = setup_environment()

# è·å–æ¨èé…ç½®
print(f"è®¡ç®—è®¾å¤‡: {config['device']}")
print(f"æ‰¹å¤„ç†å¤§å°: {config['batch_size']}")
print(f"å·¥ä½œè¿›ç¨‹æ•°: {config['num_workers']}")
```

### æ€§èƒ½ç›‘æ§

```python
from logsense-gpu.utils.platform_utils import PerformanceMonitor

# åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
monitor = PerformanceMonitor()
monitor.start_monitoring()

# è®­ç»ƒè¿‡ç¨‹ä¸­è®°å½•æŒ‡æ ‡
monitor.record_metrics()

# è®­ç»ƒç»“æŸåæŸ¥çœ‹æ‘˜è¦
monitor.print_summary()
```

## æ¨¡å‹è®­ç»ƒæµç¨‹

### 1. æ•°æ®åŠ è½½å’Œé‡‡æ ·

```python
# åŠ è½½è®­ç»ƒæ•°æ®
df = pd.read_csv('training_dataset.csv')

# å°æ ·æœ¬é‡‡æ ·ï¼ˆæ¯ç±»500æ¡ï¼‰
sampled_data = []
for class_name in target_classes:
    class_data = df[df['label'] == class_name]
    sampled = class_data.sample(n=500, random_state=42)
    sampled_data.append(sampled)

df_sampled = pd.concat(sampled_data, ignore_index=True)
```

### 2. ç‰¹å¾å·¥ç¨‹

```python
# TF-IDFå‘é‡åŒ–
vectorizer = TfidfVectorizer(
    max_features=3000,
    ngram_range=(1, 2),
    min_df=2,
    max_df=0.95
)

X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)
```

### 3. æ¨¡å‹è®­ç»ƒ

```python
# GradientBoostingæ¨¡å‹
model = GradientBoostingClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    random_state=42
)

model.fit(X_train_vec, y_train)
```

### 4. æ¨¡å‹è¯„ä¼°

```python
# é¢„æµ‹å’Œè¯„ä¼°
y_pred = model.predict(X_test_vec)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
print(report)
```

## å®éªŒç»“æœç¤ºä¾‹

### è®­ç»ƒè¿‡ç¨‹è¾“å‡º

```
ğŸ§ª å¼€å§‹å°æ ·æœ¬éªŒè¯å®éªŒ
============================================================
ğŸ“‚ åŠ è½½æ•°æ®æ–‡ä»¶: DATA_OUTPUT/training_dataset_20250802_013437.csv
ğŸ“Š åŸå§‹æ•°æ®: 4764 æ¡è®°å½•
ğŸ” è¿‡æ»¤åæ•°æ®: 2500 æ¡è®°å½•

ğŸ“ˆ æœ€ç»ˆç±»åˆ«åˆ†å¸ƒ:
  stack_exception: 500 æ¡ (20.0%)
  connection_issue: 500 æ¡ (20.0%)
  database_exception: 500 æ¡ (20.0%)
  auth_authorization: 500 æ¡ (20.0%)
  memory_performance: 500 æ¡ (20.0%)

ğŸ“Š è®­ç»ƒé›†: 2000 æ¡è®°å½•
ğŸ“Š æµ‹è¯•é›†: 500 æ¡è®°å½•

ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...
ğŸ“ å‘é‡åŒ–è®­ç»ƒæ•°æ®...
ğŸ“Š ç‰¹å¾ç»´åº¦: 3000
ğŸ‹ï¸ è®­ç»ƒæ¨¡å‹...
â±ï¸ è®­ç»ƒæ—¶é—´: 15.23 ç§’

ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:
å‡†ç¡®ç‡: 0.8920
å®å¹³å‡F1: 0.8915
åŠ æƒå¹³å‡F1: 0.8920
```

### ç”Ÿæˆçš„å›¾è¡¨

- **æ··æ·†çŸ©é˜µ**: æ˜¾ç¤ºå„ç±»åˆ«çš„é¢„æµ‹å‡†ç¡®åº¦
- **F1åˆ†æ•°å›¾**: å„ç±»åˆ«çš„F1åˆ†æ•°å¯¹æ¯”
- **æ€§èƒ½ç›‘æ§**: è®­ç»ƒè¿‡ç¨‹ä¸­çš„èµ„æºä½¿ç”¨æƒ…å†µ

## æ‰©å±•åŠŸèƒ½

### æ·»åŠ æ–°çš„æ¨¡å‹ç±»å‹

```python
# åœ¨baseline_model.pyä¸­æ·»åŠ æ–°çš„æ¨¡å‹
def create_custom_model(self):
    from sklearn.ensemble import RandomForestClassifier
    
    self.model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42
    )
```

### è‡ªå®šä¹‰ç‰¹å¾å·¥ç¨‹

```python
# æ·»åŠ è‡ªå®šä¹‰ç‰¹å¾
def extract_custom_features(self, text):
    features = {}
    features['length'] = len(text)
    features['word_count'] = len(text.split())
    features['has_error'] = 'error' in text.lower()
    return features
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **GPUä¸å¯ç”¨**
   - æ£€æŸ¥NVIDIAé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…
   - ç¡®è®¤PyTorchæ”¯æŒCUDA

2. **å†…å­˜ä¸è¶³**
   - å‡å°‘`sample_size`å‚æ•°
   - é™ä½`max_features`å‚æ•°

3. **è®­ç»ƒé€Ÿåº¦æ…¢**
   - ä½¿ç”¨LightGBMæ›¿ä»£GradientBoosting
   - å¯ç”¨GPUåŠ é€Ÿ
   - è°ƒæ•´æ‰¹å¤„ç†å¤§å°

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

- **GPUè®­ç»ƒ**: ä½¿ç”¨NVIDIA GPUå¯æ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦
- **å†…å­˜ä¼˜åŒ–**: æ ¹æ®ç³»ç»Ÿå†…å­˜è°ƒæ•´æ‰¹å¤„ç†å¤§å°
- **å¹¶è¡Œå¤„ç†**: åˆ©ç”¨å¤šæ ¸CPUè¿›è¡Œç‰¹å¾å·¥ç¨‹

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd AILogForSpring

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# è¿è¡Œæµ‹è¯•
python -m pytest tests/
```

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚ 