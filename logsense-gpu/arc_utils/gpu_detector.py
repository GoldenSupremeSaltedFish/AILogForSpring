#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Intel Arc GPU æ£€æµ‹å™¨
"""

import torch
import logging
from typing import Dict, Optional

logger = logging.getLogger(__name__)


class ArcGPUDetector:
    """Intel Arc GPU æ£€æµ‹å™¨"""
    
    @staticmethod
    def check_arc_gpu() -> bool:
        """
        æ£€æŸ¥Intel Arc GPUæ˜¯å¦å¯ç”¨
        Returns:
            bool: GPUæ˜¯å¦å¯ç”¨
        """
        try:
            import intel_extension_for_pytorch as ipex
            if torch.xpu.is_available():
                device_count = torch.xpu.device_count()
                device_name = torch.xpu.get_device_name(0)
                logger.info(f"âœ… æ£€æµ‹åˆ°Intel GPU: {device_name}")
                logger.info(f"   GPUæ•°é‡: {device_count}")
                return True
            else:
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°Intel XPUè®¾å¤‡")
                return False
        except ImportError:
            logger.error("âŒ Intel Extension for PyTorchæœªå®‰è£…")
            return False
        except Exception as e:
            logger.error(f"âŒ GPUæ£€æµ‹å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def get_device() -> torch.device:
        """
        è·å–æœ€ä½³è®¡ç®—è®¾å¤‡
        Returns:
            torch.device: è®¡ç®—è®¾å¤‡
        """
        if ArcGPUDetector.check_arc_gpu():
            return torch.device("xpu:0")
        else:
            return torch.device("cpu")
    
    @staticmethod
    def get_gpu_info() -> Dict[str, any]:
        """
        è·å–GPUä¿¡æ¯
        Returns:
            Dict: GPUä¿¡æ¯å­—å…¸
        """
        info = {
            'available': False,
            'device_name': None,
            'device_count': 0,
            'memory_info': {}
        }
        
        try:
            import intel_extension_for_pytorch as ipex
            if torch.xpu.is_available():
                info['available'] = True
                info['device_name'] = torch.xpu.get_device_name(0)
                info['device_count'] = torch.xpu.device_count()
                
                # è·å–å†…å­˜ä¿¡æ¯
                for i in range(torch.xpu.device_count()):
                    props = torch.xpu.get_device_properties(i)
                    info['memory_info'][f'device_{i}'] = {
                        'total_memory': props.total_memory,
                        'name': props.name
                    }
        except Exception as e:
            logger.warning(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
        
        return info
    
    @staticmethod
    def print_gpu_status():
        """æ‰“å°GPUçŠ¶æ€ä¿¡æ¯"""
        info = ArcGPUDetector.get_gpu_info()
        
        print("ğŸ–¥ï¸ GPUçŠ¶æ€ä¿¡æ¯")
        print("=" * 50)
        
        if info['available']:
            print(f"âœ… GPUå¯ç”¨: {info['device_name']}")
            print(f"ğŸ“Š GPUæ•°é‡: {info['device_count']}")
            
            for device_id, memory_info in info['memory_info'].items():
                total_gb = memory_info['total_memory'] / (1024**3)
                print(f"ğŸ’¾ {device_id}: {memory_info['name']} ({total_gb:.1f} GB)")
        else:
            print("âŒ GPUä¸å¯ç”¨")
            print("ğŸ’¡ å»ºè®®å®‰è£…Intel Extension for PyTorch")
        
        print("=" * 50) 