import requests
import time
import re
import json
import os
import csv
from datetime import datetime
from tqdm import tqdm
from collections import defaultdict

# åŠ è½½é…ç½®
def load_config(config_file='config_extended.json'):
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºé…ç½®æ–‡ä»¶")
        return None
    except json.JSONDecodeError:
        print(f"âŒ é…ç½®æ–‡ä»¶ {config_file} æ ¼å¼é”™è¯¯")
        return None

# å¢å¼ºçš„æ—¥å¿—è¯†åˆ«
def is_log_text_enhanced(text, log_keywords):
    # åŸºç¡€æ—¥å¿—å…³é”®è¯æ£€æŸ¥
    if any(k.lower() in text.lower() for k in log_keywords):
        return True
    
    # æ›´ç²¾ç¡®çš„æ—¥å¿—æ¨¡å¼åŒ¹é…
    log_patterns = [
        r'\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}',  # æ—¶é—´æˆ³
        r'\[\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\]',  # å¸¦æ–¹æ‹¬å·çš„æ—¶é—´æˆ³
        r'ERROR|WARN|INFO|DEBUG|TRACE|FATAL',  # æ—¥å¿—çº§åˆ«
        r'Exception\s+in\s+thread',  # çº¿ç¨‹å¼‚å¸¸
        r'Caused\s+by:',  # å¼‚å¸¸é“¾
        r'at\s+[\w\.$]+\([^)]*\)',  # å †æ ˆè·Ÿè¸ª
        r'java\.lang\.',  # Javaå¼‚å¸¸
        r'org\.springframework\.',  # Springå¼‚å¸¸
        r'org\.hibernate\.',  # Hibernateå¼‚å¸¸
        r'org\.apache\.',  # Apacheå¼‚å¸¸
        r'com\.mysql\.',  # MySQLå¼‚å¸¸
        r'redis\.',  # Rediså¼‚å¸¸
        r'kafka\.',  # Kafkaå¼‚å¸¸
        r'rabbitmq\.',  # RabbitMQå¼‚å¸¸
        r'Connection\s+refused',  # è¿æ¥é”™è¯¯
        r'Connection\s+timeout',  # è¿æ¥è¶…æ—¶
        r'SQL\s+state',  # SQLçŠ¶æ€
        r'ORA-\d+',  # Oracleé”™è¯¯
        r'MySQL\s+error',  # MySQLé”™è¯¯
        r'PostgreSQL\s+error',  # PostgreSQLé”™è¯¯
        r'Authentication\s+failed',  # è®¤è¯å¤±è´¥
        r'Authorization\s+denied',  # æˆæƒæ‹’ç»
        r'Validation\s+failed',  # éªŒè¯å¤±è´¥
        r'Transaction\s+rollback',  # äº‹åŠ¡å›æ»š
        r'Deadlock\s+found',  # æ­»é”
        r'Lock\s+wait\s+timeout',  # é”ç­‰å¾…è¶…æ—¶
        r'OutOfMemoryError',  # å†…å­˜æº¢å‡º
        r'StackOverflowError',  # æ ˆæº¢å‡º
        r'ClassNotFoundException',  # ç±»æœªæ‰¾åˆ°
        r'NoSuchMethodException',  # æ–¹æ³•æœªæ‰¾åˆ°
        r'IllegalStateException',  # éæ³•çŠ¶æ€å¼‚å¸¸
        r'BeanCreationException',  # Beanåˆ›å»ºå¼‚å¸¸
        r'NoSuchBeanDefinitionException',  # Beanå®šä¹‰æœªæ‰¾åˆ°
        r'CircularDependencyException',  # å¾ªç¯ä¾èµ–å¼‚å¸¸
        r'DataIntegrityViolationException',  # æ•°æ®å®Œæ•´æ€§è¿åå¼‚å¸¸
        r'JdbcSQLException',  # JDBC SQLå¼‚å¸¸
        r'HttpMessageNotReadableException',  # HTTPæ¶ˆæ¯ä¸å¯è¯»å¼‚å¸¸
        r'MethodArgumentNotValidException',  # æ–¹æ³•å‚æ•°éªŒè¯å¼‚å¸¸
        r'BindException',  # ç»‘å®šå¼‚å¸¸
        r'TypeMismatchException',  # ç±»å‹ä¸åŒ¹é…å¼‚å¸¸
        r'MissingServletRequestParameterException',  # ç¼ºå°‘è¯·æ±‚å‚æ•°å¼‚å¸¸
        r'HttpRequestMethodNotSupportedException',  # HTTPæ–¹æ³•ä¸æ”¯æŒå¼‚å¸¸
        r'HttpMediaTypeNotSupportedException',  # HTTPåª’ä½“ç±»å‹ä¸æ”¯æŒå¼‚å¸¸
        r'NoHandlerFoundException',  # å¤„ç†å™¨æœªæ‰¾åˆ°å¼‚å¸¸
        r'AsyncRequestTimeoutException',  # å¼‚æ­¥è¯·æ±‚è¶…æ—¶å¼‚å¸¸
        r'ResponseStatusException',  # å“åº”çŠ¶æ€å¼‚å¸¸
        r'AccessDeniedException',  # è®¿é—®æ‹’ç»å¼‚å¸¸
        r'BadCredentialsException',  # å‡­æ®é”™è¯¯å¼‚å¸¸
        r'UsernameNotFoundException',  # ç”¨æˆ·åæœªæ‰¾åˆ°å¼‚å¸¸
        r'AccountExpiredException',  # è´¦æˆ·è¿‡æœŸå¼‚å¸¸
        r'LockedException',  # è´¦æˆ·é”å®šå¼‚å¸¸
        r'DisabledException',  # è´¦æˆ·ç¦ç”¨å¼‚å¸¸
        r'CredentialsExpiredException',  # å‡­æ®è¿‡æœŸå¼‚å¸¸
        r'InvalidTokenException',  # æ— æ•ˆä»¤ç‰Œå¼‚å¸¸
        r'TokenExpiredException',  # ä»¤ç‰Œè¿‡æœŸå¼‚å¸¸
        r'JwtException',  # JWTå¼‚å¸¸
        r'OAuth2AuthenticationException',  # OAuth2è®¤è¯å¼‚å¸¸
        r'InvalidGrantException',  # æ— æ•ˆæˆæƒå¼‚å¸¸
        r'RedirectMismatchException',  # é‡å®šå‘ä¸åŒ¹é…å¼‚å¸¸
        r'UnsupportedGrantTypeException',  # ä¸æ”¯æŒçš„æˆæƒç±»å‹å¼‚å¸¸
        r'InvalidClientException',  # æ— æ•ˆå®¢æˆ·ç«¯å¼‚å¸¸
        r'InvalidScopeException',  # æ— æ•ˆä½œç”¨åŸŸå¼‚å¸¸
        r'InsufficientScopeException',  # ä½œç”¨åŸŸä¸è¶³å¼‚å¸¸
        r'InvalidRequestException',  # æ— æ•ˆè¯·æ±‚å¼‚å¸¸
        r'UnsupportedResponseTypeException',  # ä¸æ”¯æŒçš„å“åº”ç±»å‹å¼‚å¸¸
        r'UserDeniedAuthorizationException',  # ç”¨æˆ·æ‹’ç»æˆæƒå¼‚å¸¸
    ]
    
    return any(re.search(pattern, text, re.IGNORECASE) for pattern in log_patterns)

# æ¸…ç†å’Œæ ‡å‡†åŒ–æ—¥å¿—æ–‡æœ¬
def clean_log_text(text):
    # ç§»é™¤ä»£ç å—æ ‡è®°
    text = re.sub(r'^```[\w]*\n?', '', text, flags=re.MULTILINE)
    text = re.sub(r'\n?```$', '', text, flags=re.MULTILINE)
    
    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    text = re.sub(r'\n\s*\n', '\n', text)
    
    # ç§»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    
    return text

# è·å–æ‰€æœ‰ issue åˆ—è¡¨
def fetch_issues(owner_repo, headers, max_pages, state="all"):
    issues = []
    print(f"\nğŸ“¥ æ­£åœ¨çˆ¬å–ä»“åº“: {owner_repo}")
    print(f"ğŸ” ç›®æ ‡é¡µæ•°: {max_pages} (æ¯é¡µæœ€å¤š100ä¸ªissues)")
    
    for page in tqdm(range(1, max_pages + 1), desc=f"è·å– {owner_repo} issues"):
        url = f"https://api.github.com/repos/{owner_repo}/issues?page={page}&per_page=100&state={state}"
        
        print(f"\nğŸ“¡ è¯·æ±‚ç¬¬ {page} é¡µ: {url}")
        
        try:
            res = requests.get(url, headers=headers, timeout=30)
        except requests.exceptions.Timeout:
            error_msg = f"âŒ è¯·æ±‚è¶…æ—¶: {url}"
            print(error_msg)
            raise Exception(f"ç½‘ç»œè¶…æ—¶ - {owner_repo} ç¬¬{page}é¡µ")
        except requests.exceptions.ConnectionError:
            error_msg = f"âŒ è¿æ¥é”™è¯¯: æ— æ³•è¿æ¥åˆ°GitHub API"
            print(error_msg)
            raise Exception(f"ç½‘ç»œè¿æ¥å¤±è´¥ - {owner_repo}")
        except requests.exceptions.RequestException as e:
            error_msg = f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}"
            print(error_msg)
            raise Exception(f"è¯·æ±‚å¤±è´¥ - {owner_repo}: {str(e)}")
        
        if res.status_code == 200:
            print(f"âœ… ç¬¬ {page} é¡µè¯·æ±‚æˆåŠŸ")
        elif res.status_code == 403:
            error_msg = f"âŒ APIé™æµ (HTTP 403): {owner_repo}"
            print(error_msg)
            print(f"ğŸ“Š å‰©ä½™è¯·æ±‚æ¬¡æ•°: {res.headers.get('X-RateLimit-Remaining', 'Unknown')}")
            print(f"ğŸ• é‡ç½®æ—¶é—´: {res.headers.get('X-RateLimit-Reset', 'Unknown')}")
            raise Exception(f"APIé™æµ - {owner_repo}")
        elif res.status_code == 404:
            error_msg = f"âŒ ä»“åº“ä¸å­˜åœ¨ (HTTP 404): {owner_repo}"
            print(error_msg)
            raise Exception(f"ä»“åº“ä¸å­˜åœ¨ - {owner_repo}")
        elif res.status_code == 401:
            error_msg = f"âŒ è®¤è¯å¤±è´¥ (HTTP 401): è¯·æ£€æŸ¥GitHub Token"
            print(error_msg)
            raise Exception(f"è®¤è¯å¤±è´¥ - è¯·æ£€æŸ¥Token")
        else:
            error_msg = f"âŒ HTTPé”™è¯¯ {res.status_code}: {owner_repo}"
            print(error_msg)
            try:
                error_detail = res.json().get('message', 'æœªçŸ¥é”™è¯¯')
                print(f"ğŸ“ é”™è¯¯è¯¦æƒ…: {error_detail}")
            except:
                print(f"ğŸ“ å“åº”å†…å®¹: {res.text[:200]}...")
            raise Exception(f"HTTP {res.status_code} - {owner_repo}")
            
        try:
            data = res.json()
        except json.JSONDecodeError:
            error_msg = f"âŒ JSONè§£æå¤±è´¥: {owner_repo} ç¬¬{page}é¡µ"
            print(error_msg)
            raise Exception(f"JSONè§£æå¤±è´¥ - {owner_repo}")
            
        if not data:
            print(f"ğŸ“„ ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œåœæ­¢è·å–")
            break
            
        print(f"âœ… ç¬¬ {page} é¡µè·å–åˆ° {len(data)} ä¸ªissues")
        issues.extend(data)
        
        # æ˜¾ç¤ºAPIé™åˆ¶ä¿¡æ¯
        remaining = res.headers.get('X-RateLimit-Remaining')
        if remaining:
            print(f"ğŸ“Š APIå‰©ä½™è¯·æ±‚æ¬¡æ•°: {remaining}")
            if int(remaining) < 10:
                print(f"âš ï¸  APIè¯·æ±‚æ¬¡æ•°å³å°†è€—å°½ï¼Œå»ºè®®ç¨åå†è¯•")
        
        time.sleep(0.5)  # é¿å…é™æµ
        
    print(f"\nğŸ¯ {owner_repo} æ€»å…±è·å–åˆ° {len(issues)} ä¸ªissues")
    return issues

# æŠ½å–æ—¥å¿—ä»£ç ç‰‡æ®µ
def extract_logs_from_body(body, issue_info, log_keywords):
    logs = []
    
    if not body:
        return logs

    print(f"  ğŸ” åˆ†æIssue #{issue_info['number']}: {issue_info['title'][:50]}...")
    
    try:
        # åŒ¹é… ```xxx``` ä»£ç å—
        code_blocks = re.findall(r"```[\s\S]*?```", body, re.MULTILINE)
        print(f"    ğŸ“ æ‰¾åˆ° {len(code_blocks)} ä¸ªä»£ç å—")
        
        log_blocks_found = 0
        for block in code_blocks:
            if is_log_text_enhanced(block, log_keywords):
                cleaned_log = clean_log_text(block)
                if cleaned_log and len(cleaned_log) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                    logs.append({
                        'timestamp': datetime.now().isoformat(),
                        'message': cleaned_log,
                        'label': 'unknown',  # å¾…æ ‡æ³¨
                        'source': 'github_issue',
                        'repository': issue_info['repository'],
                        'issue_number': issue_info['number'],
                        'issue_title': issue_info['title'],
                        'issue_url': issue_info['url'],
                        'category': issue_info.get('category', 'unknown')
                    })
                    log_blocks_found += 1
        
        if log_blocks_found > 0:
            print(f"    âœ… ä»ä»£ç å—ä¸­æå–åˆ° {log_blocks_found} æ¡æ—¥å¿—")

        # åŒ¹é… inline æŠ¥é”™ä¿¡æ¯ï¼ˆä¸åœ¨ ``` ä¸­ï¼‰
        lines = body.split("\n")
        current_log = []
        inline_logs_found = 0
        
        for line in lines:
            line = line.strip()
            if is_log_text_enhanced(line, log_keywords):
                current_log.append(line)
            elif current_log and line == "":
                # ç©ºè¡Œå¯èƒ½æ˜¯æ—¥å¿—çš„ä¸€éƒ¨åˆ†
                current_log.append(line)
            elif current_log:
                # éæ—¥å¿—è¡Œï¼Œä¿å­˜å½“å‰æ—¥å¿—
                log_text = "\n".join(current_log).strip()
                if len(log_text) > 20:
                    logs.append({
                        'timestamp': datetime.now().isoformat(),
                        'message': log_text,
                        'label': 'unknown',
                        'source': 'github_issue',
                        'repository': issue_info['repository'],
                        'issue_number': issue_info['number'],
                        'issue_title': issue_info['title'],
                        'issue_url': issue_info['url'],
                        'category': issue_info.get('category', 'unknown')
                    })
                    inline_logs_found += 1
                current_log = []
        
        # å¤„ç†æœ€åä¸€ä¸ªæ—¥å¿—
        if current_log:
            log_text = "\n".join(current_log).strip()
            if len(log_text) > 20:
                logs.append({
                    'timestamp': datetime.now().isoformat(),
                    'message': log_text,
                    'label': 'unknown',
                    'source': 'github_issue',
                    'repository': issue_info['repository'],
                    'issue_number': issue_info['number'],
                    'issue_title': issue_info['title'],
                    'issue_url': issue_info['url'],
                    'category': issue_info.get('category', 'unknown')
                })
                inline_logs_found += 1
        
        if inline_logs_found > 0:
            print(f"    âœ… ä»å†…è”æ–‡æœ¬ä¸­æå–åˆ° {inline_logs_found} æ¡æ—¥å¿—")
        
        total_logs = log_blocks_found + inline_logs_found
        if total_logs == 0:
            print(f"    âšª Issue #{issue_info['number']} æœªå‘ç°æ—¥å¿—å†…å®¹")
        else:
            print(f"    ğŸ¯ Issue #{issue_info['number']} æ€»å…±æå–åˆ° {total_logs} æ¡æ—¥å¿—")

    except Exception as e:
        error_msg = f"âŒ å¤„ç†Issue #{issue_info['number']} æ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­å¤„ç†å…¶ä»–issues
        
    return logs

# ä¿å­˜æ•°æ®é›†
def save_dataset(logs, repository, output_dir, category='unknown'):
    if not logs:
        print(f"âš ï¸  {repository}: æ²¡æœ‰æ—¥å¿—æ•°æ®éœ€è¦ä¿å­˜")
        return
        
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        
        # ç”Ÿæˆæ–‡ä»¶å
        repo_name = repository.replace('/', '_')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_filename = f"{repo_name}_logs_{timestamp}_{category}.csv"
        csv_path = os.path.join(output_dir, csv_filename)
        
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°æ–‡ä»¶: {csv_filename}")
        
        # ä¿å­˜ä¸ºCSVæ ¼å¼
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['timestamp', 'message', 'label', 'source', 'repository', 
                         'issue_number', 'issue_title', 'issue_url', 'category']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for log in logs:
                writer.writerow(log)
        
        print(f"âœ… {repository}: æˆåŠŸä¿å­˜ {len(logs)} æ¡æ—¥å¿—åˆ° {csv_filename}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(csv_path) / 1024:.2f} KB")
        
    except PermissionError:
        error_msg = f"âŒ æƒé™é”™è¯¯: æ— æ³•å†™å…¥æ–‡ä»¶ {csv_path}"
        print(error_msg)
        raise Exception(f"æ–‡ä»¶å†™å…¥æƒé™é”™è¯¯ - {repository}")
    except OSError as e:
        error_msg = f"âŒ æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        raise Exception(f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ - {repository}: {str(e)}")
    except Exception as e:
        error_msg = f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ - {repository}: {str(e)}")

# å¤„ç†å•ä¸ªä»“åº“
def process_repository(repo, headers, config, category='unknown'):
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹å¤„ç†ä»“åº“: {repo} (ç±»åˆ«: {category})")
    print(f"{'='*60}")
    
    try:
        issues = fetch_issues(repo, headers, config['max_pages'])
    except Exception as e:
        error_msg = f"âŒ è·å–issueså¤±è´¥: {str(e)}"
        print(error_msg)
        raise Exception(f"è·å–issueså¤±è´¥ - {repo}: {str(e)}")
    
    all_logs = []
    
    print(f"\nğŸ“‹ å¼€å§‹åˆ†æ {len(issues)} ä¸ªissues...")
    
    for i, issue in enumerate(tqdm(issues, desc=f"å¤„ç† {repo} issues"), 1):
        try:
            issue_info = {
                'repository': repo,
                'number': issue.get('number'),
                'title': issue.get('title', ''),
                'url': issue.get('html_url', ''),
                'category': category
            }
            
            print(f"\nğŸ“„ [{i}/{len(issues)}] å¤„ç†Issue #{issue_info['number']}")
            print(f"ğŸ“ æ ‡é¢˜: {issue_info['title']}")
            print(f"ğŸ”— é“¾æ¥: {issue_info['url']}")
            
            # æå–issueæ­£æ–‡ä¸­çš„æ—¥å¿—
            logs = extract_logs_from_body(issue.get("body", ""), issue_info, config['log_keywords'])
            all_logs.extend(logs)

            # æå–è¯„è®ºä¸­çš„æ—¥å¿—
            comments_url = issue.get("comments_url")
            if comments_url:
                print(f"  ğŸ’¬ è·å–è¯„è®º: {comments_url}")
                try:
                    res = requests.get(comments_url, headers=headers, timeout=30)
                    if res.status_code == 200:
                        comments = res.json()
                        print(f"  ğŸ“¨ æ‰¾åˆ° {len(comments)} æ¡è¯„è®º")
                        
                        comment_logs_total = 0
                        for j, comment in enumerate(comments, 1):
                            print(f"    ğŸ’¬ åˆ†æè¯„è®º {j}/{len(comments)}")
                            comment_logs = extract_logs_from_body(comment.get("body", ""), issue_info, config['log_keywords'])
                            all_logs.extend(comment_logs)
                            comment_logs_total += len(comment_logs)
                        
                        if comment_logs_total > 0:
                            print(f"  âœ… ä»è¯„è®ºä¸­æ€»å…±æå–åˆ° {comment_logs_total} æ¡æ—¥å¿—")
                        else:
                            print(f"  âšª è¯„è®ºä¸­æœªå‘ç°æ—¥å¿—å†…å®¹")
                    else:
                        print(f"  âŒ è·å–è¯„è®ºå¤±è´¥: HTTP {res.status_code}")
                except requests.exceptions.RequestException as e:
                    print(f"  âŒ è·å–è¯„è®ºæ—¶ç½‘ç»œé”™è¯¯: {str(e)}")
                    # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                
                time.sleep(0.3)  # é¿å…é™æµ
            else:
                print(f"  âšª è¯¥Issueæ— è¯„è®º")
            
            print(f"ğŸ“Š å½“å‰ç´¯è®¡æ—¥å¿—æ•°é‡: {len(all_logs)}")
            
        except Exception as e:
            print(f"âŒ å¤„ç†Issue #{issue.get('number', 'Unknown')} æ—¶å‡ºé”™: {str(e)}")
            # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªissueï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
            continue

    # ä¿å­˜è¯¥ä»“åº“çš„æ•°æ®é›†
    print(f"\nğŸ’¾ å¼€å§‹ä¿å­˜ {repo} çš„æ•°æ®é›†...")
    try:
        save_dataset(all_logs, repo, config['output_directory'], category)
    except Exception as e:
        error_msg = f"âŒ ä¿å­˜æ•°æ®é›†å¤±è´¥: {str(e)}"
        print(error_msg)
        raise Exception(f"ä¿å­˜æ•°æ®é›†å¤±è´¥ - {repo}: {str(e)}")
    
    print(f"\nğŸ‰ {repo} å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {len(all_logs)} æ¡æ—¥å¿—")
    
    return len(all_logs)

# æŒ‰ç±»åˆ«å¤„ç†ä»“åº“
def process_by_category(config, headers):
    category_stats = defaultdict(lambda: {'total_logs': 0, 'successful_repos': 0, 'failed_repos': []})
    
    for category, repos in config['categories'].items():
        print(f"\n{'='*80}")
        print(f"ğŸ¯ å¼€å§‹å¤„ç†ç±»åˆ«: {category}")
        print(f"ğŸ“‹ åŒ…å«ä»“åº“: {', '.join(repos)}")
        print(f"{'='*80}")
        
        for repo in repos:
            try:
                log_count = process_repository(repo, headers, config, category)
                category_stats[category]['total_logs'] += log_count
                category_stats[category]['successful_repos'] += 1
                print(f"âœ… {repo} å¤„ç†æˆåŠŸï¼Œè·å– {log_count} æ¡æ—¥å¿—")
            except Exception as e:
                error_msg = f"âŒ å¤„ç†ä»“åº“ {repo} æ—¶å‡ºé”™: {str(e)}"
                print(error_msg)
                category_stats[category]['failed_repos'].append(repo)
                continue
    
    return category_stats

# ä¸»å‡½æ•°
def main():
    print("ğŸš€ GitHub Issue æ—¥å¿—çˆ¬å–å·¥å…· - å¢å¼ºç‰ˆ")
    print("=" * 60)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åŠ è½½é…ç½®
    print("\nğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶...")
    config = load_config('config_extended.json')
    if not config:
        return
    
    print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
    print(f"ğŸ¯ ç›®æ ‡ä»“åº“æ•°é‡: {len(config['repositories'])}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {config['output_directory']}")
    print(f"ğŸ“„ æ¯ä¸ªä»“åº“æœ€å¤§é¡µæ•°: {config['max_pages']}")
    
    # æ˜¾ç¤ºç±»åˆ«ä¿¡æ¯
    print("\nğŸ“‹ æŒ‰ç±»åˆ«ç»„ç»‡çš„ä»“åº“:")
    for category, repos in config['categories'].items():
        print(f"  ğŸ·ï¸  {category}: {len(repos)} ä¸ªä»“åº“")
        for repo in repos:
            print(f"    â€¢ {repo}")
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {"Authorization": f"token {config['github_token']}"}
    print(f"\nğŸ”‘ ä½¿ç”¨GitHub Token: {config['github_token'][:10]}...")
    
    # æŒ‰ç±»åˆ«å¤„ç†
    category_stats = process_by_category(config, headers)
    
    # æœ€ç»ˆç»Ÿè®¡
    print("\n" + "=" * 80)
    print("ğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆï¼")
    print("=" * 80)
    print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    total_logs = 0
    total_successful = 0
    total_failed = 0
    
    print(f"\nğŸ“Š æŒ‰ç±»åˆ«ç»Ÿè®¡:")
    for category, stats in category_stats.items():
        print(f"\nğŸ·ï¸  {category}:")
        print(f"  ğŸ“Š æ—¥å¿—æ•°é‡: {stats['total_logs']} æ¡")
        print(f"  âœ… æˆåŠŸä»“åº“: {stats['successful_repos']} ä¸ª")
        if stats['failed_repos']:
            print(f"  âŒ å¤±è´¥ä»“åº“: {len(stats['failed_repos'])} ä¸ª")
            for repo in stats['failed_repos']:
                print(f"    â€¢ {repo}")
        
        total_logs += stats['total_logs']
        total_successful += stats['successful_repos']
        total_failed += len(stats['failed_repos'])
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  ğŸ¯ æ€»æ—¥å¿—æ•°é‡: {total_logs} æ¡")
    print(f"  âœ… æˆåŠŸå¤„ç†ä»“åº“: {total_successful} ä¸ª")
    print(f"  âŒ å¤±è´¥ä»“åº“: {total_failed} ä¸ª")
    print(f"  ğŸ“ è¾“å‡ºç›®å½•: {config['output_directory']}")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    if total_logs > 0:
        print("1. æ£€æŸ¥è¾“å‡ºç›®å½•ä¸­çš„CSVæ–‡ä»¶")
        print("2. ä½¿ç”¨ log_reviewer.py å·¥å…·æ¥æ ‡æ³¨å’ŒéªŒè¯æ—¥å¿—")
        print("3. å°†æ ‡æ³¨å¥½çš„æ•°æ®ç”¨äºè®­ç»ƒæ—¥å¿—åˆ†ç±»æ¨¡å‹")
        print("4. åˆ†æä¸åŒç±»åˆ«çš„æ—¥å¿—åˆ†å¸ƒï¼Œä¼˜åŒ–æ•°æ®å¹³è¡¡")
    
    if total_failed > 0:
        print("5. æ£€æŸ¥å¤±è´¥ä»“åº“çš„é”™è¯¯ä¿¡æ¯")
        print("6. ä¿®å¤é—®é¢˜åé‡æ–°è¿è¡Œè„šæœ¬")
    
    if total_logs > 0:
        print(f"\nğŸŠ æ­å–œï¼æˆåŠŸè·å–äº† {total_logs} æ¡æ—¥å¿—æ•°æ®")
        print("ğŸ“ˆ æ•°æ®è¦†ç›–äº†å¤šç§Spring Bootåº”ç”¨åœºæ™¯ï¼Œå°†æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ï¼")
    else:
        print("\nâš ï¸  æœªè·å–åˆ°ä»»ä½•æ—¥å¿—æ•°æ®ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
