"""
Baselineæ¨¡å‹å®ç°
åŸºäºTF-IDF + LightGBMå’ŒFastTextçš„æ—¥å¿—åˆ†ç±»æ¨¡å‹
é€‚é…Intel XPUç¯å¢ƒ
"""
import os
import pandas as pd
import numpy as np
import joblib
import time
import psutil
from typing import Dict, List, Tuple, Optional
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
import lightgbm as lgb
# import fasttext  # æš‚æ—¶æ³¨é‡Šæ‰ï¼Œå› ä¸ºç¼–è¯‘é—®é¢˜
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import logging
from tqdm import tqdm
from utils import setup_logging, get_device, check_xpu_availability

class BaselineLogClassifier:
    """Baselineæ—¥å¿—åˆ†ç±»å™¨"""
    
    def __init__(self, model_type: str = "lightgbm", use_xpu: bool = True):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ("lightgbm" æˆ– "fasttext")
            use_xpu: æ˜¯å¦ä½¿ç”¨Intel XPU
        """
        self.logger = setup_logging()
        self.model_type = model_type
        self.use_xpu = use_xpu and check_xpu_availability()
        
        # æ¨¡å‹ç»„ä»¶
        self.vectorizer = None
        self.model = None
        self.label_encoder = None
        
        # è®­ç»ƒå‚æ•°
        self.tfidf_params = {
            'max_features': 10000,
            'ngram_range': (1, 2),
            'min_df': 2,
            'max_df': 0.95
        }
        
        self.lightgbm_params = {
            'objective': 'multiclass',
            'metric': 'multi_logloss',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.9,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'random_state': 42
        }
        
        self.fasttext_params = {
            'lr': 0.1,
            'epoch': 25,
            'wordNgrams': 2,
            'minCount': 2,
            'minn': 3,
            'maxn': 6,
            'verbose': 2
        }
        
        self.logger.info(f"åˆå§‹åŒ–Baselineåˆ†ç±»å™¨ - æ¨¡å‹ç±»å‹: {model_type}, XPU: {self.use_xpu}")
        
        # æ€§èƒ½ç›‘æ§
        self.start_time = None
        self.memory_usage = []
    
    def _log_performance(self, step_name: str, start_time: float = None):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        current_time = time.time()
        memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        self.memory_usage.append((step_name, current_time, memory))
        
        if start_time:
            elapsed = current_time - start_time
            self.logger.info(f"â±ï¸  {step_name} å®Œæˆ - è€—æ—¶: {elapsed:.2f}ç§’, å†…å­˜: {memory:.1f}MB")
        else:
            self.logger.info(f"ğŸš€ {step_name} å¼€å§‹ - å†…å­˜: {memory:.1f}MB")
        
        return current_time
    
    def _get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡(MB)"""
        return psutil.Process().memory_info().rss / 1024 / 1024
    
    def load_data_from_categories(self, data_dir: str) -> Tuple[pd.DataFrame, List[str]]:
        """
        ä»åˆ†ç±»ç›®å½•åŠ è½½æ•°æ®
        
        Args:
            data_dir: DATA_OUTPUTç›®å½•è·¯å¾„
            
        Returns:
            æ•°æ®æ¡†å’Œç±»åˆ«åˆ—è¡¨
        """
        start_time = self._log_performance("æ•°æ®åŠ è½½")
        self.logger.info(f"ğŸ“ ä»ç›®å½•åŠ è½½æ•°æ®: {data_dir}")
        
        all_data = []
        categories = []
        total_files = 0
        processed_files = 0
        
        # ç»Ÿè®¡æ–‡ä»¶æ€»æ•°
        for item in os.listdir(data_dir):
            item_path = os.path.join(data_dir, item)
            if os.path.isdir(item_path) and item.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')):
                for file in os.listdir(item_path):
                    if file.endswith('.csv'):
                        total_files += 1
        
        self.logger.info(f"ğŸ“Š å‘ç° {total_files} ä¸ªCSVæ–‡ä»¶")
        
        # éå†æ‰€æœ‰åˆ†ç±»ç›®å½•
        for item in tqdm(os.listdir(data_dir), desc="éå†ç±»åˆ«ç›®å½•"):
            item_path = os.path.join(data_dir, item)
            if os.path.isdir(item_path) and item.startswith(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')):
                # æå–ç±»åˆ«åç§°
                category_name = item.split('_', 1)[1] if '_' in item else item
                categories.append(category_name)
                
                # è¯»å–è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰CSVæ–‡ä»¶
                for file in os.listdir(item_path):
                    if file.endswith('.csv'):
                        file_path = os.path.join(item_path, file)
                        processed_files += 1
                        try:
                            df = pd.read_csv(file_path)
                            if 'original_log' in df.columns:
                                df['category'] = category_name
                                df['category_id'] = len(categories) - 1
                                all_data.append(df[['original_log', 'category', 'category_id']])
                                
                                if processed_files % 10 == 0:  # æ¯å¤„ç†10ä¸ªæ–‡ä»¶è¾“å‡ºä¸€æ¬¡è¿›åº¦
                                    self.logger.info(f"ğŸ“ˆ å·²å¤„ç† {processed_files}/{total_files} ä¸ªæ–‡ä»¶")
                        except Exception as e:
                            self.logger.warning(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        if not all_data:
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®æ–‡ä»¶")
        
        combined_df = pd.concat(all_data, ignore_index=True)
        self.logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ - æ€»è®°å½•: {len(combined_df)}, ç±»åˆ«æ•°: {len(categories)}")
        
        self._log_performance("æ•°æ®åŠ è½½", start_time)
        return combined_df, categories
    
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        é¢„å¤„ç†æ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            
        Returns:
            é¢„å¤„ç†åçš„æ•°æ®æ¡†
        """
        start_time = self._log_performance("æ•°æ®é¢„å¤„ç†")
        self.logger.info(f"ğŸ§¹ å¼€å§‹æ•°æ®é¢„å¤„ç†... åŸå§‹è®°å½•æ•°: {len(df)}")
        
        # æ¸…æ´—æ–‡æœ¬
        self.logger.info("ğŸ“ å¼€å§‹æ–‡æœ¬æ¸…æ´—...")
        tqdm.pandas(desc="æ¸…æ´—æ—¥å¿—æ–‡æœ¬")
        df['cleaned_log'] = df['original_log'].fillna('').astype(str).progress_apply(self._clean_text)
        
        # ç§»é™¤ç©ºæ–‡æœ¬
        empty_count = len(df[df['cleaned_log'].str.len() == 0])
        df = df[df['cleaned_log'].str.len() > 0]
        self.logger.info(f"ğŸ—‘ï¸  ç§»é™¤ç©ºæ–‡æœ¬: {empty_count} æ¡")
        
        # ç§»é™¤é‡å¤
        original_count = len(df)
        df = df.drop_duplicates(subset=['cleaned_log'])
        duplicate_count = original_count - len(df)
        self.logger.info(f"ğŸ” ç§»é™¤é‡å¤: {duplicate_count} æ¡")
        
        self.logger.info(f"âœ… é¢„å¤„ç†å®Œæˆ - å‰©ä½™è®°å½•: {len(df)} æ¡")
        self._log_performance("æ•°æ®é¢„å¤„ç†", start_time)
        return df
    
    def _clean_text(self, text: str) -> str:
        """æ¸…æ´—æ–‡æœ¬"""
        import re
        
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­è‹±æ–‡æ•°å­—å’Œå¸¸ç”¨æ ‡ç‚¹
        text = re.sub(r'[^\w\s\u4e00-\u9fff.,!?;:-]', ' ', text)
        
        # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def train_tfidf_lightgbm(self, X_train: List[str], y_train: np.ndarray, 
                             X_val: Optional[List[str]] = None, 
                             y_val: Optional[np.ndarray] = None) -> None:
        """
        è®­ç»ƒTF-IDF + LightGBMæ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒæ–‡æœ¬åˆ—è¡¨
            y_train: è®­ç»ƒæ ‡ç­¾
            X_val: éªŒè¯æ–‡æœ¬åˆ—è¡¨
            y_val: éªŒè¯æ ‡ç­¾
        """
        start_time = self._log_performance("TF-IDFç‰¹å¾æå–")
        self.logger.info(f"ğŸ”¤ å¼€å§‹TF-IDFç‰¹å¾æå–... è®­ç»ƒæ ·æœ¬æ•°: {len(X_train)}")
        
        # TF-IDFç‰¹å¾æå–
        self.vectorizer = TfidfVectorizer(**self.tfidf_params)
        X_train_tfidf = self.vectorizer.fit_transform(X_train)
        
        if X_val is not None:
            X_val_tfidf = self.vectorizer.transform(X_val)
            self.logger.info(f"ğŸ“Š TF-IDFç‰¹å¾ç»´åº¦: {X_train_tfidf.shape}, éªŒè¯é›†: {X_val_tfidf.shape}")
        else:
            self.logger.info(f"ğŸ“Š TF-IDFç‰¹å¾ç»´åº¦: {X_train_tfidf.shape}")
        
        self._log_performance("TF-IDFç‰¹å¾æå–", start_time)
        
        # LightGBMè®­ç»ƒ
        train_start_time = self._log_performance("LightGBMæ¨¡å‹è®­ç»ƒ")
        self.logger.info(f"ğŸŒ³ å¼€å§‹LightGBMæ¨¡å‹è®­ç»ƒ... ç±»åˆ«æ•°: {len(np.unique(y_train))}")
        
        # è®¾ç½®LightGBMå‚æ•°
        train_params = self.lightgbm_params.copy()
        train_params['num_class'] = len(np.unique(y_train))
        
        # åˆ›å»ºæ•°æ®é›†
        train_data = lgb.Dataset(X_train_tfidf, label=y_train)
        if X_val is not None:
            val_data = lgb.Dataset(X_val_tfidf, label=y_val, reference=train_data)
            valid_sets = [train_data, val_data]
            valid_names = ['train', 'valid']
        else:
            valid_sets = [train_data]
            valid_names = ['train']
        
        # è®­ç»ƒæ¨¡å‹
        self.model = lgb.train(
            train_params,
            train_data,
            valid_sets=valid_sets,
            valid_names=valid_names,
            num_boost_round=100,
            callbacks=[lgb.log_evaluation(period=10)]
        )
        
        self._log_performance("LightGBMæ¨¡å‹è®­ç»ƒ", train_start_time)
        self.logger.info("âœ… TF-IDF + LightGBMæ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    def train_fasttext(self, X_train: List[str], y_train: np.ndarray,
                       X_val: Optional[List[str]] = None,
                       y_val: Optional[np.ndarray] = None) -> None:
        """
        è®­ç»ƒFastTextæ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒæ–‡æœ¬åˆ—è¡¨
            y_train: è®­ç»ƒæ ‡ç­¾
            X_val: éªŒè¯æ–‡æœ¬åˆ—è¡¨
            y_val: éªŒè¯æ ‡ç­¾
        """
        self.logger.info("FastTextæ¨¡å‹æš‚ä¸å¯ç”¨ï¼Œè¯·å®‰è£…Microsoft Visual C++ Build Tools")
        raise NotImplementedError("FastTextæ¨¡å‹æš‚ä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…Microsoft Visual C++ Build Tools")
    
    def train(self, data_dir: str, test_size: float = 0.2, 
              random_state: int = 42) -> Dict:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
            
        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        total_start_time = self._log_performance("å®Œæ•´è®­ç»ƒæµç¨‹")
        self.logger.info(f"ğŸ¯ å¼€å§‹å®Œæ•´è®­ç»ƒæµç¨‹ - æ•°æ®ç›®å½•: {data_dir}")
        
        # åŠ è½½æ•°æ®
        df, categories = self.load_data_from_categories(data_dir)
        
        # é¢„å¤„ç†æ•°æ®
        df = self.preprocess_data(df)
        
        # æ ‡ç­¾ç¼–ç 
        encode_start_time = self._log_performance("æ ‡ç­¾ç¼–ç ")
        self.label_encoder = LabelEncoder()
        y = self.label_encoder.fit_transform(df['category'])
        self.logger.info(f"ğŸ·ï¸  æ ‡ç­¾ç¼–ç å®Œæˆ - ç±»åˆ«æ•°: {len(categories)}")
        self._log_performance("æ ‡ç­¾ç¼–ç ", encode_start_time)
        
        # åˆ†å‰²æ•°æ®
        split_start_time = self._log_performance("æ•°æ®åˆ†å‰²")
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                df['cleaned_log'].tolist(), y,
                test_size=test_size,
                random_state=random_state,
                stratify=y
            )
            
            # è¿›ä¸€æ­¥åˆ†å‰²éªŒè¯é›†
            X_train, X_val, y_train, y_val = train_test_split(
                X_train, y_train,
                test_size=0.2,
                random_state=random_state,
                stratify=y_train
            )
        except ValueError:
            # å¦‚æœæ•°æ®å¤ªå°‘æ— æ³•åˆ†å±‚æŠ½æ ·ï¼Œä½¿ç”¨éšæœºåˆ†å‰²
            self.logger.warning("âš ï¸  æ•°æ®é‡è¾ƒå°‘ï¼Œä½¿ç”¨éšæœºåˆ†å‰²")
            X_train, X_test, y_train, y_test = train_test_split(
                df['cleaned_log'].tolist(), y,
                test_size=test_size,
                random_state=random_state
            )
            
            X_train, X_val, y_train, y_val = train_test_split(
                X_train, y_train,
                test_size=0.2,
                random_state=random_state
            )
        
        self.logger.info(f"ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ - è®­ç»ƒ: {len(X_train)}, éªŒè¯: {len(X_val)}, æµ‹è¯•: {len(X_test)}")
        self._log_performance("æ•°æ®åˆ†å‰²", split_start_time)
        
        # è®­ç»ƒæ¨¡å‹
        if self.model_type == "lightgbm":
            self.train_tfidf_lightgbm(X_train, y_train, X_val, y_val)
        elif self.model_type == "fasttext":
            self.train_fasttext(X_train, y_train, X_val, y_val)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
        
        # è¯„ä¼°æ¨¡å‹
        eval_start_time = self._log_performance("æ¨¡å‹è¯„ä¼°")
        self.logger.info("ğŸ“ˆ å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        train_metrics = self.evaluate(X_train, y_train, "è®­ç»ƒé›†")
        val_metrics = self.evaluate(X_val, y_val, "éªŒè¯é›†")
        test_metrics = self.evaluate(X_test, y_test, "æµ‹è¯•é›†")
        self._log_performance("æ¨¡å‹è¯„ä¼°", eval_start_time)
        
        # ä¿å­˜æ¨¡å‹
        save_start_time = self._log_performance("æ¨¡å‹ä¿å­˜")
        self.save_model()
        self._log_performance("æ¨¡å‹ä¿å­˜", save_start_time)
        
        # è¾“å‡ºæ€»ä½“æ€§èƒ½ç»Ÿè®¡
        self._log_performance("å®Œæ•´è®­ç»ƒæµç¨‹", total_start_time)
        self.logger.info("ğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼")
        
        return {
            'categories': categories,
            'train_metrics': train_metrics,
            'val_metrics': val_metrics,
            'test_metrics': test_metrics,
            'model_type': self.model_type,
            'performance_stats': self.memory_usage
        }
    
    def predict(self, texts: List[str]) -> np.ndarray:
        """
        é¢„æµ‹
        
        Args:
            texts: å¾…é¢„æµ‹çš„æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            é¢„æµ‹ç»“æœ
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨trainæ–¹æ³•")
        
        if self.model_type == "lightgbm":
            # TF-IDFç‰¹å¾æå–
            X_tfidf = self.vectorizer.transform(texts)
            # LightGBMé¢„æµ‹
            predictions = self.model.predict(X_tfidf)
            return np.argmax(predictions, axis=1)
        
        elif self.model_type == "fasttext":
            # FastTexté¢„æµ‹
            raise NotImplementedError("FastTextæ¨¡å‹æš‚ä¸å¯ç”¨")
            # predictions = []
            # for text in texts:
            #     pred = self.model.predict(text, k=1)
            #     # æå–æ ‡ç­¾ID
            #     label = pred[0][0].replace('__label__', '')
            #     predictions.append(int(label))
            # return np.array(predictions)
    
    def evaluate(self, X: List[str], y: np.ndarray, dataset_name: str = "") -> Dict:
        """
        è¯„ä¼°æ¨¡å‹
        
        Args:
            X: è¾“å…¥æ–‡æœ¬
            y: çœŸå®æ ‡ç­¾
            dataset_name: æ•°æ®é›†åç§°
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡
        """
        self.logger.info(f"ğŸ” å¼€å§‹è¯„ä¼° {dataset_name} - æ ·æœ¬æ•°: {len(X)}")
        
        predictions = self.predict(X)
        
        accuracy = accuracy_score(y, predictions)
        
        # åˆ†ç±»æŠ¥å‘Š
        report = classification_report(y, predictions, output_dict=True)
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y, predictions)
        
        metrics = {
            'accuracy': accuracy,
            'precision': report['weighted avg']['precision'],
            'recall': report['weighted avg']['recall'],
            'f1_score': report['weighted avg']['f1-score'],
            'confusion_matrix': cm
        }
        
        self.logger.info(f"ğŸ“Š {dataset_name}è¯„ä¼°ç»“æœ:")
        self.logger.info(f"   ğŸ“ˆ å‡†ç¡®ç‡: {accuracy:.4f}")
        self.logger.info(f"   ğŸ¯ ç²¾ç¡®ç‡: {metrics['precision']:.4f}")
        self.logger.info(f"   ğŸ”„ å¬å›ç‡: {metrics['recall']:.4f}")
        self.logger.info(f"   âš–ï¸  F1åˆ†æ•°: {metrics['f1_score']:.4f}")
        
        return metrics
    
    def save_model(self, model_dir: str = "models") -> None:
        """ä¿å­˜æ¨¡å‹"""
        self.logger.info(f"ğŸ’¾ å¼€å§‹ä¿å­˜æ¨¡å‹åˆ°ç›®å½•: {model_dir}")
        os.makedirs(model_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if self.model_type == "lightgbm":
            # ä¿å­˜LightGBMæ¨¡å‹å’ŒTF-IDFå‘é‡å™¨
            model_path = os.path.join(model_dir, f"lightgbm_model_{timestamp}.txt")
            vectorizer_path = os.path.join(model_dir, f"tfidf_vectorizer_{timestamp}.joblib")
            label_encoder_path = os.path.join(model_dir, f"label_encoder_{timestamp}.joblib")
            
            self.logger.info(f"ğŸ’¾ ä¿å­˜LightGBMæ¨¡å‹: {model_path}")
            self.model.save_model(model_path)
            
            self.logger.info(f"ğŸ’¾ ä¿å­˜TF-IDFå‘é‡å™¨: {vectorizer_path}")
            joblib.dump(self.vectorizer, vectorizer_path)
            
            self.logger.info(f"ğŸ’¾ ä¿å­˜æ ‡ç­¾ç¼–ç å™¨: {label_encoder_path}")
            joblib.dump(self.label_encoder, label_encoder_path)
            
        elif self.model_type == "fasttext":
            # ä¿å­˜FastTextæ¨¡å‹
            raise NotImplementedError("FastTextæ¨¡å‹æš‚ä¸å¯ç”¨")
            # model_path = os.path.join(model_dir, f"fasttext_model_{timestamp}.bin")
            # label_encoder_path = os.path.join(model_dir, f"label_encoder_{timestamp}.joblib")
            # 
            # self.model.save_model(model_path)
            # joblib.dump(self.label_encoder, label_encoder_path)
        
        self.logger.info(f"âœ… æ¨¡å‹ä¿å­˜å®Œæˆ - æ—¶é—´æˆ³: {timestamp}")
    
    def load_model(self, model_dir: str, timestamp: str) -> None:
        """åŠ è½½æ¨¡å‹"""
        if self.model_type == "lightgbm":
            model_path = os.path.join(model_dir, f"lightgbm_model_{timestamp}.txt")
            vectorizer_path = os.path.join(model_dir, f"tfidf_vectorizer_{timestamp}.joblib")
            label_encoder_path = os.path.join(model_dir, f"label_encoder_{timestamp}.joblib")
            
            self.model = lgb.Booster(model_file=model_path)
            self.vectorizer = joblib.load(vectorizer_path)
            self.label_encoder = joblib.load(label_encoder_path)
            
        elif self.model_type == "fasttext":
            raise NotImplementedError("FastTextæ¨¡å‹æš‚ä¸å¯ç”¨")
            # model_path = os.path.join(model_dir, f"fasttext_model_{timestamp}.bin")
            # label_encoder_path = os.path.join(model_dir, f"label_encoder_{timestamp}.joblib")
            # 
            # self.model = fasttext.load_model(model_path)
            # self.label_encoder = joblib.load(label_encoder_path)
        
        self.logger.info(f"æ¨¡å‹å·²ä» {model_dir} åŠ è½½")
    
    def plot_confusion_matrix(self, cm: np.ndarray, categories: List[str], 
                             save_path: str = None) -> None:
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=categories, yticklabels=categories)
        plt.title('æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = BaselineLogClassifier(model_type="lightgbm", use_xpu=True)
    
    # è®­ç»ƒæ¨¡å‹
    data_dir = "../../DATA_OUTPUT"  # ç›¸å¯¹äºlogsense-xpuç›®å½•çš„è·¯å¾„
    results = classifier.train(data_dir)
    
    # æ‰“å°ç»“æœ
    print("\n=== è®­ç»ƒç»“æœ ===")
    print(f"æ¨¡å‹ç±»å‹: {results['model_type']}")
    print(f"ç±»åˆ«æ•°é‡: {len(results['categories'])}")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {results['test_metrics']['accuracy']:.4f}")
    print(f"æµ‹è¯•é›†F1åˆ†æ•°: {results['test_metrics']['f1_score']:.4f}")
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    classifier.plot_confusion_matrix(
        results['test_metrics']['confusion_matrix'],
        results['categories'],
        "confusion_matrix.png"
    )

if __name__ == "__main__":
    main() 