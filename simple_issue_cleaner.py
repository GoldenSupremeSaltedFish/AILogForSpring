# -*- coding: utf-8 -*-
"""
ç®€å•çš„Issueæ—¥å¿—æ•°æ®æ¸…æ´—è„šæœ¬
"""

import pandas as pd
import re
from pathlib import Path
from datetime import datetime

def clean_message(message):
    """æ¸…æ´—æ—¥å¿—æ¶ˆæ¯"""
    if pd.isna(message) or not isinstance(message, str):
        return ""
    
    # ç§»é™¤HTMLæ ‡ç­¾
    message = re.sub(r'<[^>]+>', '', message)
    
    # ç§»é™¤Markdownæ ¼å¼
    message = re.sub(r'\*\*([^*]+)\*\*', r'\1', message)
    message = re.sub(r'\*([^*]+)\*', r'\1', message)
    message = re.sub(r'`([^`]+)`', r'\1', message)
    
    # ç§»é™¤URL
    message = re.sub(r'http[s]?://[^\s]+', '', message)
    
    # ç§»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
    message = re.sub(r'\s+', ' ', message)
    message = message.strip()
    
    return message

def should_filter_message(message):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿‡æ»¤æ‰è¿™æ¡æ¶ˆæ¯"""
    if pd.isna(message) or not isinstance(message, str):
        return True
    
    # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ¶ˆæ¯
    if len(message.strip()) < 10:
        return True
    
    # è¿‡æ»¤æ‰åŒ…å«ç‰¹å®šæ¨¡å¼çš„æ¶ˆæ¯
    filter_patterns = [
        r'### What did you expect to happen',
        r'### What happened',
        r'### What did I do',
        r'@dependabot',
        r'Dependabot compatibility score',
        r'<li>.*</li>',
        r'<p>.*</p>',
        r'<code>.*</code>',
    ]
    
    for pattern in filter_patterns:
        if re.search(pattern, message, re.IGNORECASE):
            return True
    
    return False

def classify_log(message):
    """æ ¹æ®æ—¥å¿—å†…å®¹è‡ªåŠ¨åˆ†ç±»"""
    if pd.isna(message) or not isinstance(message, str):
        return 'unknown'
    
    message_lower = message.lower()
    
    # å®šä¹‰åˆ†ç±»è§„åˆ™
    patterns = {
        'stack_exception': [
            r'Exception|Error|Throwable|RuntimeException|NullPointerException',
            r'java\.lang\..*Exception',
            r'org\.springframework\..*Exception',
            r'Caused by:|at |Stack trace',
            r'java: cannot find symbol',
            r'compilation failed'
        ],
        'startup_failure': [
            r'Failed to start|Startup failed|Application startup failed',
            r'BeanCreationException|ContextLoadException',
            r'Port already in use|Address already in use',
            r'Database connection failed|Connection refused',
            r'Unable to start|Cannot start'
        ],
        'auth_error': [
            r'Authentication failed|Authorization failed',
            r'Access denied|Permission denied',
            r'Invalid token|Token expired',
            r'Unauthorized|Forbidden',
            r'Login failed|Password incorrect',
            r'LDAP.*error|OAuth.*error'
        ],
        'db_error': [
            r'SQLException|DatabaseException',
            r'Connection.*failed|Connection.*refused',
            r'Table.*not found|Column.*not found',
            r'Duplicate entry|Constraint violation',
            r'Deadlock|Lock timeout',
            r'MySQL|PostgreSQL|Oracle.*error'
        ],
        'connection_issue': [
            r'Connection.*timeout|Connection.*refused',
            r'Network.*unreachable|Host.*unreachable',
            r'Connection.*closed|Socket.*closed',
            r'Unable to connect|Failed to connect',
            r'Zookeeper.*connection|Redis.*connection'
        ],
        'timeout': [
            r'Timeout|timeout|TIMEOUT',
            r'Request.*timeout|Response.*timeout',
            r'Read.*timeout|Write.*timeout',
            r'Operation.*timeout|Execution.*timeout'
        ],
        'performance': [
            r'OutOfMemoryError|Memory.*full',
            r'GC.*overhead|Garbage collection',
            r'Performance.*issue|Slow.*query',
            r'CPU.*high|Memory.*leak'
        ],
        'config': [
            r'Configuration.*error|Config.*not found',
            r'Property.*not found|Environment.*variable',
            r'Invalid.*configuration|Missing.*property',
            r'YAML.*error|Properties.*error'
        ],
        'business': [
            r'Business.*error|Logic.*error',
            r'Validation.*failed|Invalid.*input',
            r'Business.*exception|Service.*exception'
        ],
        'normal': [
            r'INFO.*Started|INFO.*Running',
            r'DEBUG.*|TRACE.*',
            r'Application.*started|Server.*started',
            r'Health.*check|Heartbeat'
        ]
    }
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥å„ç±»åˆ«
    for category, category_patterns in patterns.items():
        for pattern in category_patterns:
            if re.search(pattern, message, re.IGNORECASE):
                return category
    
    return 'unknown'

def main():
    print("ğŸš€ å¼€å§‹å¤„ç†Issueæ—¥å¿—æ•°æ®...")
    
    # æŸ¥æ‰¾CSVæ–‡ä»¶
    input_dir = Path("issue-logs")
    output_dir = Path("DATA_OUTPUT")
    output_dir.mkdir(exist_ok=True)
    
    csv_files = list(input_dir.glob("*.csv"))
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        return
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    all_data = []
    for csv_file in csv_files:
        print(f"ğŸ“Š åŠ è½½: {csv_file.name}")
        try:
            df = pd.read_csv(csv_file)
            print(f"  - {len(df)} æ¡è®°å½•")
            all_data.append(df)
        except Exception as e:
            print(f"  âŒ è¯»å–å¤±è´¥: {e}")
    
    if not all_data:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return
    
    # åˆå¹¶æ•°æ®
    combined_df = pd.concat(all_data, ignore_index=True)
    print(f"ğŸ“Š åˆå¹¶åæ€»æ•°æ®: {len(combined_df)} æ¡è®°å½•")
    
    # æ¸…æ´—æ•°æ®
    print("ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—...")
    
    # æ¸…æ´—æ¶ˆæ¯å†…å®¹
    combined_df['cleaned_message'] = combined_df['message'].apply(clean_message)
    
    # è¿‡æ»¤æ‰ä¸éœ€è¦çš„æ¶ˆæ¯
    original_count = len(combined_df)
    combined_df = combined_df[~combined_df['cleaned_message'].apply(should_filter_message)]
    filtered_count = len(combined_df)
    
    print(f"ğŸ“Š è¿‡æ»¤å‰: {original_count} æ¡")
    print(f"ğŸ“Š è¿‡æ»¤å: {filtered_count} æ¡")
    print(f"ğŸ—‘ï¸ è¿‡æ»¤æ‰: {original_count - filtered_count} æ¡")
    
    # è‡ªåŠ¨åˆ†ç±»
    print("ğŸ·ï¸ å¼€å§‹è‡ªåŠ¨åˆ†ç±»...")
    combined_df['auto_label'] = combined_df['cleaned_message'].apply(classify_log)
    
    # ç»Ÿè®¡åˆ†ç±»ç»“æœ
    label_counts = combined_df['auto_label'].value_counts()
    print("ğŸ“ˆ è‡ªåŠ¨åˆ†ç±»ç»“æœ:")
    for label, count in label_counts.items():
        print(f"  {label}: {count} æ¡")
    
    # å¹³è¡¡æ•°æ®
    print("âš–ï¸ å¼€å§‹æ•°æ®å¹³è¡¡...")
    max_per_class = 500
    balanced_dfs = []
    
    for category in combined_df['auto_label'].unique():
        category_df = combined_df[combined_df['auto_label'] == category]
        if len(category_df) > max_per_class:
            category_df = category_df.sample(n=max_per_class, random_state=42)
        balanced_dfs.append(category_df)
    
    balanced_df = pd.concat(balanced_dfs, ignore_index=True)
    print(f"ğŸ“Š å¹³è¡¡åæ€»æ•°æ®: {len(balanced_df)} æ¡")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    training_df = balanced_df[['cleaned_message', 'auto_label']].copy()
    training_df.columns = ['text', 'label']
    training_df = training_df[training_df['text'].str.len() > 0]
    
    # ä¿å­˜æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    combined_file = output_dir / f"issue_logs_combined_{timestamp}.csv"
    balanced_df.to_csv(combined_file, index=False, encoding='utf-8')
    print(f"ğŸ’¾ å·²ä¿å­˜åˆå¹¶æ•°æ®é›†åˆ°: {combined_file}")
    
    training_file = output_dir / f"issue_logs_training_{timestamp}.csv"
    training_df.to_csv(training_file, index=False, encoding='utf-8')
    print(f"ğŸ’¾ å·²ä¿å­˜è®­ç»ƒæ•°æ®åˆ°: {training_file}")
    
    print(f"\nğŸ“ˆ æœ€ç»ˆç±»åˆ«åˆ†å¸ƒ:")
    final_counts = balanced_df['auto_label'].value_counts()
    for label, count in final_counts.items():
        percentage = (count / len(balanced_df)) * 100
        print(f"  {label}: {count} æ¡ ({percentage:.1f}%)")
    
    print("\nâœ… æ•°æ®æ¸…æ´—å®Œæˆï¼")

if __name__ == "__main__":
    main()
