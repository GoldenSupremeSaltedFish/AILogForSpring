#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥å¿—åˆ†ç±»è´¨é‡æ£€æµ‹åˆ†æå™¨
æ”¯æŒè‡ªåŠ¨åŒ–è´¨é‡è¯„ä¼°ã€ç»Ÿè®¡åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import pandas as pd
import numpy as np
import json
import os
import sys
from pathlib import Path
from datetime import datetime
import argparse
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# Configure matplotlib for Chinese font support
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class QualityAnalyzer:
    """æ—¥å¿—åˆ†ç±»è´¨é‡åˆ†æå™¨"""
    
    def __init__(self):
        self.classification_mapping = {
            'stack_exception': 'å †æ ˆå¼‚å¸¸',
            'connection_issue': 'è¿æ¥é—®é¢˜', 
            'database_exception': 'æ•°æ®åº“å¼‚å¸¸',
            'timeout': 'è¶…æ—¶',
            'spring_boot_startup_failure': 'Spring Bootå¯åŠ¨å¤±è´¥',
            'config_environment': 'é…ç½®ç¯å¢ƒ',
            'monitoring_heartbeat': 'ç›‘æ§å¿ƒè·³',
            'performance_issue': 'æ€§èƒ½é—®é¢˜',
            'security_auth': 'å®‰å…¨è®¤è¯',
            'api_request_response': 'APIè¯·æ±‚å“åº”',
            'business_logic': 'ä¸šåŠ¡é€»è¾‘',
            'other': 'å…¶ä»–'
        }
        
        self.priority_levels = {
            1: 'æé«˜ä¼˜å…ˆçº§',
            2: 'é«˜ä¼˜å…ˆçº§', 
            3: 'ä¸­é«˜ä¼˜å…ˆçº§',
            4: 'ä¸­ç­‰ä¼˜å…ˆçº§',
            8: 'ä½ä¼˜å…ˆçº§',
            11: 'æä½ä¼˜å…ˆçº§',
            999: 'å¿½ç•¥çº§åˆ«'
        }
        
        # æ·»åŠ é»˜è®¤è¾“å‡ºç›®å½•é…ç½®
        self.default_output_base = r"c:\Users\30871\Desktop\AILogForSpring\DATA_OUTPUT\è´¨é‡åˆ†æç»“æœ"
    
    def convert_numpy_types(self, obj):
        """Convert numpy types to native Python types for JSON serialization"""
        if isinstance(obj, dict):
            return {key: self.convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self.convert_numpy_types(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return obj
    
    def get_output_directory(self, file_path: str, custom_output_dir: str = None) -> str:
        """è·å–è¾“å‡ºç›®å½•ï¼ŒæŒ‰æ–‡ä»¶ååˆ›å»ºå­æ–‡ä»¶å¤¹"""
        if custom_output_dir:
            base_dir = custom_output_dir
        else:
            base_dir = self.default_output_base
        
        # ä»æ–‡ä»¶è·¯å¾„æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        file_name = os.path.splitext(os.path.basename(file_path))[0]
        
        # åˆ›å»ºä»¥æ–‡ä»¶åå‘½åçš„å­ç›®å½•
        output_dir = os.path.join(base_dir, file_name)
        os.makedirs(output_dir, exist_ok=True)
        
        return output_dir

    def load_data(self, file_path: str) -> pd.DataFrame:
        """åŠ è½½åˆ†ç±»æ•°æ®"""
        try:
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {len(df)} æ¡è®°å½•")
            return df
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None
    
    def basic_statistics(self, df: pd.DataFrame) -> Dict:
        """åŸºç¡€ç»Ÿè®¡åˆ†æ"""
        stats = {
            'total_records': int(len(df)),  # Convert to int
            'log_level_distribution': df['log_level'].value_counts().to_dict(),
            'content_type_distribution': df['content_type'].value_counts().to_dict(),
            'priority_distribution': df['priority'].value_counts().to_dict(),
            'manual_annotation_needed': {
                'count': int(df['manual_annotation_needed'].sum()),  # Convert to int
                'percentage': float((df['manual_annotation_needed'].sum() / len(df)) * 100)  # Convert to float
            }
        }
        return self.convert_numpy_types(stats)
    
    def quality_metrics(self, df: pd.DataFrame) -> Dict:
        """è´¨é‡æŒ‡æ ‡è®¡ç®—"""
        metrics = {}
        
        # åˆ†ç±»è¦†ç›–ç‡
        classified_count = len(df[df['content_type'] != 'other'])
        metrics['classification_coverage'] = float((classified_count / len(df)) * 100)
        
        # é«˜ä¼˜å…ˆçº§æ¯”ä¾‹
        high_priority_count = len(df[df['priority'] <= 4])
        metrics['high_priority_ratio'] = float((high_priority_count / len(df)) * 100)
        
        # éœ€è¦äººå·¥æ ‡æ³¨æ¯”ä¾‹
        manual_needed = df['manual_annotation_needed'].sum()
        metrics['manual_annotation_ratio'] = float((manual_needed / len(df)) * 100)
        
        # æ—¥å¿—çº§åˆ«åˆ†å¸ƒå‡è¡¡æ€§ï¼ˆç†µå€¼ï¼‰
        level_counts = df['log_level'].value_counts(normalize=True)
        metrics['level_distribution_entropy'] = float(-sum(p * np.log2(p) for p in level_counts if p > 0))
        
        # åˆ†ç±»åˆ†å¸ƒå‡è¡¡æ€§
        type_counts = df['content_type'].value_counts(normalize=True)
        metrics['type_distribution_entropy'] = float(-sum(p * np.log2(p) for p in type_counts if p > 0))
        
        return self.convert_numpy_types(metrics)
    
    def anomaly_detection(self, df: pd.DataFrame) -> Dict:
        """å¼‚å¸¸æ£€æµ‹"""
        anomalies = {}
        
        # æ£€æµ‹å¼‚å¸¸ä¼˜å…ˆçº§ç»„åˆ
        priority_content_combinations = df.groupby(['content_type', 'priority']).size()
        unusual_combinations = []
        
        for (content_type, priority), count in priority_content_combinations.items():
            if content_type == 'stack_exception' and priority > 4:
                unusual_combinations.append(f"å †æ ˆå¼‚å¸¸ä½†ä¼˜å…ˆçº§ä½: {content_type} - {priority} ({count}æ¡)")
            elif content_type == 'monitoring_heartbeat' and priority < 8:
                unusual_combinations.append(f"ç›‘æ§å¿ƒè·³ä½†ä¼˜å…ˆçº§é«˜: {content_type} - {priority} ({count}æ¡)")
        
        anomalies['unusual_priority_combinations'] = unusual_combinations
        
        # æ£€æµ‹ç©ºæˆ–å¼‚å¸¸é•¿åº¦çš„æ—¥å¿—
        empty_logs = len(df[df['original_log'].str.len() < 10])
        very_long_logs = len(df[df['original_log'].str.len() > 1000])
        
        anomalies['data_quality_issues'] = {
            'empty_or_short_logs': empty_logs,
            'very_long_logs': very_long_logs
        }
        
        # æ£€æµ‹é‡å¤æ—¥å¿—
        duplicate_logs = df['original_log'].duplicated().sum()
        anomalies['duplicate_logs'] = duplicate_logs
        
        return anomalies
    
    def generate_recommendations(self, stats: Dict, metrics: Dict, anomalies: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºåˆ†ç±»è¦†ç›–ç‡çš„å»ºè®®
        if metrics['classification_coverage'] < 80:
            recommendations.append("ğŸ”§ åˆ†ç±»è¦†ç›–ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–åˆ†ç±»è§„åˆ™ä»¥å‡å°‘'å…¶ä»–'ç±»åˆ«")
        
        # åŸºäºäººå·¥æ ‡æ³¨æ¯”ä¾‹çš„å»ºè®®
        if metrics['manual_annotation_ratio'] > 30:
            recommendations.append("âš ï¸ éœ€è¦äººå·¥æ ‡æ³¨çš„æ¯”ä¾‹è¿‡é«˜ï¼Œå»ºè®®å®Œå–„è‡ªåŠ¨åˆ†ç±»è§„åˆ™")
        
        # åŸºäºä¼˜å…ˆçº§åˆ†å¸ƒçš„å»ºè®®
        if metrics['high_priority_ratio'] > 50:
            recommendations.append("ğŸ“Š é«˜ä¼˜å…ˆçº§æ—¥å¿—æ¯”ä¾‹è¿‡é«˜ï¼Œå»ºè®®æ£€æŸ¥ä¼˜å…ˆçº§åˆ†é…é€»è¾‘")
        elif metrics['high_priority_ratio'] < 10:
            recommendations.append("ğŸ“Š é«˜ä¼˜å…ˆçº§æ—¥å¿—æ¯”ä¾‹è¿‡ä½ï¼Œå¯èƒ½é—æ¼é‡è¦é—®é¢˜")
        
        # åŸºäºå¼‚å¸¸æ£€æµ‹çš„å»ºè®®
        if anomalies['unusual_priority_combinations']:
            recommendations.append("ğŸš¨ å‘ç°å¼‚å¸¸çš„ä¼˜å…ˆçº§ç»„åˆï¼Œå»ºè®®æ£€æŸ¥åˆ†ç±»é€»è¾‘")
        
        if anomalies['duplicate_logs'] > 0:
            recommendations.append(f"ğŸ”„ å‘ç° {anomalies['duplicate_logs']} æ¡é‡å¤æ—¥å¿—ï¼Œå»ºè®®è¿›è¡Œå»é‡å¤„ç†")
        
        # åŸºäºæ•°æ®è´¨é‡çš„å»ºè®®
        data_issues = anomalies['data_quality_issues']
        if data_issues['empty_or_short_logs'] > 0:
            recommendations.append(f"ğŸ“ å‘ç° {data_issues['empty_or_short_logs']} æ¡è¿‡çŸ­æ—¥å¿—ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡")
        
        return recommendations
    
    def create_visualizations(self, df: pd.DataFrame, output_dir: str):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        # ç¡®ä¿ä¸­æ–‡å­—ä½“æ­£ç¡®æ˜¾ç¤º
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('æ—¥å¿—åˆ†ç±»è´¨é‡åˆ†ææŠ¥å‘Š', fontsize=16, fontweight='bold')
        
        # 1. æ—¥å¿—çº§åˆ«åˆ†å¸ƒ
        level_counts = df['log_level'].value_counts()
        axes[0, 0].pie(level_counts.values, labels=level_counts.index, autopct='%1.1f%%')
        axes[0, 0].set_title('æ—¥å¿—çº§åˆ«åˆ†å¸ƒ')
        
        # 2. å†…å®¹ç±»å‹åˆ†å¸ƒ
        type_counts = df['content_type'].value_counts().head(10)
        axes[0, 1].bar(range(len(type_counts)), type_counts.values)
        axes[0, 1].set_xticks(range(len(type_counts)))
        axes[0, 1].set_xticklabels([self.classification_mapping.get(t, t) for t in type_counts.index], 
                                  rotation=45, ha='right')
        axes[0, 1].set_title('å†…å®¹ç±»å‹åˆ†å¸ƒ (Top 10)')
        axes[0, 1].set_ylabel('æ•°é‡')
        
        # 3. ä¼˜å…ˆçº§åˆ†å¸ƒ
        priority_counts = df['priority'].value_counts().sort_index()
        axes[1, 0].bar([self.priority_levels.get(p, str(p)) for p in priority_counts.index], 
                      priority_counts.values)
        axes[1, 0].set_title('ä¼˜å…ˆçº§åˆ†å¸ƒ')
        axes[1, 0].set_ylabel('æ•°é‡')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 4. äººå·¥æ ‡æ³¨éœ€æ±‚åˆ†å¸ƒ
        manual_counts = df['manual_annotation_needed'].value_counts()
        axes[1, 1].pie(manual_counts.values, 
                      labels=['ä¸éœ€è¦äººå·¥æ ‡æ³¨', 'éœ€è¦äººå·¥æ ‡æ³¨'], 
                      autopct='%1.1f%%',
                      colors=['lightgreen', 'lightcoral'])
        axes[1, 1].set_title('äººå·¥æ ‡æ³¨éœ€æ±‚åˆ†å¸ƒ')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨ï¼Œç¡®ä¿æ”¯æŒä¸­æ–‡æ–‡ä»¶å
        chart_path = os.path.join(output_dir, 'quality_analysis_charts.png')
        plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {chart_path}")

    def generate_report(self, file_path: str, output_dir: str = None):
        """ç”Ÿæˆå®Œæ•´çš„è´¨é‡åˆ†ææŠ¥å‘Š"""
        # Use new output directory logic
        output_dir = self.get_output_directory(file_path, output_dir)
        
        os.makedirs(output_dir, exist_ok=True)
        
        # åŠ è½½æ•°æ®
        df = self.load_data(file_path)
        if df is None:
            return
        
        # æ‰§è¡Œåˆ†æ
        print("\nğŸ” æ‰§è¡ŒåŸºç¡€ç»Ÿè®¡åˆ†æ...")
        stats = self.basic_statistics(df)
        
        print("ğŸ“Š è®¡ç®—è´¨é‡æŒ‡æ ‡...")
        metrics = self.quality_metrics(df)
        
        print("ğŸš¨ æ‰§è¡Œå¼‚å¸¸æ£€æµ‹...")
        anomalies = self.anomaly_detection(df)
        
        print("ğŸ’¡ ç”Ÿæˆæ”¹è¿›å»ºè®®...")
        recommendations = self.generate_recommendations(stats, metrics, anomalies)
        
        print("ğŸ“ˆ åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        self.create_visualizations(df, output_dir)
        
        # ç”ŸæˆæŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = os.path.join(output_dir, f'quality_analysis_report_{timestamp}.txt')
        
        with open(report_file, 'w', encoding='utf-8-sig') as f:
            f.write("="*60 + "\n")
            f.write("æ—¥å¿—åˆ†ç±»è´¨é‡åˆ†ææŠ¥å‘Š\n")
            f.write("="*60 + "\n")
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•°æ®æ–‡ä»¶: {os.path.basename(file_path)}\n")
            f.write(f"æ€»è®°å½•æ•°: {stats['total_records']}\n\n")
            
            # åŸºç¡€ç»Ÿè®¡
            f.write("ğŸ“Š åŸºç¡€ç»Ÿè®¡ä¿¡æ¯\n")
            f.write("-"*30 + "\n")
            f.write(f"æ—¥å¿—çº§åˆ«åˆ†å¸ƒ:\n")
            for level, count in stats['log_level_distribution'].items():
                percentage = (count / stats['total_records']) * 100
                f.write(f"  {level}: {count} ({percentage:.1f}%)\n")
            
            f.write(f"\nå†…å®¹ç±»å‹åˆ†å¸ƒ (Top 10):\n")
            for i, (ctype, count) in enumerate(list(stats['content_type_distribution'].items())[:10]):
                percentage = (count / stats['total_records']) * 100
                display_name = self.classification_mapping.get(ctype, ctype)
                f.write(f"  {display_name}: {count} ({percentage:.1f}%)\n")
            
            # è´¨é‡æŒ‡æ ‡
            f.write(f"\nğŸ“ˆ è´¨é‡æŒ‡æ ‡\n")
            f.write("-"*30 + "\n")
            f.write(f"åˆ†ç±»è¦†ç›–ç‡: {metrics['classification_coverage']:.1f}%\n")
            f.write(f"é«˜ä¼˜å…ˆçº§æ¯”ä¾‹: {metrics['high_priority_ratio']:.1f}%\n")
            f.write(f"éœ€è¦äººå·¥æ ‡æ³¨æ¯”ä¾‹: {metrics['manual_annotation_ratio']:.1f}%\n")
            f.write(f"æ—¥å¿—çº§åˆ«åˆ†å¸ƒç†µå€¼: {metrics['level_distribution_entropy']:.2f}\n")
            f.write(f"åˆ†ç±»åˆ†å¸ƒç†µå€¼: {metrics['type_distribution_entropy']:.2f}\n")
            
            # å¼‚å¸¸æ£€æµ‹
            f.write(f"\nğŸš¨ å¼‚å¸¸æ£€æµ‹ç»“æœ\n")
            f.write("-"*30 + "\n")
            if anomalies['unusual_priority_combinations']:
                f.write("å¼‚å¸¸ä¼˜å…ˆçº§ç»„åˆ:\n")
                for combo in anomalies['unusual_priority_combinations']:
                    f.write(f"  âš ï¸ {combo}\n")
            else:
                f.write("âœ… æœªå‘ç°å¼‚å¸¸ä¼˜å…ˆçº§ç»„åˆ\n")
            
            f.write(f"\næ•°æ®è´¨é‡é—®é¢˜:\n")
            f.write(f"  è¿‡çŸ­æ—¥å¿—: {anomalies['data_quality_issues']['empty_or_short_logs']} æ¡\n")
            f.write(f"  è¿‡é•¿æ—¥å¿—: {anomalies['data_quality_issues']['very_long_logs']} æ¡\n")
            f.write(f"  é‡å¤æ—¥å¿—: {anomalies['duplicate_logs']} æ¡\n")
            
            # æ”¹è¿›å»ºè®®
            f.write(f"\nğŸ’¡ æ”¹è¿›å»ºè®®\n")
            f.write("-"*30 + "\n")
            if recommendations:
                for i, rec in enumerate(recommendations, 1):
                    f.write(f"{i}. {rec}\n")
            else:
                f.write("âœ… å½“å‰åˆ†ç±»è´¨é‡è‰¯å¥½ï¼Œæš‚æ— ç‰¹åˆ«å»ºè®®\n")
            
            f.write(f"\n" + "="*60 + "\n")
            f.write("æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n")
        
        # ç”ŸæˆJSONæ ¼å¼çš„è¯¦ç»†æ•°æ®
        json_file = os.path.join(output_dir, f'quality_analysis_data_{timestamp}.json')
        # Apply conversion before JSON serialization
        analysis_data = self.convert_numpy_types({
            'metadata': {
                'file_path': file_path,
                'analysis_time': datetime.now().isoformat(),
                'total_records': stats['total_records']
            },
            'statistics': stats,
            'quality_metrics': metrics,
            'anomalies': anomalies,
            'recommendations': recommendations
        })
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… è´¨é‡åˆ†æå®Œæˆ!")
        print(f"ğŸ“„ æ–‡æœ¬æŠ¥å‘Š: {report_file}")
        print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {json_file}")
        print(f"ğŸ“ˆ å›¾è¡¨æ–‡ä»¶: {os.path.join(output_dir, 'quality_analysis_charts.png')}")
        
        return analysis_data
    
    def compare_files(self, file1: str, file2: str, output_dir: str = None):
        """æ¯”è¾ƒä¸¤ä¸ªåˆ†ç±»æ–‡ä»¶çš„è´¨é‡å·®å¼‚"""
        print("ğŸ”„ å¼€å§‹æ¯”è¾ƒåˆ†æ...")
        
        df1 = self.load_data(file1)
        df2 = self.load_data(file2)
        
        if df1 is None or df2 is None:
            return
        
        metrics1 = self.quality_metrics(df1)
        metrics2 = self.quality_metrics(df2)
        
        # ä½¿ç”¨æ–°çš„è¾“å‡ºç›®å½•é€»è¾‘ï¼ŒåŸºäºç¬¬ä¸€ä¸ªæ–‡ä»¶ååˆ›å»ºç›®å½•
        if output_dir is None:
            output_dir = self.get_output_directory(file1)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        comparison_file = os.path.join(output_dir, f'quality_comparison_{timestamp}.txt')
        
        with open(comparison_file, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("åˆ†ç±»è´¨é‡å¯¹æ¯”åˆ†ææŠ¥å‘Š\n")
            f.write("="*60 + "\n")
            f.write(f"æ–‡ä»¶1: {os.path.basename(file1)} ({len(df1)} æ¡è®°å½•)\n")
            f.write(f"æ–‡ä»¶2: {os.path.basename(file2)} ({len(df2)} æ¡è®°å½•)\n")
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ğŸ“Š è´¨é‡æŒ‡æ ‡å¯¹æ¯”\n")
            f.write("-"*40 + "\n")
            f.write(f"{'æŒ‡æ ‡':<20} {'æ–‡ä»¶1':<15} {'æ–‡ä»¶2':<15} {'å·®å¼‚':<10}\n")
            f.write("-"*40 + "\n")
            
            for metric in ['classification_coverage', 'high_priority_ratio', 'manual_annotation_ratio']:
                val1 = metrics1[metric]
                val2 = metrics2[metric]
                diff = val2 - val1
                f.write(f"{metric:<20} {val1:<15.1f} {val2:<15.1f} {diff:+.1f}\n")
        
        print(f"ğŸ“Š å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {comparison_file}")

def main():
    parser = argparse.ArgumentParser(description='æ—¥å¿—åˆ†ç±»è´¨é‡åˆ†æå™¨')
    parser.add_argument('mode', choices=['analyze', 'compare'], help='åˆ†ææ¨¡å¼')
    parser.add_argument('--file', help='è¦åˆ†æçš„CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--file1', help='æ¯”è¾ƒæ¨¡å¼ï¼šç¬¬ä¸€ä¸ªæ–‡ä»¶')
    parser.add_argument('--file2', help='æ¯”è¾ƒæ¨¡å¼ï¼šç¬¬äºŒä¸ªæ–‡ä»¶')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    analyzer = QualityAnalyzer()
    
    if args.mode == 'analyze':
        if not args.file:
            print("âŒ åˆ†ææ¨¡å¼éœ€è¦æŒ‡å®š --file å‚æ•°")
            return
        
        analyzer.generate_report(args.file, args.output_dir)
    
    elif args.mode == 'compare':
        if not args.file1 or not args.file2:
            print("âŒ æ¯”è¾ƒæ¨¡å¼éœ€è¦æŒ‡å®š --file1 å’Œ --file2 å‚æ•°")
            return
        
        analyzer.compare_files(args.file1, args.file2, args.output_dir)

if __name__ == '__main__':
    main()