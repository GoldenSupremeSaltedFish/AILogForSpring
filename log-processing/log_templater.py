#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥å¿—æ¨¡æ¿åŒ–å·¥å…·
å®ç°ç±»ä¼¼Drain3çš„æ—¥å¿—æ¨¡æ¿åŒ–åŠŸèƒ½ï¼Œå°†ç›¸ä¼¼ç»“æ„çš„æ—¥å¿—å½’å¹¶ä¸ºæ¨¡æ¿
æ”¯æŒå™ªå£°å»é™¤ã€å¼‚å¸¸å­—å…¸ç”Ÿæˆå’Œæ¨¡æ¿IDåˆ†é…

ä½¿ç”¨æ–¹æ³•:
python log_templater.py --input-file logs.csv --output-dir output/
python log_templater.py --batch --input-dir logs/ --output-dir output/
"""

import pandas as pd
import numpy as np
import re
import json
import argparse
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict, Counter
import hashlib
import warnings
warnings.filterwarnings('ignore')

class LogTemplater:
    """æ—¥å¿—æ¨¡æ¿åŒ–å™¨"""
    
    def __init__(self):
        # å™ªå£°æ¨¡å¼å®šä¹‰
        self.noise_patterns = {
            'timestamp': [
                r'\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}(?:\.\d{3})?(?:Z|[+-]\d{2}:\d{2})?',  # ISOæ ¼å¼
                r'\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}(?:\.\d{3})?',  # æ ‡å‡†æ ¼å¼
                r'\d{2}/\d{2}/\d{4} \d{2}:\d{2}:\d{2}',  # ç¾å¼æ ¼å¼
                r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}',  # å¸¦æ¯«ç§’
            ],
            'thread_id': [
                r'\[thread-\d+\]',
                r'\[Thread-\d+\]', 
                r'\[T-\d+\]',
                r'thread-\d+',
                r'Thread-\d+',
            ],
            'uuid': [
                r'[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}',
                r'[0-9a-f]{32}',
            ],
            'request_id': [
                r'request-id:\s*[a-zA-Z0-9-]+',
                r'req-id:\s*[a-zA-Z0-9-]+',
                r'requestId:\s*[a-zA-Z0-9-]+',
            ],
            'ip_address': [
                r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b',
                r'\b(?:[0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}\b',  # IPv6
            ],
            'port_number': [
                r':\d{1,5}\b',
            ],
            'file_path': [
                r'[a-zA-Z]:\\[^:]+',
                r'/[^:]+',
                r'[a-zA-Z0-9_.-]+\.(java|py|js|ts|go|rs|cpp|c|h)',
            ],
            'line_number': [
                r':\d+\)',
                r'line \d+',
                r'at line \d+',
            ],
            'memory_address': [
                r'0x[0-9a-fA-F]+',
            ],
            'session_id': [
                r'session[_-]?id:\s*[a-zA-Z0-9-]+',
                r'sid:\s*[a-zA-Z0-9-]+',
            ]
        }
        
        # å¼‚å¸¸å…³é”®å­—å­—å…¸
        self.exception_keywords = {
            'java': [
                'NullPointerException', 'IllegalArgumentException', 'RuntimeException',
                'IndexOutOfBoundsException', 'ClassCastException', 'UnsupportedOperationException',
                'ConcurrentModificationException', 'NoSuchElementException', 'IllegalStateException',
                'OutOfMemoryError', 'StackOverflowError', 'NoClassDefFoundError',
                'ClassNotFoundException', 'InstantiationException', 'IllegalAccessException'
            ],
            'spring': [
                'BeanCreationException', 'BeanDefinitionStoreException', 'BeanInstantiationException',
                'NoSuchBeanDefinitionException', 'NoUniqueBeanDefinitionException',
                'TransactionSystemException', 'DataAccessException', 'DataIntegrityViolationException'
            ],
            'database': [
                'SQLException', 'DataAccessException', 'DataIntegrityViolationException',
                'DeadlockLoserDataAccessException', 'DuplicateKeyException',
                'DataRetrievalFailureException', 'InvalidDataAccessApiUsageException'
            ],
            'network': [
                'ConnectException', 'SocketTimeoutException', 'UnknownHostException',
                'BindException', 'NoRouteToHostException', 'ConnectionRefusedException'
            ],
            'web': [
                'HttpRequestMethodNotSupportedException', 'HttpMediaTypeNotSupportedException',
                'HttpMessageNotReadableException', 'MethodArgumentNotValidException',
                'MissingServletRequestParameterException', 'ServletRequestBindingException'
            ]
        }
        
        # æ¨¡æ¿å­˜å‚¨
        self.templates = {}
        self.template_counter = 0
        self.template_stats = defaultdict(int)
        
        # è¾“å‡ºç›®å½•é…ç½®
        self.output_base_dir = Path(__file__).parent.parent / "log-processing-OUTPUT"
        
    def clean_noise(self, log_line: str) -> Tuple[str, Dict[str, int]]:
        """å»é™¤æ—¥å¿—ä¸­çš„å™ªå£°"""
        cleaned_line = log_line
        noise_count = {}
        
        for noise_type, patterns in self.noise_patterns.items():
            count = 0
            for pattern in patterns:
                matches = re.findall(pattern, cleaned_line, re.IGNORECASE)
                count += len(matches)
                # æ›¿æ¢ä¸ºå ä½ç¬¦
                if noise_type == 'timestamp':
                    cleaned_line = re.sub(pattern, '<TIMESTAMP>', cleaned_line)
                elif noise_type == 'thread_id':
                    cleaned_line = re.sub(pattern, '<THREAD_ID>', cleaned_line)
                elif noise_type == 'uuid':
                    cleaned_line = re.sub(pattern, '<UUID>', cleaned_line)
                elif noise_type == 'request_id':
                    cleaned_line = re.sub(pattern, '<REQUEST_ID>', cleaned_line)
                elif noise_type == 'ip_address':
                    cleaned_line = re.sub(pattern, '<IP>', cleaned_line)
                elif noise_type == 'port_number':
                    cleaned_line = re.sub(pattern, '<PORT>', cleaned_line)
                elif noise_type == 'file_path':
                    cleaned_line = re.sub(pattern, '<FILE_PATH>', cleaned_line)
                elif noise_type == 'line_number':
                    cleaned_line = re.sub(pattern, '<LINE>', cleaned_line)
                elif noise_type == 'memory_address':
                    cleaned_line = re.sub(pattern, '<MEMORY_ADDR>', cleaned_line)
                elif noise_type == 'session_id':
                    cleaned_line = re.sub(pattern, '<SESSION_ID>', cleaned_line)
            
            noise_count[noise_type] = count
        
        return cleaned_line, noise_count
    
    def extract_exception_keywords(self, log_line: str) -> List[str]:
        """æå–å¼‚å¸¸å…³é”®å­—"""
        found_exceptions = []
        log_lower = log_line.lower()
        
        for category, exceptions in self.exception_keywords.items():
            for exception in exceptions:
                if exception.lower() in log_lower:
                    found_exceptions.append(f"{category}:{exception}")
        
        return found_exceptions
    
    def generate_template_id(self, cleaned_line: str) -> str:
        """ç”Ÿæˆæ¨¡æ¿ID"""
        # ä½¿ç”¨hashç”Ÿæˆæ¨¡æ¿ID
        template_hash = hashlib.md5(cleaned_line.encode('utf-8')).hexdigest()[:8]
        return f"T_{template_hash}"
    
    def create_template(self, cleaned_line: str, original_line: str) -> Dict:
        """åˆ›å»ºæ—¥å¿—æ¨¡æ¿"""
        template_id = self.generate_template_id(cleaned_line)
        
        if template_id not in self.templates:
            self.templates[template_id] = {
                'template_id': template_id,
                'template': cleaned_line,
                'count': 0,
                'examples': [],
                'exception_keywords': set(),
                'noise_stats': defaultdict(int),
                'created_at': datetime.now().isoformat()
            }
            self.template_counter += 1
        
        # æ›´æ–°æ¨¡æ¿ç»Ÿè®¡
        template = self.templates[template_id]
        template['count'] += 1
        self.template_stats[template_id] += 1
        
        # ä¿å­˜ç¤ºä¾‹ï¼ˆæœ€å¤šä¿å­˜5ä¸ªï¼‰
        if len(template['examples']) < 5:
            template['examples'].append(original_line)
        
        return template
    
    def process_log_line(self, log_line: str) -> Dict:
        """å¤„ç†å•è¡Œæ—¥å¿—"""
        # å»é™¤å™ªå£°
        cleaned_line, noise_count = self.clean_noise(log_line)
        
        # æå–å¼‚å¸¸å…³é”®å­—
        exception_keywords = self.extract_exception_keywords(log_line)
        
        # åˆ›å»ºæˆ–æ›´æ–°æ¨¡æ¿
        template = self.create_template(cleaned_line, log_line)
        
        # æ›´æ–°å¼‚å¸¸å…³é”®å­—
        template['exception_keywords'].update(exception_keywords)
        
        # æ›´æ–°å™ªå£°ç»Ÿè®¡
        for noise_type, count in noise_count.items():
            template['noise_stats'][noise_type] += count
        
        return {
            'original_log': log_line,
            'cleaned_log': cleaned_line,
            'template_id': template['template_id'],
            'template': template['template'],
            'noise_count': noise_count,
            'exception_keywords': exception_keywords,
            'has_stack_trace': 'at ' in log_line.lower() or 'caused by' in log_line.lower(),
            'log_length': len(log_line),
            'cleaned_length': len(cleaned_line)
        }
    
    def process_file(self, input_file: str, output_dir: Path) -> Dict:
        """å¤„ç†å•ä¸ªæ—¥å¿—æ–‡ä»¶"""
        print(f"ğŸ”„ å¤„ç†æ–‡ä»¶: {Path(input_file).name}")
        
        try:
            # è¯»å–æ•°æ®
            if input_file.endswith('.csv'):
                df = pd.read_csv(input_file, encoding='utf-8-sig')
                # å°è¯•ä¸åŒçš„åˆ—å
                log_column = None
                for col in ['original_log', 'message', 'content', 'text', 'log']:
                    if col in df.columns:
                        log_column = col
                        break
                
                if log_column is None:
                    print(f"âŒ æœªæ‰¾åˆ°æ—¥å¿—åˆ—ï¼Œå¯ç”¨åˆ—: {list(df.columns)}")
                    return {}
                
                log_lines = df[log_column].fillna('').astype(str).tolist()
            else:
                # çº¯æ–‡æœ¬æ–‡ä»¶
                with open(input_file, 'r', encoding='utf-8', errors='ignore') as f:
                    log_lines = [line.strip() for line in f if line.strip()]
            
            print(f"ğŸ“Š åŠ è½½äº† {len(log_lines)} æ¡æ—¥å¿—")
            
            # å¤„ç†æ—¥å¿—
            processed_logs = []
            for i, log_line in enumerate(log_lines):
                if i % 1000 == 0:
                    print(f"  å¤„ç†è¿›åº¦: {i}/{len(log_lines)}")
                
                result = self.process_log_line(log_line)
                processed_logs.append(result)
            
            # ä¿å­˜ç»“æœ
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            input_name = Path(input_file).stem
            
            # ä¿å­˜å¤„ç†åçš„æ—¥å¿—
            output_file = output_dir / f"{input_name}_templated_{timestamp}.csv"
            result_df = pd.DataFrame(processed_logs)
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            # ä¿å­˜æ¨¡æ¿ä¿¡æ¯
            template_file = output_dir / f"{input_name}_templates_{timestamp}.json"
            template_data = {
                'metadata': {
                    'input_file': input_file,
                    'processed_at': datetime.now().isoformat(),
                    'total_logs': len(log_lines),
                    'total_templates': len(self.templates)
                },
                'templates': {}
            }
            
            # è½¬æ¢æ¨¡æ¿æ•°æ®ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
            for template_id, template in self.templates.items():
                template_data['templates'][template_id] = {
                    'template_id': template['template_id'],
                    'template': template['template'],
                    'count': template['count'],
                    'examples': template['examples'],
                    'exception_keywords': list(template['exception_keywords']),
                    'noise_stats': dict(template['noise_stats']),
                    'created_at': template['created_at']
                }
            
            with open(template_file, 'w', encoding='utf-8') as f:
                json.dump(template_data, f, ensure_ascii=False, indent=2)
            
            # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
            self.generate_template_report(output_dir, input_name, timestamp)
            
            print(f"âœ… å¤„ç†å®Œæˆ: {output_file}")
            print(f"ğŸ“Š ç”Ÿæˆäº† {len(self.templates)} ä¸ªæ¨¡æ¿")
            
            return {
                'input_file': input_file,
                'output_file': str(output_file),
                'template_file': str(template_file),
                'total_logs': len(log_lines),
                'total_templates': len(self.templates)
            }
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def generate_template_report(self, output_dir: Path, input_name: str, timestamp: str):
        """ç”Ÿæˆæ¨¡æ¿ç»Ÿè®¡æŠ¥å‘Š"""
        report_file = output_dir / f"{input_name}_template_report_{timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("æ—¥å¿—æ¨¡æ¿åŒ–ç»Ÿè®¡æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n")
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"è¾“å…¥æ–‡ä»¶: {input_name}\n")
            f.write(f"æ€»æ—¥å¿—æ•°: {sum(self.template_stats.values())}\n")
            f.write(f"æ¨¡æ¿æ•°é‡: {len(self.templates)}\n\n")
            
            # æ¨¡æ¿ä½¿ç”¨é¢‘ç‡ç»Ÿè®¡
            f.write("æ¨¡æ¿ä½¿ç”¨é¢‘ç‡ (Top 20):\n")
            f.write("-" * 30 + "\n")
            sorted_templates = sorted(self.template_stats.items(), key=lambda x: x[1], reverse=True)
            for template_id, count in sorted_templates[:20]:
                template = self.templates[template_id]
                f.write(f"{template_id}: {count} æ¬¡\n")
                f.write(f"  æ¨¡æ¿: {template['template'][:100]}...\n")
                f.write(f"  å¼‚å¸¸å…³é”®å­—: {', '.join(template['exception_keywords'])}\n\n")
            
            # å¼‚å¸¸å…³é”®å­—ç»Ÿè®¡
            f.write("å¼‚å¸¸å…³é”®å­—ç»Ÿè®¡:\n")
            f.write("-" * 30 + "\n")
            all_exceptions = []
            for template in self.templates.values():
                all_exceptions.extend(template['exception_keywords'])
            
            exception_counts = Counter(all_exceptions)
            for exception, count in exception_counts.most_common(20):
                f.write(f"{exception}: {count} æ¬¡\n")
        
        print(f"ğŸ“„ ç»Ÿè®¡æŠ¥å‘Š: {report_file}")
    
    def batch_process(self, input_dir: str, output_dir: Path):
        """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ—¥å¿—æ–‡ä»¶"""
        input_path = Path(input_dir)
        if not input_path.exists():
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        
        # æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶
        log_extensions = ['.log', '.txt', '.csv', '.out', '.err']
        log_files = []
        
        for ext in log_extensions:
            log_files.extend(input_path.rglob(f"*{ext}"))
        
        if not log_files:
            print("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")
            return
        
        print(f"ğŸ“ æ‰¾åˆ° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        batch_output_dir = output_dir / f"batch_templated_{timestamp}"
        batch_output_dir.mkdir(exist_ok=True, parents=True)
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        results = []
        for i, log_file in enumerate(log_files, 1):
            print(f"\n{'='*50}")
            print(f"å¤„ç†è¿›åº¦: {i}/{len(log_files)}")
            
            result = self.process_file(str(log_file), batch_output_dir)
            if result:
                results.append(result)
        
        # ç”Ÿæˆæ‰¹é‡å¤„ç†æ‘˜è¦
        self.generate_batch_summary(batch_output_dir, results)
        
        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {batch_output_dir}")
        print(f"ğŸ“Š æˆåŠŸå¤„ç†: {len(results)}/{len(log_files)} ä¸ªæ–‡ä»¶")
    
    def generate_batch_summary(self, output_dir: Path, results: List[Dict]):
        """ç”Ÿæˆæ‰¹é‡å¤„ç†æ‘˜è¦"""
        summary_file = output_dir / "batch_processing_summary.txt"
        
        total_logs = sum(r.get('total_logs', 0) for r in results)
        total_templates = sum(r.get('total_templates', 0) for r in results)
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("æ‰¹é‡æ—¥å¿—æ¨¡æ¿åŒ–å¤„ç†æ‘˜è¦\n")
            f.write("=" * 50 + "\n")
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¤„ç†æ–‡ä»¶æ•°: {len(results)}\n")
            f.write(f"æ€»æ—¥å¿—æ•°: {total_logs}\n")
            f.write(f"æ€»æ¨¡æ¿æ•°: {total_templates}\n\n")
            
            f.write("å¤„ç†ç»“æœ:\n")
            f.write("-" * 30 + "\n")
            for result in results:
                f.write(f"æ–‡ä»¶: {Path(result['input_file']).name}\n")
                f.write(f"  æ—¥å¿—æ•°: {result['total_logs']}\n")
                f.write(f"  æ¨¡æ¿æ•°: {result['total_templates']}\n")
                f.write(f"  è¾“å‡º: {Path(result['output_file']).name}\n\n")
        
        print(f"ğŸ“‹ æ‰¹é‡å¤„ç†æ‘˜è¦: {summary_file}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ—¥å¿—æ¨¡æ¿åŒ–å·¥å…·')
    parser.add_argument('--input-file', help='è¾“å…¥æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--input-dir', help='è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--batch', action='store_true', help='æ‰¹é‡å¤„ç†æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¨¡æ¿åŒ–å™¨
    templater = LogTemplater()
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        output_dir = templater.output_base_dir / "templated_logs"
    
    output_dir.mkdir(exist_ok=True, parents=True)
    
    if args.batch or args.input_dir:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        if not args.input_dir:
            print("âŒ æ‰¹é‡æ¨¡å¼éœ€è¦æŒ‡å®š --input-dir")
            return
        
        templater.batch_process(args.input_dir, output_dir)
    
    elif args.input_file:
        # å•æ–‡ä»¶æ¨¡å¼
        if not Path(args.input_file).exists():
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        single_output_dir = output_dir / f"single_templated_{timestamp}"
        single_output_dir.mkdir(exist_ok=True, parents=True)
        
        result = templater.process_file(args.input_file, single_output_dir)
        if result:
            print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {single_output_dir}")
    
    else:
        print("âŒ è¯·æŒ‡å®š --input-file æˆ–ä½¿ç”¨ --batch --input-dir è¿›è¡Œæ‰¹é‡å¤„ç†")
        parser.print_help()

if __name__ == "__main__":
    main()
